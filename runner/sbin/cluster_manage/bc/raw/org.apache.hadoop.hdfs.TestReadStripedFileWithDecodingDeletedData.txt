[msx] before_class
2020-04-02 05:08:46,335 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=9
Formatting using clusterid: testClusterID
2020-04-02 05:08:47,105 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:08:47,120 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:08:47,122 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:08:47,123 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:08:47,131 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:08:47,132 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:08:47,132 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:08:47,133 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:08:47,182 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:47,188 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-02 05:08:47,188 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:08:47,189 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:08:47,194 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:08:47,195 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:08:47
2020-04-02 05:08:47,198 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:08:47,199 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:47,202 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:08:47,202 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:08:47,224 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:08:47,236 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:08:47,236 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:08:47,237 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:08:47,237 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:08:47,237 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:08:47,237 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:08:47,238 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:08:47,238 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 0
2020-04-02 05:08:47,238 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:08:47,238 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:08:47,239 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:08:47,277 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:initialize(77)) - GLOBAL serial map: bits=24 maxEntries=16777215
2020-04-02 05:08:47,296 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:08:47,297 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:47,297 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:08:47,297 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:08:47,304 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:08:47,304 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:08:47,304 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:08:47,305 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:08:47,311 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:08:47,314 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:08:47,319 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:08:47,320 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:47,320 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:08:47,321 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:08:47,331 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:08:47,331 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:08:47,331 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:08:47,336 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:08:47,337 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:08:47,341 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:08:47,341 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:47,341 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:08:47,342 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:08:47,387 [main] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:47,403 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:08:47,405 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:08:47,418 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:08:47,418 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:08:47,583 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:08:47,584 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:08:47,611 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:08:47,616 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:08:47,795 [main] INFO  beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-04-02 05:08:47,862 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:08:48,315 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:08:48,321 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:08:48,328 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:08:48,361 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:08:48,412 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@54e1c68b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:48,435 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:08:48,441 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:48,459 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3473ms
2020-04-02 05:08:48,580 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:48,584 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:08:48,585 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:48,595 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:48,598 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:08:48,602 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:48,602 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:48,642 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:08:48,643 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:08:48,656 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34516
2020-04-02 05:08:48,659 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:48,775 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7d322cad{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:48,777 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4f49f6af{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:48,853 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@797b0699{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:08:48,888 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4f704591{HTTP/1.1,[http/1.1]}{localhost:34516}
2020-04-02 05:08:48,889 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3903ms
2020-04-02 05:08:48,916 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:08:48,917 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:08:48,918 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:08:48,918 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:08:48,919 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:08:48,919 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:08:48,919 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:08:48,920 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:08:48,921 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:48,922 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:08:48,922 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:08:48,923 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:08:48,924 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:08:48
2020-04-02 05:08:48,924 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:08:48,924 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:48,925 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:08:48,925 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:08:48,933 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:08:48,934 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:08:48,935 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:08:48,935 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:08:48,935 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:08:48,936 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:08:48,936 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:08:48,936 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:08:48,937 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 0
2020-04-02 05:08:48,942 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:08:48,942 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:08:48,943 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:08:48,943 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:08:48,944 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:48,944 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:08:48,944 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:08:48,947 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:08:48,947 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:08:48,962 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:08:48,962 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:08:48,963 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:08:48,963 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:08:48,964 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:08:48,964 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:48,964 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:08:48,965 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:08:48,966 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:08:48,966 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:08:48,966 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:08:48,967 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:08:48,967 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:08:48,967 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:08:48,967 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:48,968 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:08:48,968 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:08:48,983 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 10089@f8287aaf0779
2020-04-02 05:08:48,987 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 10089@f8287aaf0779
2020-04-02 05:08:48,990 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:08:48,991 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:08:48,992 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:08:48,992 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:08:49,036 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:08:49,045 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:08:49,047 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:08:49,052 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:08:49,058 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:08:49,098 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:08:49,098 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 121 msecs
2020-04-02 05:08:49,335 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:08:49,348 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:49,369 [Socket Reader #1 for port 41191] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41191
2020-04-02 05:08:49,641 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:41191 to access this namenode/service.
2020-04-02 05:08:49,648 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:08:49,769 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:08:49,771 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@7e7b159b] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-04-02 05:08:49,789 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:08:49,810 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:08:49,810 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:08:49,810 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:08:49,836 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:08:49,836 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:08:49,836 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:08:49,837 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:08:49,837 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:08:49,837 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 26 msec
2020-04-02 05:08:49,894 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:49,911 [IPC Server listener on 41191] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41191: starting
2020-04-02 05:08:49,917 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:41191
2020-04-02 05:08:49,930 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:08:49,930 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:08:49,944 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 14 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:08:49,958 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 41191 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:49,981 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:08:50,002 [CacheReplicationMonitor(115943867)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:08:50,107 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:08:50,220 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:08:50,243 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:50,244 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:50,250 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:50,253 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:50,255 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:50,257 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:50,261 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:50,283 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:34596
2020-04-02 05:08:50,286 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:50,286 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:50,304 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:50,307 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:50,308 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:50,308 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:50,311 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:50,313 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:50,314 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:50,314 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:50,321 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 43476
2020-04-02 05:08:50,322 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:50,325 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@686449f9{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:50,328 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@68b6f0d6{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:50,350 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5dd91bca{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:50,357 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@409b1aa0{HTTP/1.1,[http/1.1]}{localhost:43476}
2020-04-02 05:08:50,358 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5372ms
2020-04-02 05:08:50,840 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44049
2020-04-02 05:08:50,842 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5b970f7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:50,843 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:50,843 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:50,872 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:50,874 [Socket Reader #1 for port 36235] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36235
2020-04-02 05:08:50,886 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:36235
2020-04-02 05:08:50,903 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:50,907 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:51,375 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41191 starting to offer service
2020-04-02 05:08:51,389 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:51,389 [IPC Server listener on 36235] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36235: starting
2020-04-02 05:08:51,391 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 36235 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:51,395 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:08:51,397 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:08:51,398 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:08:51,422 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:51,429 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:51,432 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:51,432 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:51,433 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:51,434 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:51,434 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:51,435 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:39776
2020-04-02 05:08:51,436 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:51,436 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:51,439 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:51,442 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:51,443 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:51,443 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:51,445 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:51,446 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:51,446 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:51,447 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:51,448 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39627
2020-04-02 05:08:51,448 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:51,450 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6a62689d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:51,451 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@60fa3495{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:51,458 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2cf23c81{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:51,460 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3624da92{HTTP/1.1,[http/1.1]}{localhost:39627}
2020-04-02 05:08:51,461 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6475ms
2020-04-02 05:08:51,575 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36167
2020-04-02 05:08:51,576 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:51,577 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:51,577 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:51,578 [Socket Reader #1 for port 46492] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 46492
2020-04-02 05:08:51,582 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@94f6bfb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:51,607 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:46492
2020-04-02 05:08:51,661 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:51,662 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:51,666 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:51,671 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 46492 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:51,673 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:08:51,668 [Thread-84] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41191 starting to offer service
2020-04-02 05:08:51,675 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:08:51,678 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:08:51,674 [IPC Server listener on 46492] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 46492: starting
2020-04-02 05:08:51,694 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:51,703 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:51,703 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:51,704 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:51,706 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:51,706 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:51,707 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:51,717 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:33488
2020-04-02 05:08:51,717 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:51,718 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:51,766 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:51,769 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:51,775 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:51,775 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:51,777 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:51,779 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:51,779 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:51,779 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:51,780 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 45279
2020-04-02 05:08:51,781 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:51,782 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4ef27d66{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:51,815 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1d9bec4d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:51,842 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2f94c4db{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:51,850 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@593e824f{HTTP/1.1,[http/1.1]}{localhost:45279}
2020-04-02 05:08:51,851 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6866ms
2020-04-02 05:08:51,875 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42409
2020-04-02 05:08:51,881 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6d8792db] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:51,881 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:51,882 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:51,882 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:51,883 [Socket Reader #1 for port 46631] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 46631
2020-04-02 05:08:51,887 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:46631
2020-04-02 05:08:51,904 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:51,905 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:51,906 [Thread-107] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41191 starting to offer service
2020-04-02 05:08:51,918 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 46631 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:51,923 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:08:51,925 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:08:51,925 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:51,934 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:08:51,916 [IPC Server listener on 46631] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 46631: starting
2020-04-02 05:08:51,943 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:51,943 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:51,944 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:51,944 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:51,944 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:51,945 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:51,945 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:51,946 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:45517
2020-04-02 05:08:51,947 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:51,947 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:51,949 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:51,951 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:51,952 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:51,953 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:51,955 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:51,957 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:51,957 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:51,958 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:51,960 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38180
2020-04-02 05:08:51,960 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:51,963 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@549621f3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:51,964 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@32232e55{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:51,970 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@192f2f27{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:51,971 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@8a589a2{HTTP/1.1,[http/1.1]}{localhost:38180}
2020-04-02 05:08:51,972 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6986ms
2020-04-02 05:08:52,077 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41207
2020-04-02 05:08:52,077 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6b5176f2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:52,077 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:52,077 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:52,078 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:52,078 [Socket Reader #1 for port 44568] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 44568
2020-04-02 05:08:52,083 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:44568
2020-04-02 05:08:52,088 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:52,088 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:52,093 [Thread-130] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41191 starting to offer service
2020-04-02 05:08:52,154 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:52,161 [IPC Server listener on 44568] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 44568: starting
2020-04-02 05:08:52,182 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 44568 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:52,184 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:08:52,186 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:08:52,186 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:08:52,202 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:52,202 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:52,202 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:52,202 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:52,203 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:52,209 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:52,210 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:52,211 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:41818
2020-04-02 05:08:52,211 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:52,211 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:52,213 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:52,215 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:52,216 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:52,216 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:52,226 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:52,227 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:52,237 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:52,242 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:52,261 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34231
2020-04-02 05:08:52,261 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:52,273 [Thread-107] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41191
2020-04-02 05:08:52,275 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4fd4cae3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:52,280 [Thread-107] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:52,273 [Thread-130] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41191
2020-04-02 05:08:52,264 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41191
2020-04-02 05:08:52,288 [Thread-84] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41191
2020-04-02 05:08:52,286 [Thread-130] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:52,291 [Thread-130] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 10089@f8287aaf0779
2020-04-02 05:08:52,292 [Thread-130] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 870746973. Formatting...
2020-04-02 05:08:52,293 [Thread-130] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-bd9fc205-c45f-48b9-85ed-311ae68dcf33 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-04-02 05:08:52,294 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@a1217f9{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:52,297 [Thread-107] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 10089@f8287aaf0779
2020-04-02 05:08:52,297 [Thread-107] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 870746973. Formatting...
2020-04-02 05:08:52,298 [Thread-107] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-473eb806-1eb7-4944-8753-5f4b73aff970 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-04-02 05:08:52,302 [Thread-130] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 10089@f8287aaf0779
2020-04-02 05:08:52,303 [Thread-130] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 870746973. Formatting...
2020-04-02 05:08:52,303 [Thread-130] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a691264e-7ef4-4189-b9ec-6f397eff2bb2 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-04-02 05:08:52,305 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@66ea1466{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:52,307 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1601e47{HTTP/1.1,[http/1.1]}{localhost:34231}
2020-04-02 05:08:52,308 [main] INFO  server.Server (Server.java:doStart(419)) - Started @7323ms
2020-04-02 05:08:52,307 [Thread-107] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 10089@f8287aaf0779
2020-04-02 05:08:52,322 [Thread-84] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:52,318 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:52,344 [Thread-107] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 870746973. Formatting...
2020-04-02 05:08:52,347 [Thread-107] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-74648b74-08f4-4ca5-a128-e9784b6b21d8 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-04-02 05:08:52,348 [Thread-59] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 10089@f8287aaf0779
2020-04-02 05:08:52,348 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 870746973. Formatting...
2020-04-02 05:08:52,349 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2078a8cc-9828-4e10-96be-f8b4239ff4fe for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:08:52,350 [Thread-84] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 10089@f8287aaf0779
2020-04-02 05:08:52,350 [Thread-84] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 870746973. Formatting...
2020-04-02 05:08:52,351 [Thread-84] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0a0c2452-7424-4ea5-a7af-8c6055bbad34 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:08:52,354 [Thread-59] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 10089@f8287aaf0779
2020-04-02 05:08:52,356 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 870746973. Formatting...
2020-04-02 05:08:52,356 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-244b1c01-4b44-4923-8631-0dc549a7ddde for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:08:52,359 [Thread-84] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 10089@f8287aaf0779
2020-04-02 05:08:52,359 [Thread-84] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 870746973. Formatting...
2020-04-02 05:08:52,359 [Thread-84] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c37ee172-cb9b-4f05-84aa-bcebbe58c663 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:08:52,373 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:52,373 [Thread-59] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:52,374 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1781155512-172.17.0.11-1585804127366 is not formatted. Formatting ...
2020-04-02 05:08:52,374 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1781155512-172.17.0.11-1585804127366 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1781155512-172.17.0.11-1585804127366/current
2020-04-02 05:08:52,375 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:52,376 [Thread-84] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:52,376 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1781155512-172.17.0.11-1585804127366 is not formatted. Formatting ...
2020-04-02 05:08:52,376 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1781155512-172.17.0.11-1585804127366 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1781155512-172.17.0.11-1585804127366/current
2020-04-02 05:08:52,392 [Thread-130] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:52,392 [Thread-130] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:52,392 [Thread-130] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-1781155512-172.17.0.11-1585804127366 is not formatted. Formatting ...
2020-04-02 05:08:52,392 [Thread-130] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1781155512-172.17.0.11-1585804127366 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1781155512-172.17.0.11-1585804127366/current
2020-04-02 05:08:52,394 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:52,394 [Thread-59] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:52,395 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1781155512-172.17.0.11-1585804127366 is not formatted. Formatting ...
2020-04-02 05:08:52,395 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1781155512-172.17.0.11-1585804127366 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1781155512-172.17.0.11-1585804127366/current
2020-04-02 05:08:52,396 [Thread-107] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:52,396 [Thread-107] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:52,396 [Thread-107] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-1781155512-172.17.0.11-1585804127366 is not formatted. Formatting ...
2020-04-02 05:08:52,397 [Thread-107] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1781155512-172.17.0.11-1585804127366 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1781155512-172.17.0.11-1585804127366/current
2020-04-02 05:08:52,424 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=870746973;bpid=BP-1781155512-172.17.0.11-1585804127366;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=870746973;c=1585804127366;bpid=BP-1781155512-172.17.0.11-1585804127366;dnuuid=null
2020-04-02 05:08:52,425 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42795
2020-04-02 05:08:52,427 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 690f7552-c4c3-4286-845f-64b6525bf551
2020-04-02 05:08:52,437 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:52,437 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:52,438 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@66971f6b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:52,438 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:52,439 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:52,439 [Thread-84] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:52,439 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1781155512-172.17.0.11-1585804127366 is not formatted. Formatting ...
2020-04-02 05:08:52,439 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1781155512-172.17.0.11-1585804127366 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1781155512-172.17.0.11-1585804127366/current
2020-04-02 05:08:52,442 [Socket Reader #1 for port 43620] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43620
2020-04-02 05:08:52,445 [Thread-107] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:52,445 [Thread-107] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:52,445 [Thread-107] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-1781155512-172.17.0.11-1585804127366 is not formatted. Formatting ...
2020-04-02 05:08:52,445 [Thread-107] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1781155512-172.17.0.11-1585804127366 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1781155512-172.17.0.11-1585804127366/current
2020-04-02 05:08:52,456 [Thread-130] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:52,457 [Thread-130] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:52,461 [Thread-107] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=870746973;bpid=BP-1781155512-172.17.0.11-1585804127366;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=870746973;c=1585804127366;bpid=BP-1781155512-172.17.0.11-1585804127366;dnuuid=null
2020-04-02 05:08:52,464 [Thread-107] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID f1177179-f009-4517-a835-ba14c97e85ff
2020-04-02 05:08:52,465 [Thread-130] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-1781155512-172.17.0.11-1585804127366 is not formatted. Formatting ...
2020-04-02 05:08:52,466 [Thread-130] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1781155512-172.17.0.11-1585804127366 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1781155512-172.17.0.11-1585804127366/current
2020-04-02 05:08:52,474 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:43620
2020-04-02 05:08:52,475 [Thread-130] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=870746973;bpid=BP-1781155512-172.17.0.11-1585804127366;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=870746973;c=1585804127366;bpid=BP-1781155512-172.17.0.11-1585804127366;dnuuid=null
2020-04-02 05:08:52,477 [Thread-130] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c
2020-04-02 05:08:52,474 [Thread-84] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=870746973;bpid=BP-1781155512-172.17.0.11-1585804127366;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=870746973;c=1585804127366;bpid=BP-1781155512-172.17.0.11-1585804127366;dnuuid=null
2020-04-02 05:08:52,479 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:52,480 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:52,481 [Thread-84] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID ca9828e1-172e-4a2c-a1a8-917b3485899c
2020-04-02 05:08:52,484 [Thread-153] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41191 starting to offer service
2020-04-02 05:08:52,510 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:52,510 [IPC Server listener on 43620] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43620: starting
2020-04-02 05:08:52,523 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 43620 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:52,525 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:08:52,528 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:08:52,529 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:08:52,542 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:52,542 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:52,542 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:52,542 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:52,543 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:52,543 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:52,543 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:52,544 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:38003
2020-04-02 05:08:52,544 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:52,544 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:52,546 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:52,548 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:52,556 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:52,556 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:52,558 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:52,559 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:52,559 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:52,560 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:52,560 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35793
2020-04-02 05:08:52,561 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:52,562 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@26be6ca7{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:52,563 [Thread-153] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41191
2020-04-02 05:08:52,563 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@759fad4{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:52,582 [Thread-153] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:52,584 [Thread-153] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 10089@f8287aaf0779
2020-04-02 05:08:52,584 [Thread-153] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 870746973. Formatting...
2020-04-02 05:08:52,584 [Thread-153] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c5dfe81d-cd58-425d-bfae-86f08d014c3b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-04-02 05:08:52,585 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6cea706c{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:52,585 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3bd7f8dc{HTTP/1.1,[http/1.1]}{localhost:35793}
2020-04-02 05:08:52,586 [main] INFO  server.Server (Server.java:doStart(419)) - Started @7600ms
2020-04-02 05:08:52,594 [Thread-153] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 10089@f8287aaf0779
2020-04-02 05:08:52,595 [Thread-153] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 870746973. Formatting...
2020-04-02 05:08:52,595 [Thread-153] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d9137667-94c0-4dee-b215-ab45ce9137b2 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-04-02 05:08:52,604 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37522
2020-04-02 05:08:52,605 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1eba372c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:52,605 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:52,606 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:52,606 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:52,607 [Socket Reader #1 for port 33566] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33566
2020-04-02 05:08:52,630 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:52,630 [Thread-153] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:52,630 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-1781155512-172.17.0.11-1585804127366 is not formatted. Formatting ...
2020-04-02 05:08:52,630 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1781155512-172.17.0.11-1585804127366 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1781155512-172.17.0.11-1585804127366/current
2020-04-02 05:08:52,640 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:33566
2020-04-02 05:08:52,664 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:52,665 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:52,668 [Thread-176] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41191 starting to offer service
2020-04-02 05:08:52,669 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:52,669 [IPC Server listener on 33566] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33566: starting
2020-04-02 05:08:52,670 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:52,671 [Thread-153] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:52,671 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-1781155512-172.17.0.11-1585804127366 is not formatted. Formatting ...
2020-04-02 05:08:52,671 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1781155512-172.17.0.11-1585804127366 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1781155512-172.17.0.11-1585804127366/current
2020-04-02 05:08:52,694 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 33566 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:52,695 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:08:52,696 [Thread-153] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=870746973;bpid=BP-1781155512-172.17.0.11-1585804127366;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=870746973;c=1585804127366;bpid=BP-1781155512-172.17.0.11-1585804127366;dnuuid=null
2020-04-02 05:08:52,696 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:08:52,697 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:08:52,704 [Thread-153] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 138c0d7d-7e58-4339-8b75-15c135daf76d
2020-04-02 05:08:52,711 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:52,711 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:52,712 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:52,712 [Thread-176] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41191
2020-04-02 05:08:52,712 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:52,713 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:52,713 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:52,713 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:52,734 [Thread-176] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:52,734 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:45304
2020-04-02 05:08:52,734 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:52,734 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:52,737 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:52,755 [Thread-176] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 10089@f8287aaf0779
2020-04-02 05:08:52,756 [Thread-176] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 870746973. Formatting...
2020-04-02 05:08:52,756 [Thread-176] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-cd20bec6-61af-4cee-a017-bfc56735fa58 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-04-02 05:08:52,758 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:52,759 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:52,759 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:52,760 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:52,764 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:52,764 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:52,764 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:52,765 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 43019
2020-04-02 05:08:52,765 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:52,781 [Thread-176] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 10089@f8287aaf0779
2020-04-02 05:08:52,781 [Thread-176] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 870746973. Formatting...
2020-04-02 05:08:52,781 [Thread-176] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8ed92d4e-a113-43e3-89fc-e65f907cbe5e for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-04-02 05:08:52,786 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:08:52,789 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2f4854d6{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:52,802 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7e70bd39{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:52,847 [Thread-176] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:52,848 [Thread-176] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:52,854 [Thread-176] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-1781155512-172.17.0.11-1585804127366 is not formatted. Formatting ...
2020-04-02 05:08:52,854 [Thread-176] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1781155512-172.17.0.11-1585804127366 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1781155512-172.17.0.11-1585804127366/current
2020-04-02 05:08:52,858 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6e57e95e{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:52,859 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2755d705{HTTP/1.1,[http/1.1]}{localhost:43019}
2020-04-02 05:08:52,859 [main] INFO  server.Server (Server.java:doStart(419)) - Started @7874ms
2020-04-02 05:08:52,881 [Thread-176] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:52,910 [Thread-176] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:52,910 [Thread-176] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-1781155512-172.17.0.11-1585804127366 is not formatted. Formatting ...
2020-04-02 05:08:52,910 [Thread-176] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1781155512-172.17.0.11-1585804127366 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1781155512-172.17.0.11-1585804127366/current
2020-04-02 05:08:52,911 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-2078a8cc-9828-4e10-96be-f8b4239ff4fe
2020-04-02 05:08:52,911 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:08:52,912 [Thread-176] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=870746973;bpid=BP-1781155512-172.17.0.11-1585804127366;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=870746973;c=1585804127366;bpid=BP-1781155512-172.17.0.11-1585804127366;dnuuid=null
2020-04-02 05:08:52,913 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-244b1c01-4b44-4923-8631-0dc549a7ddde
2020-04-02 05:08:52,914 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:08:52,911 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-0a0c2452-7424-4ea5-a7af-8c6055bbad34
2020-04-02 05:08:52,911 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c5dfe81d-cd58-425d-bfae-86f08d014c3b
2020-04-02 05:08:52,918 [Thread-153] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-04-02 05:08:52,918 [Thread-176] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0
2020-04-02 05:08:52,919 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37250
2020-04-02 05:08:52,919 [Thread-130] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-bd9fc205-c45f-48b9-85ed-311ae68dcf33
2020-04-02 05:08:52,935 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:52,935 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:52,936 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:52,936 [Thread-176] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-cd20bec6-61af-4cee-a017-bfc56735fa58
2020-04-02 05:08:52,914 [Thread-107] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-473eb806-1eb7-4944-8753-5f4b73aff970
2020-04-02 05:08:52,962 [Thread-107] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:08:52,962 [Thread-176] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-04-02 05:08:52,965 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:52,966 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:45067
2020-04-02 05:08:52,966 [Thread-176] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-8ed92d4e-a113-43e3-89fc-e65f907cbe5e
2020-04-02 05:08:52,967 [Thread-176] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-04-02 05:08:52,967 [Thread-107] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-74648b74-08f4-4ca5-a128-e9784b6b21d8
2020-04-02 05:08:52,960 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-d9137667-94c0-4dee-b215-ab45ce9137b2
2020-04-02 05:08:52,976 [Thread-153] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-04-02 05:08:52,977 [Thread-153] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:52,953 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:08:52,938 [Socket Reader #1 for port 45067] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 45067
2020-04-02 05:08:52,935 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@740abb5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:52,935 [Thread-130] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-04-02 05:08:52,974 [Thread-176] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:52,993 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:52,994 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:52,995 [Thread-209] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41191 starting to offer service
2020-04-02 05:08:52,997 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:52,970 [Thread-107] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:08:53,002 [Thread-107] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:53,013 [IPC Server listener on 45067] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 45067: starting
2020-04-02 05:08:53,021 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 45067 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:53,022 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:08:53,025 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:08:53,026 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:08:53,027 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:53,027 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:53,028 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:53,019 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:08:53,021 [Thread-107] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:08:53,022 [Thread-176] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:08:53,045 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c37ee172-cb9b-4f05-84aa-bcebbe58c663
2020-04-02 05:08:53,046 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:08:53,046 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:53,047 [Thread-84] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:08:53,050 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:53,052 [Thread-130] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-a691264e-7ef4-4189-b9ec-6f397eff2bb2
2020-04-02 05:08:53,052 [Thread-130] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-04-02 05:08:53,052 [Thread-153] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:08:53,053 [Thread-130] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:53,055 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:53,055 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:53,056 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:53,056 [Thread-130] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:08:53,056 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:38083
2020-04-02 05:08:53,056 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:53,057 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:53,064 [Thread-209] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41191
2020-04-02 05:08:53,065 [Thread-107] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:08:53,071 [Thread-176] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:08:53,067 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:08:53,067 [Thread-153] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:08:53,071 [Thread-209] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:53,067 [Thread-130] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:08:53,073 [Thread-209] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 10089@f8287aaf0779
2020-04-02 05:08:53,073 [Thread-130] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:08:53,073 [Thread-209] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 870746973. Formatting...
2020-04-02 05:08:53,073 [Thread-107] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:08:53,077 [Thread-107] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:08:53,079 [Thread-209] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-57d3a558-2677-4860-b211-26930cea2ac4 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-04-02 05:08:53,079 [Thread-107] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:53,080 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:53,080 [Thread-226] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:08:53,081 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:53,082 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:53,074 [Thread-130] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:08:53,082 [Thread-130] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:53,082 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:53,083 [Thread-227] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:08:53,080 [Thread-225] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:08:53,078 [Thread-176] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:08:53,078 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:08:53,084 [Thread-176] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:08:53,084 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:08:53,078 [Thread-153] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:08:53,078 [Thread-84] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:08:53,087 [Thread-153] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:08:53,087 [Thread-209] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 10089@f8287aaf0779
2020-04-02 05:08:53,084 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:53,083 [Thread-228] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:08:53,126 [Thread-209] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 870746973. Formatting...
2020-04-02 05:08:53,087 [Thread-84] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:08:53,133 [Thread-176] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:53,133 [Thread-84] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:08:53,133 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:53,134 [Thread-209] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-52fa7b3d-3f2c-4afb-8e3c-b713e4545d8d for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-04-02 05:08:53,134 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:53,134 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:53,135 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:53,135 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 45504
2020-04-02 05:08:53,136 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:53,140 [Thread-229] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-04-02 05:08:53,185 [Thread-232] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-04-02 05:08:53,213 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:53,227 [Thread-236] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:08:53,233 [Thread-230] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:08:53,224 [Thread-209] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:53,224 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5003041b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:53,239 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@16fb356{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:53,222 [Thread-153] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:53,259 [Thread-209] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:53,233 [Thread-235] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:08:53,227 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:08:53,304 [Thread-209] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-1781155512-172.17.0.11-1585804127366 is not formatted. Formatting ...
2020-04-02 05:08:53,304 [Thread-209] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1781155512-172.17.0.11-1585804127366 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1781155512-172.17.0.11-1585804127366/current
2020-04-02 05:08:53,300 [Thread-241] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-04-02 05:08:53,294 [Thread-232] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1781155512-172.17.0.11-1585804127366 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 109ms
2020-04-02 05:08:53,305 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@514eedd8{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:53,307 [Thread-247] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-04-02 05:08:53,339 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@617fe9e1{HTTP/1.1,[http/1.1]}{localhost:45504}
2020-04-02 05:08:53,340 [main] INFO  server.Server (Server.java:doStart(419)) - Started @8354ms
2020-04-02 05:08:53,369 [Thread-209] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:53,369 [Thread-209] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:53,369 [Thread-209] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-1781155512-172.17.0.11-1585804127366 is not formatted. Formatting ...
2020-04-02 05:08:53,369 [Thread-209] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1781155512-172.17.0.11-1585804127366 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1781155512-172.17.0.11-1585804127366/current
2020-04-02 05:08:53,373 [Thread-209] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=870746973;bpid=BP-1781155512-172.17.0.11-1585804127366;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=870746973;c=1585804127366;bpid=BP-1781155512-172.17.0.11-1585804127366;dnuuid=null
2020-04-02 05:08:53,375 [Thread-209] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 31f7c920-c39d-4ae7-b315-1227a3caafd0
2020-04-02 05:08:53,378 [Thread-229] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1781155512-172.17.0.11-1585804127366 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 238ms
2020-04-02 05:08:53,378 [Thread-176] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1781155512-172.17.0.11-1585804127366: 245ms
2020-04-02 05:08:53,381 [Thread-252] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-04-02 05:08:53,381 [Thread-252] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1781155512-172.17.0.11-1585804127366/current/replicas doesn't exist 
2020-04-02 05:08:53,382 [Thread-253] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-04-02 05:08:53,384 [Thread-252] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 3ms
2020-04-02 05:08:53,387 [Thread-226] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1781155512-172.17.0.11-1585804127366 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 306ms
2020-04-02 05:08:53,389 [Thread-209] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-57d3a558-2677-4860-b211-26930cea2ac4
2020-04-02 05:08:53,401 [Thread-209] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-04-02 05:08:53,382 [Thread-253] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1781155512-172.17.0.11-1585804127366/current/replicas doesn't exist 
2020-04-02 05:08:53,406 [Thread-253] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 24ms
2020-04-02 05:08:53,407 [Thread-176] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366: 27ms
2020-04-02 05:08:53,408 [Thread-209] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-52fa7b3d-3f2c-4afb-8e3c-b713e4545d8d
2020-04-02 05:08:53,411 [Thread-209] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-04-02 05:08:53,422 [Thread-209] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:53,424 [Thread-209] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:08:53,451 [Thread-209] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:08:53,452 [Thread-209] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:08:53,452 [Thread-209] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:08:53,465 [Thread-209] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:53,466 [Thread-256] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-04-02 05:08:53,467 [Thread-257] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-04-02 05:08:53,523 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:08:53,526 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-8ed92d4e-a113-43e3-89fc-e65f907cbe5e): finished scanning block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:53,598 [Thread-228] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1781155512-172.17.0.11-1585804127366 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 467ms
2020-04-02 05:08:53,593 [Thread-235] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1781155512-172.17.0.11-1585804127366 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 292ms
2020-04-02 05:08:53,564 [Thread-176] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:00 AM with interval of 21600000ms
2020-04-02 05:08:53,563 [Thread-225] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1781155512-172.17.0.11-1585804127366 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 479ms
2020-04-02 05:08:53,525 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:08:53,664 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-cd20bec6-61af-4cee-a017-bfc56735fa58): finished scanning block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:53,665 [Thread-236] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1781155512-172.17.0.11-1585804127366 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 438ms
2020-04-02 05:08:53,666 [Thread-107] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1781155512-172.17.0.11-1585804127366: 586ms
2020-04-02 05:08:53,654 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1781155512-172.17.0.11-1585804127366 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 351ms
2020-04-02 05:08:53,648 [Thread-247] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1781155512-172.17.0.11-1585804127366 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 303ms
2020-04-02 05:08:53,640 [Thread-241] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1781155512-172.17.0.11-1585804127366 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 335ms
2020-04-02 05:08:53,639 [Thread-227] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1781155512-172.17.0.11-1585804127366 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 556ms
2020-04-02 05:08:53,667 [Thread-130] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1781155512-172.17.0.11-1585804127366: 584ms
2020-04-02 05:08:53,666 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:08:53,666 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:08:53,667 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1781155512-172.17.0.11-1585804127366: 442ms
2020-04-02 05:08:53,667 [Thread-264] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1781155512-172.17.0.11-1585804127366/current/replicas doesn't exist 
2020-04-02 05:08:53,668 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:08:53,668 [Thread-263] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1781155512-172.17.0.11-1585804127366/current/replicas doesn't exist 
2020-04-02 05:08:53,668 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 2ms
2020-04-02 05:08:53,668 [Thread-266] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1781155512-172.17.0.11-1585804127366/current/replicas doesn't exist 
2020-04-02 05:08:53,670 [Thread-230] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1781155512-172.17.0.11-1585804127366 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 436ms
2020-04-02 05:08:53,671 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1781155512-172.17.0.11-1585804127366: 537ms
2020-04-02 05:08:53,674 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37146
2020-04-02 05:08:53,732 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0) service to localhost/127.0.0.1:41191 beginning handshake with NN
2020-04-02 05:08:53,733 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1781155512-172.17.0.11-1585804127366: 467ms
2020-04-02 05:08:53,733 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:08:53,734 [Thread-265] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1781155512-172.17.0.11-1585804127366/current/replicas doesn't exist 
2020-04-02 05:08:53,734 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 11ms
2020-04-02 05:08:53,758 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:08:53,758 [Thread-267] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1781155512-172.17.0.11-1585804127366/current/replicas doesn't exist 
2020-04-02 05:08:53,759 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 1ms
2020-04-02 05:08:53,765 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:08:53,765 [Thread-268] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1781155512-172.17.0.11-1585804127366/current/replicas doesn't exist 
2020-04-02 05:08:53,767 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 99ms
2020-04-02 05:08:53,767 [Thread-107] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366: 101ms
2020-04-02 05:08:53,769 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:08:53,769 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-74648b74-08f4-4ca5-a128-e9784b6b21d8): finished scanning block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:53,773 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:53,773 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:53,773 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:53,774 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:08:53,774 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-473eb806-1eb7-4944-8753-5f4b73aff970): finished scanning block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:53,774 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1cf2fed4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:53,778 [Socket Reader #1 for port 37392] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37392
2020-04-02 05:08:53,781 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:08:53,782 [Thread-269] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1781155512-172.17.0.11-1585804127366/current/replicas doesn't exist 
2020-04-02 05:08:53,783 [Thread-275] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:08:53,783 [Thread-275] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1781155512-172.17.0.11-1585804127366/current/replicas doesn't exist 
2020-04-02 05:08:53,783 [Thread-275] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 0ms
2020-04-02 05:08:53,789 [Thread-256] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1781155512-172.17.0.11-1585804127366 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 323ms
2020-04-02 05:08:53,790 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 50ms
2020-04-02 05:08:53,796 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-04-02 05:08:53,797 [Thread-277] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-04-02 05:08:53,797 [Thread-271] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1781155512-172.17.0.11-1585804127366/current/replicas doesn't exist 
2020-04-02 05:08:53,797 [Thread-277] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1781155512-172.17.0.11-1585804127366/current/replicas doesn't exist 
2020-04-02 05:08:53,798 [Thread-277] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 1ms
2020-04-02 05:08:53,798 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 1ms
2020-04-02 05:08:53,798 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 16ms
2020-04-02 05:08:53,800 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:37392
2020-04-02 05:08:53,802 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 37ms
2020-04-02 05:08:53,802 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366: 135ms
2020-04-02 05:08:53,803 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:08:53,803 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-0a0c2452-7424-4ea5-a7af-8c6055bbad34): finished scanning block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:53,805 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:08:53,806 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-74648b74-08f4-4ca5-a128-e9784b6b21d8): no suitable block pools found to scan.  Waiting 1814399961 ms.
2020-04-02 05:08:53,806 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-c37ee172-cb9b-4f05-84aa-bcebbe58c663): finished scanning block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:53,806 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-8ed92d4e-a113-43e3-89fc-e65f907cbe5e): no suitable block pools found to scan.  Waiting 1814399716 ms.
2020-04-02 05:08:53,807 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-cd20bec6-61af-4cee-a017-bfc56735fa58): no suitable block pools found to scan.  Waiting 1814399715 ms.
2020-04-02 05:08:53,807 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-0a0c2452-7424-4ea5-a7af-8c6055bbad34): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:08:53,807 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-c37ee172-cb9b-4f05-84aa-bcebbe58c663): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:08:53,815 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366: 82ms
2020-04-02 05:08:53,821 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:08:53,822 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-d9137667-94c0-4dee-b215-ab45ce9137b2): finished scanning block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:53,823 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-d9137667-94c0-4dee-b215-ab45ce9137b2): no suitable block pools found to scan.  Waiting 1814399993 ms.
2020-04-02 05:08:53,834 [Thread-130] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366: 167ms
2020-04-02 05:08:53,834 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-473eb806-1eb7-4944-8753-5f4b73aff970): no suitable block pools found to scan.  Waiting 1814399933 ms.
2020-04-02 05:08:53,835 [Thread-130] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:09 AM with interval of 21600000ms
2020-04-02 05:08:53,835 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:08:53,836 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-bd9fc205-c45f-48b9-85ed-311ae68dcf33): finished scanning block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:53,837 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-bd9fc205-c45f-48b9-85ed-311ae68dcf33): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-04-02 05:08:53,837 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366: 164ms
2020-04-02 05:08:53,838 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:11 AM with interval of 21600000ms
2020-04-02 05:08:53,839 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:08:53,839 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-c5dfe81d-cd58-425d-bfae-86f08d014c3b): finished scanning block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:53,840 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-c5dfe81d-cd58-425d-bfae-86f08d014c3b): no suitable block pools found to scan.  Waiting 1814399976 ms.
2020-04-02 05:08:53,812 [Thread-84] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:14 AM with interval of 21600000ms
2020-04-02 05:08:53,841 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:08:53,850 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:08:53,850 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-244b1c01-4b44-4923-8631-0dc549a7ddde): finished scanning block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:53,851 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:08:53,851 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-2078a8cc-9828-4e10-96be-f8b4239ff4fe): finished scanning block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:53,851 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-244b1c01-4b44-4923-8631-0dc549a7ddde): no suitable block pools found to scan.  Waiting 1814399987 ms.
2020-04-02 05:08:53,851 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-2078a8cc-9828-4e10-96be-f8b4239ff4fe): no suitable block pools found to scan.  Waiting 1814399987 ms.
2020-04-02 05:08:53,866 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-a691264e-7ef4-4189-b9ec-6f397eff2bb2): finished scanning block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:53,867 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-a691264e-7ef4-4189-b9ec-6f397eff2bb2): no suitable block pools found to scan.  Waiting 1814399967 ms.
2020-04-02 05:08:53,816 [Thread-153] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:04 AM with interval of 21600000ms
2020-04-02 05:08:53,816 [Thread-107] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:37 AM with interval of 21600000ms
2020-04-02 05:08:53,868 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid ca9828e1-172e-4a2c-a1a8-917b3485899c) service to localhost/127.0.0.1:41191 beginning handshake with NN
2020-04-02 05:08:53,898 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid 690f7552-c4c3-4286-845f-64b6525bf551) service to localhost/127.0.0.1:41191 beginning handshake with NN
2020-04-02 05:08:53,902 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid 30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c) service to localhost/127.0.0.1:41191 beginning handshake with NN
2020-04-02 05:08:53,903 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid f1177179-f009-4517-a835-ba14c97e85ff) service to localhost/127.0.0.1:41191 beginning handshake with NN
2020-04-02 05:08:53,903 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid 138c0d7d-7e58-4339-8b75-15c135daf76d) service to localhost/127.0.0.1:41191 beginning handshake with NN
2020-04-02 05:08:53,904 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:53,905 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:53,905 [Thread-294] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41191 starting to offer service
2020-04-02 05:08:53,907 [IPC Server handler 7 on 41191] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) storage fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0
2020-04-02 05:08:53,909 [IPC Server handler 7 on 41191] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38003
2020-04-02 05:08:53,910 [Thread-257] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1781155512-172.17.0.11-1585804127366 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 443ms
2020-04-02 05:08:53,910 [Thread-209] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1781155512-172.17.0.11-1585804127366: 445ms
2020-04-02 05:08:53,913 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:53,913 [IPC Server listener on 37392] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37392: starting
2020-04-02 05:08:53,915 [IPC Server handler 7 on 41191] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0 (127.0.0.1:38003).
2020-04-02 05:08:53,976 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 37392 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:53,977 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:08:53,977 [IPC Server handler 9 on 41191] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41818, datanodeUuid=138c0d7d-7e58-4339-8b75-15c135daf76d, infoPort=42795, infoSecurePort=0, ipcPort=43620, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) storage 138c0d7d-7e58-4339-8b75-15c135daf76d
2020-04-02 05:08:53,977 [IPC Server handler 9 on 41191] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41818
2020-04-02 05:08:53,978 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:08:53,978 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:08:53,978 [IPC Server handler 9 on 41191] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 138c0d7d-7e58-4339-8b75-15c135daf76d (127.0.0.1:41818).
2020-04-02 05:08:54,000 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0) service to localhost/127.0.0.1:41191 successfully registered with NN
2020-04-02 05:08:54,001 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:41191 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:54,002 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid 138c0d7d-7e58-4339-8b75-15c135daf76d) service to localhost/127.0.0.1:41191 successfully registered with NN
2020-04-02 05:08:54,002 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:41191 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:54,010 [Thread-295] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-04-02 05:08:54,010 [Thread-295] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1781155512-172.17.0.11-1585804127366/current/replicas doesn't exist 
2020-04-02 05:08:54,024 [Thread-295] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 14ms
2020-04-02 05:08:54,024 [IPC Server handler 1 on 41191] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33488, datanodeUuid=f1177179-f009-4517-a835-ba14c97e85ff, infoPort=42409, infoSecurePort=0, ipcPort=46631, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) storage f1177179-f009-4517-a835-ba14c97e85ff
2020-04-02 05:08:54,034 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:54,034 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:54,035 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:54,035 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:54,036 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:54,037 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:54,037 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:54,038 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:33931
2020-04-02 05:08:54,038 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:54,038 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:54,025 [Thread-306] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-04-02 05:08:54,034 [IPC Server handler 1 on 41191] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33488
2020-04-02 05:08:54,041 [IPC Server handler 1 on 41191] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f1177179-f009-4517-a835-ba14c97e85ff (127.0.0.1:33488).
2020-04-02 05:08:54,042 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:54,043 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid f1177179-f009-4517-a835-ba14c97e85ff) service to localhost/127.0.0.1:41191 successfully registered with NN
2020-04-02 05:08:54,043 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:41191 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:54,044 [Thread-306] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1781155512-172.17.0.11-1585804127366/current/replicas doesn't exist 
2020-04-02 05:08:54,044 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:54,046 [Thread-306] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 2ms
2020-04-02 05:08:54,046 [Thread-209] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366: 135ms
2020-04-02 05:08:54,048 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:54,048 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:54,049 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:08:54,049 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-52fa7b3d-3f2c-4afb-8e3c-b713e4545d8d): finished scanning block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:54,049 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:08:54,063 [Thread-209] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:40 AM with interval of 21600000ms
2020-04-02 05:08:54,064 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-52fa7b3d-3f2c-4afb-8e3c-b713e4545d8d): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-04-02 05:08:54,065 [IPC Server handler 4 on 41191] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45517, datanodeUuid=30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, infoPort=41207, infoSecurePort=0, ipcPort=44568, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) storage 30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c
2020-04-02 05:08:54,066 [IPC Server handler 4 on 41191] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45517
2020-04-02 05:08:54,066 [IPC Server handler 4 on 41191] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c (127.0.0.1:45517).
2020-04-02 05:08:54,067 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid 30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c) service to localhost/127.0.0.1:41191 successfully registered with NN
2020-04-02 05:08:54,067 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:41191 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:54,069 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-57d3a558-2677-4860-b211-26930cea2ac4): finished scanning block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:54,070 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-57d3a558-2677-4860-b211-26930cea2ac4): no suitable block pools found to scan.  Waiting 1814399977 ms.
2020-04-02 05:08:54,070 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:54,071 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:54,071 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:54,071 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:54,072 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33576
2020-04-02 05:08:54,072 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:54,088 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1494b84d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:54,089 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@71a9b4c7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:54,095 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@22c01ab0{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:54,095 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@411341bd{HTTP/1.1,[http/1.1]}{localhost:33576}
2020-04-02 05:08:54,096 [main] INFO  server.Server (Server.java:doStart(419)) - Started @9110ms
2020-04-02 05:08:54,101 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid 31f7c920-c39d-4ae7-b315-1227a3caafd0) service to localhost/127.0.0.1:41191 beginning handshake with NN
2020-04-02 05:08:54,101 [IPC Server handler 2 on 41191] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) storage ca9828e1-172e-4a2c-a1a8-917b3485899c
2020-04-02 05:08:54,104 [IPC Server handler 2 on 41191] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39776
2020-04-02 05:08:54,105 [IPC Server handler 2 on 41191] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ca9828e1-172e-4a2c-a1a8-917b3485899c (127.0.0.1:39776).
2020-04-02 05:08:54,105 [IPC Server handler 0 on 41191] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34596, datanodeUuid=690f7552-c4c3-4286-845f-64b6525bf551, infoPort=44049, infoSecurePort=0, ipcPort=36235, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) storage 690f7552-c4c3-4286-845f-64b6525bf551
2020-04-02 05:08:54,105 [IPC Server handler 0 on 41191] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34596
2020-04-02 05:08:54,105 [IPC Server handler 0 on 41191] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 690f7552-c4c3-4286-845f-64b6525bf551 (127.0.0.1:34596).
2020-04-02 05:08:54,109 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid ca9828e1-172e-4a2c-a1a8-917b3485899c) service to localhost/127.0.0.1:41191 successfully registered with NN
2020-04-02 05:08:54,110 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:41191 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:54,111 [IPC Server handler 3 on 41191] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45304, datanodeUuid=31f7c920-c39d-4ae7-b315-1227a3caafd0, infoPort=37250, infoSecurePort=0, ipcPort=45067, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) storage 31f7c920-c39d-4ae7-b315-1227a3caafd0
2020-04-02 05:08:54,129 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid 690f7552-c4c3-4286-845f-64b6525bf551) service to localhost/127.0.0.1:41191 successfully registered with NN
2020-04-02 05:08:54,133 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:41191 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:54,134 [Thread-294] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41191
2020-04-02 05:08:54,140 [IPC Server handler 3 on 41191] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45304
2020-04-02 05:08:54,140 [IPC Server handler 3 on 41191] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 31f7c920-c39d-4ae7-b315-1227a3caafd0 (127.0.0.1:45304).
2020-04-02 05:08:54,141 [Thread-294] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:54,146 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid 31f7c920-c39d-4ae7-b315-1227a3caafd0) service to localhost/127.0.0.1:41191 successfully registered with NN
2020-04-02 05:08:54,146 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:41191 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:54,153 [Thread-294] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 10089@f8287aaf0779
2020-04-02 05:08:54,155 [IPC Server handler 6 on 41191] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-473eb806-1eb7-4944-8753-5f4b73aff970 for DN 127.0.0.1:33488
2020-04-02 05:08:54,156 [IPC Server handler 6 on 41191] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-74648b74-08f4-4ca5-a128-e9784b6b21d8 for DN 127.0.0.1:33488
2020-04-02 05:08:54,158 [Thread-294] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 870746973. Formatting...
2020-04-02 05:08:54,158 [Thread-294] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f29fcc8c-4f45-47a4-addd-01231a8988bd for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-04-02 05:08:54,171 [Thread-294] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 10089@f8287aaf0779
2020-04-02 05:08:54,172 [Thread-294] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 870746973. Formatting...
2020-04-02 05:08:54,172 [Thread-294] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-94f6e665-b2d5-46c4-969f-c9b2db0add83 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-04-02 05:08:54,185 [IPC Server handler 5 on 41191] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-57d3a558-2677-4860-b211-26930cea2ac4 for DN 127.0.0.1:45304
2020-04-02 05:08:54,198 [IPC Server handler 5 on 41191] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-52fa7b3d-3f2c-4afb-8e3c-b713e4545d8d for DN 127.0.0.1:45304
2020-04-02 05:08:54,207 [IPC Server handler 7 on 41191] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c5dfe81d-cd58-425d-bfae-86f08d014c3b for DN 127.0.0.1:41818
2020-04-02 05:08:54,208 [IPC Server handler 7 on 41191] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d9137667-94c0-4dee-b215-ab45ce9137b2 for DN 127.0.0.1:41818
2020-04-02 05:08:54,222 [IPC Server handler 1 on 41191] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0a0c2452-7424-4ea5-a7af-8c6055bbad34 for DN 127.0.0.1:39776
2020-04-02 05:08:54,222 [IPC Server handler 1 on 41191] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c37ee172-cb9b-4f05-84aa-bcebbe58c663 for DN 127.0.0.1:39776
2020-04-02 05:08:54,233 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45217
2020-04-02 05:08:54,234 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:54,234 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:54,256 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5400db36] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:54,263 [Thread-294] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:54,264 [Thread-294] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:54,264 [Thread-294] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-1781155512-172.17.0.11-1585804127366 is not formatted. Formatting ...
2020-04-02 05:08:54,264 [Thread-294] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1781155512-172.17.0.11-1585804127366 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1781155512-172.17.0.11-1585804127366/current
2020-04-02 05:08:54,272 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:54,301 [Socket Reader #1 for port 38205] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38205
2020-04-02 05:08:54,302 [IPC Server handler 9 on 41191] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bd9fc205-c45f-48b9-85ed-311ae68dcf33 for DN 127.0.0.1:45517
2020-04-02 05:08:54,302 [IPC Server handler 9 on 41191] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a691264e-7ef4-4189-b9ec-6f397eff2bb2 for DN 127.0.0.1:45517
2020-04-02 05:08:54,327 [IPC Server handler 0 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:41818, datanodeUuid=138c0d7d-7e58-4339-8b75-15c135daf76d, infoPort=42795, infoSecurePort=0, ipcPort=43620, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366), reports.length=2
2020-04-02 05:08:54,330 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:38205
2020-04-02 05:08:54,350 [IPC Server handler 4 on 41191] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2078a8cc-9828-4e10-96be-f8b4239ff4fe for DN 127.0.0.1:34596
2020-04-02 05:08:54,350 [IPC Server handler 4 on 41191] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-244b1c01-4b44-4923-8631-0dc549a7ddde for DN 127.0.0.1:34596
2020-04-02 05:08:54,359 [Thread-294] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:54,359 [Thread-294] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:54,359 [Thread-294] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-1781155512-172.17.0.11-1585804127366 is not formatted. Formatting ...
2020-04-02 05:08:54,359 [Thread-294] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1781155512-172.17.0.11-1585804127366 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1781155512-172.17.0.11-1585804127366/current
2020-04-02 05:08:54,361 [IPC Server handler 8 on 41191] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-cd20bec6-61af-4cee-a017-bfc56735fa58 for DN 127.0.0.1:38003
2020-04-02 05:08:54,368 [Thread-294] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=870746973;bpid=BP-1781155512-172.17.0.11-1585804127366;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=870746973;c=1585804127366;bpid=BP-1781155512-172.17.0.11-1585804127366;dnuuid=null
2020-04-02 05:08:54,371 [IPC Server handler 8 on 41191] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8ed92d4e-a113-43e3-89fc-e65f907cbe5e for DN 127.0.0.1:38003
2020-04-02 05:08:54,372 [IPC Server handler 8 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:45517, datanodeUuid=30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, infoPort=41207, infoSecurePort=0, ipcPort=44568, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366), reports.length=2
2020-04-02 05:08:54,373 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xfce8c7d3f8c47ae1: Processing first storage report for DS-d9137667-94c0-4dee-b215-ab45ce9137b2 from datanode 138c0d7d-7e58-4339-8b75-15c135daf76d
2020-04-02 05:08:54,373 [Thread-294] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 3d038cc2-f80f-4a72-8c2c-febccfb87908
2020-04-02 05:08:54,375 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xfce8c7d3f8c47ae1: from storage DS-d9137667-94c0-4dee-b215-ab45ce9137b2 node DatanodeRegistration(127.0.0.1:41818, datanodeUuid=138c0d7d-7e58-4339-8b75-15c135daf76d, infoPort=42795, infoSecurePort=0, ipcPort=43620, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:08:54,375 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x40b5f26b10b6526b: Processing first storage report for DS-bd9fc205-c45f-48b9-85ed-311ae68dcf33 from datanode 30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c
2020-04-02 05:08:54,375 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x40b5f26b10b6526b: from storage DS-bd9fc205-c45f-48b9-85ed-311ae68dcf33 node DatanodeRegistration(127.0.0.1:45517, datanodeUuid=30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, infoPort=41207, infoSecurePort=0, ipcPort=44568, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:54,381 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:54,383 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xfce8c7d3f8c47ae1: Processing first storage report for DS-c5dfe81d-cd58-425d-bfae-86f08d014c3b from datanode 138c0d7d-7e58-4339-8b75-15c135daf76d
2020-04-02 05:08:54,383 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xfce8c7d3f8c47ae1: from storage DS-c5dfe81d-cd58-425d-bfae-86f08d014c3b node DatanodeRegistration(127.0.0.1:41818, datanodeUuid=138c0d7d-7e58-4339-8b75-15c135daf76d, infoPort=42795, infoSecurePort=0, ipcPort=43620, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:54,383 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x40b5f26b10b6526b: Processing first storage report for DS-a691264e-7ef4-4189-b9ec-6f397eff2bb2 from datanode 30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c
2020-04-02 05:08:54,384 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x40b5f26b10b6526b: from storage DS-a691264e-7ef4-4189-b9ec-6f397eff2bb2 node DatanodeRegistration(127.0.0.1:45517, datanodeUuid=30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, infoPort=41207, infoSecurePort=0, ipcPort=44568, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:54,385 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:54,385 [IPC Server handler 0 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xfce8c7d3f8c47ae1
2020-04-02 05:08:54,386 [IPC Server handler 3 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:45304, datanodeUuid=31f7c920-c39d-4ae7-b315-1227a3caafd0, infoPort=37250, infoSecurePort=0, ipcPort=45067, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366), reports.length=2
2020-04-02 05:08:54,387 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xaec64df48d23d98c: Processing first storage report for DS-57d3a558-2677-4860-b211-26930cea2ac4 from datanode 31f7c920-c39d-4ae7-b315-1227a3caafd0
2020-04-02 05:08:54,387 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xaec64df48d23d98c: from storage DS-57d3a558-2677-4860-b211-26930cea2ac4 node DatanodeRegistration(127.0.0.1:45304, datanodeUuid=31f7c920-c39d-4ae7-b315-1227a3caafd0, infoPort=37250, infoSecurePort=0, ipcPort=45067, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:54,387 [IPC Server handler 5 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:33488, datanodeUuid=f1177179-f009-4517-a835-ba14c97e85ff, infoPort=42409, infoSecurePort=0, ipcPort=46631, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366), reports.length=2
2020-04-02 05:08:54,387 [IPC Server handler 6 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:34596, datanodeUuid=690f7552-c4c3-4286-845f-64b6525bf551, infoPort=44049, infoSecurePort=0, ipcPort=36235, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366), reports.length=2
2020-04-02 05:08:54,388 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x9c256f3b360d05d7: Processing first storage report for DS-473eb806-1eb7-4944-8753-5f4b73aff970 from datanode f1177179-f009-4517-a835-ba14c97e85ff
2020-04-02 05:08:54,388 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x9c256f3b360d05d7: from storage DS-473eb806-1eb7-4944-8753-5f4b73aff970 node DatanodeRegistration(127.0.0.1:33488, datanodeUuid=f1177179-f009-4517-a835-ba14c97e85ff, infoPort=42409, infoSecurePort=0, ipcPort=46631, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:54,388 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xaec64df48d23d98c: Processing first storage report for DS-52fa7b3d-3f2c-4afb-8e3c-b713e4545d8d from datanode 31f7c920-c39d-4ae7-b315-1227a3caafd0
2020-04-02 05:08:54,388 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xaec64df48d23d98c: from storage DS-52fa7b3d-3f2c-4afb-8e3c-b713e4545d8d node DatanodeRegistration(127.0.0.1:45304, datanodeUuid=31f7c920-c39d-4ae7-b315-1227a3caafd0, infoPort=37250, infoSecurePort=0, ipcPort=45067, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:54,388 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x60286082ddae49c4: Processing first storage report for DS-244b1c01-4b44-4923-8631-0dc549a7ddde from datanode 690f7552-c4c3-4286-845f-64b6525bf551
2020-04-02 05:08:54,388 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x60286082ddae49c4: from storage DS-244b1c01-4b44-4923-8631-0dc549a7ddde node DatanodeRegistration(127.0.0.1:34596, datanodeUuid=690f7552-c4c3-4286-845f-64b6525bf551, infoPort=44049, infoSecurePort=0, ipcPort=36235, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:54,388 [IPC Server handler 3 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xaec64df48d23d98c
2020-04-02 05:08:54,387 [IPC Server handler 7 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366), reports.length=2
2020-04-02 05:08:54,388 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x60286082ddae49c4: Processing first storage report for DS-2078a8cc-9828-4e10-96be-f8b4239ff4fe from datanode 690f7552-c4c3-4286-845f-64b6525bf551
2020-04-02 05:08:54,389 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x60286082ddae49c4: from storage DS-2078a8cc-9828-4e10-96be-f8b4239ff4fe node DatanodeRegistration(127.0.0.1:34596, datanodeUuid=690f7552-c4c3-4286-845f-64b6525bf551, infoPort=44049, infoSecurePort=0, ipcPort=36235, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:54,391 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x9c256f3b360d05d7: Processing first storage report for DS-74648b74-08f4-4ca5-a128-e9784b6b21d8 from datanode f1177179-f009-4517-a835-ba14c97e85ff
2020-04-02 05:08:54,395 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x9c256f3b360d05d7: from storage DS-74648b74-08f4-4ca5-a128-e9784b6b21d8 node DatanodeRegistration(127.0.0.1:33488, datanodeUuid=f1177179-f009-4517-a835-ba14c97e85ff, infoPort=42409, infoSecurePort=0, ipcPort=46631, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366), blocks: 0, hasStaleStorage: false, processing time: 4 msecs, invalidatedBlocks: 0
2020-04-02 05:08:54,395 [IPC Server handler 5 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x9c256f3b360d05d7
2020-04-02 05:08:54,395 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xabcad57f84b81dc2: Processing first storage report for DS-c37ee172-cb9b-4f05-84aa-bcebbe58c663 from datanode ca9828e1-172e-4a2c-a1a8-917b3485899c
2020-04-02 05:08:54,396 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xabcad57f84b81dc2: from storage DS-c37ee172-cb9b-4f05-84aa-bcebbe58c663 node DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:54,396 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xabcad57f84b81dc2: Processing first storage report for DS-0a0c2452-7424-4ea5-a7af-8c6055bbad34 from datanode ca9828e1-172e-4a2c-a1a8-917b3485899c
2020-04-02 05:08:54,396 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xabcad57f84b81dc2: from storage DS-0a0c2452-7424-4ea5-a7af-8c6055bbad34 node DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:54,396 [IPC Server handler 7 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xabcad57f84b81dc2
2020-04-02 05:08:54,407 [Thread-322] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41191 starting to offer service
2020-04-02 05:08:54,414 [IPC Server handler 6 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x60286082ddae49c4
2020-04-02 05:08:54,417 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:54,417 [IPC Server listener on 38205] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38205: starting
2020-04-02 05:08:54,439 [IPC Server handler 8 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x40b5f26b10b6526b
2020-04-02 05:08:54,439 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 38205 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:54,444 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-f29fcc8c-4f45-47a4-addd-01231a8988bd
2020-04-02 05:08:54,447 [Thread-294] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-04-02 05:08:54,485 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-94f6e665-b2d5-46c4-969f-c9b2db0add83
2020-04-02 05:08:54,485 [Thread-294] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-04-02 05:08:54,486 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x60286082ddae49c4,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 118 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:54,487 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:54,487 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xfce8c7d3f8c47ae1,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 245 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:54,487 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:54,487 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xaec64df48d23d98c,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 154 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:54,488 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:54,490 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xabcad57f84b81dc2,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 162 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:54,490 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:54,486 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x9c256f3b360d05d7,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 254 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:54,488 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x40b5f26b10b6526b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 153 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:54,490 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:54,490 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:54,491 [Thread-294] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:54,492 [Thread-294] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:08:54,497 [Thread-294] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:08:54,497 [Thread-294] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:08:54,502 [Thread-294] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:08:54,524 [Thread-322] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41191
2020-04-02 05:08:54,550 [Thread-294] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:54,550 [Thread-335] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-04-02 05:08:54,557 [Thread-322] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:54,558 [Thread-336] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-04-02 05:08:54,565 [Thread-322] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 10089@f8287aaf0779
2020-04-02 05:08:54,565 [Thread-322] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 870746973. Formatting...
2020-04-02 05:08:54,565 [Thread-322] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3f8ec3d4-2938-4c87-90b2-6481f726aa28 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-04-02 05:08:54,633 [Thread-322] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 10089@f8287aaf0779
2020-04-02 05:08:54,634 [Thread-322] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 870746973. Formatting...
2020-04-02 05:08:54,634 [Thread-322] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-653a74b1-1e06-48c8-9fc4-adfe2a024aaf for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-04-02 05:08:54,634 [Thread-335] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1781155512-172.17.0.11-1585804127366 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 84ms
2020-04-02 05:08:54,656 [Thread-322] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:54,658 [Thread-322] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:54,669 [Thread-322] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-1781155512-172.17.0.11-1585804127366 is not formatted. Formatting ...
2020-04-02 05:08:54,670 [Thread-322] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1781155512-172.17.0.11-1585804127366 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1781155512-172.17.0.11-1585804127366/current
2020-04-02 05:08:54,658 [Thread-336] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1781155512-172.17.0.11-1585804127366 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 101ms
2020-04-02 05:08:54,671 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1781155512-172.17.0.11-1585804127366: 121ms
2020-04-02 05:08:54,681 [Thread-339] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-04-02 05:08:54,681 [Thread-339] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1781155512-172.17.0.11-1585804127366/current/replicas doesn't exist 
2020-04-02 05:08:54,682 [Thread-339] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 1ms
2020-04-02 05:08:54,682 [Thread-340] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-04-02 05:08:54,682 [Thread-340] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1781155512-172.17.0.11-1585804127366/current/replicas doesn't exist 
2020-04-02 05:08:54,683 [Thread-340] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 1ms
2020-04-02 05:08:54,683 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366: 2ms
2020-04-02 05:08:54,683 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:08:54,684 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-94f6e665-b2d5-46c4-969f-c9b2db0add83): finished scanning block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:54,684 [Thread-294] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:16 AM with interval of 21600000ms
2020-04-02 05:08:54,684 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:08:54,697 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-94f6e665-b2d5-46c4-969f-c9b2db0add83): no suitable block pools found to scan.  Waiting 1814399986 ms.
2020-04-02 05:08:54,697 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid 3d038cc2-f80f-4a72-8c2c-febccfb87908) service to localhost/127.0.0.1:41191 beginning handshake with NN
2020-04-02 05:08:54,707 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-f29fcc8c-4f45-47a4-addd-01231a8988bd): finished scanning block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:54,720 [IPC Server handler 9 on 41191] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38083, datanodeUuid=3d038cc2-f80f-4a72-8c2c-febccfb87908, infoPort=37146, infoSecurePort=0, ipcPort=37392, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) storage 3d038cc2-f80f-4a72-8c2c-febccfb87908
2020-04-02 05:08:54,721 [IPC Server handler 9 on 41191] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38083
2020-04-02 05:08:54,721 [IPC Server handler 9 on 41191] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3d038cc2-f80f-4a72-8c2c-febccfb87908 (127.0.0.1:38083).
2020-04-02 05:08:54,721 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-f29fcc8c-4f45-47a4-addd-01231a8988bd): no suitable block pools found to scan.  Waiting 1814399962 ms.
2020-04-02 05:08:54,722 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid 3d038cc2-f80f-4a72-8c2c-febccfb87908) service to localhost/127.0.0.1:41191 successfully registered with NN
2020-04-02 05:08:54,722 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:41191 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:54,748 [IPC Server handler 4 on 41191] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f29fcc8c-4f45-47a4-addd-01231a8988bd for DN 127.0.0.1:38083
2020-04-02 05:08:54,748 [IPC Server handler 4 on 41191] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-94f6e665-b2d5-46c4-969f-c9b2db0add83 for DN 127.0.0.1:38083
2020-04-02 05:08:54,766 [Thread-322] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:54,766 [Thread-322] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:54,766 [Thread-322] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-1781155512-172.17.0.11-1585804127366 is not formatted. Formatting ...
2020-04-02 05:08:54,766 [Thread-322] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1781155512-172.17.0.11-1585804127366 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1781155512-172.17.0.11-1585804127366/current
2020-04-02 05:08:54,771 [IPC Server handler 2 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:38083, datanodeUuid=3d038cc2-f80f-4a72-8c2c-febccfb87908, infoPort=37146, infoSecurePort=0, ipcPort=37392, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366), reports.length=2
2020-04-02 05:08:54,771 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xe16c08eb7bea2a2: Processing first storage report for DS-94f6e665-b2d5-46c4-969f-c9b2db0add83 from datanode 3d038cc2-f80f-4a72-8c2c-febccfb87908
2020-04-02 05:08:54,771 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xe16c08eb7bea2a2: from storage DS-94f6e665-b2d5-46c4-969f-c9b2db0add83 node DatanodeRegistration(127.0.0.1:38083, datanodeUuid=3d038cc2-f80f-4a72-8c2c-febccfb87908, infoPort=37146, infoSecurePort=0, ipcPort=37392, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:08:54,772 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xe16c08eb7bea2a2: Processing first storage report for DS-f29fcc8c-4f45-47a4-addd-01231a8988bd from datanode 3d038cc2-f80f-4a72-8c2c-febccfb87908
2020-04-02 05:08:54,772 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xe16c08eb7bea2a2: from storage DS-f29fcc8c-4f45-47a4-addd-01231a8988bd node DatanodeRegistration(127.0.0.1:38083, datanodeUuid=3d038cc2-f80f-4a72-8c2c-febccfb87908, infoPort=37146, infoSecurePort=0, ipcPort=37392, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:54,772 [IPC Server handler 2 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xe16c08eb7bea2a2
2020-04-02 05:08:54,773 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xe16c08eb7bea2a2,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 20 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:54,773 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:54,774 [Thread-322] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=870746973;bpid=BP-1781155512-172.17.0.11-1585804127366;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=870746973;c=1585804127366;bpid=BP-1781155512-172.17.0.11-1585804127366;dnuuid=null
2020-04-02 05:08:54,786 [Thread-322] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 04fa600d-9223-4e33-b0a1-d4242966c7f0
2020-04-02 05:08:54,789 [Thread-322] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-3f8ec3d4-2938-4c87-90b2-6481f726aa28
2020-04-02 05:08:54,790 [Thread-322] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-04-02 05:08:54,792 [Thread-322] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-653a74b1-1e06-48c8-9fc4-adfe2a024aaf
2020-04-02 05:08:54,793 [Thread-322] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-04-02 05:08:54,793 [Thread-322] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:54,809 [Thread-322] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:08:54,816 [Thread-322] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:08:54,816 [Thread-322] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:08:54,816 [Thread-322] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:08:54,821 [Thread-322] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:54,823 [Thread-346] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-04-02 05:08:54,824 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-04-02 05:08:54,925 [Thread-346] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1781155512-172.17.0.11-1585804127366 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 101ms
2020-04-02 05:08:54,929 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1781155512-172.17.0.11-1585804127366 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 105ms
2020-04-02 05:08:54,929 [Thread-322] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1781155512-172.17.0.11-1585804127366: 108ms
2020-04-02 05:08:54,930 [Thread-350] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-04-02 05:08:54,930 [Thread-350] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1781155512-172.17.0.11-1585804127366/current/replicas doesn't exist 
2020-04-02 05:08:54,931 [Thread-350] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 1ms
2020-04-02 05:08:54,930 [Thread-351] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-04-02 05:08:54,936 [Thread-351] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1781155512-172.17.0.11-1585804127366/current/replicas doesn't exist 
2020-04-02 05:08:54,937 [Thread-351] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 1ms
2020-04-02 05:08:54,937 [Thread-322] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1781155512-172.17.0.11-1585804127366: 7ms
2020-04-02 05:08:54,937 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:08:54,937 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1781155512-172.17.0.11-1585804127366 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:08:54,938 [Thread-322] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:49 AM with interval of 21600000ms
2020-04-02 05:08:54,938 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-653a74b1-1e06-48c8-9fc4-adfe2a024aaf): finished scanning block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:54,939 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-653a74b1-1e06-48c8-9fc4-adfe2a024aaf): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:08:54,951 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid 04fa600d-9223-4e33-b0a1-d4242966c7f0) service to localhost/127.0.0.1:41191 beginning handshake with NN
2020-04-02 05:08:54,958 [IPC Server handler 7 on 41191] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33931, datanodeUuid=04fa600d-9223-4e33-b0a1-d4242966c7f0, infoPort=45217, infoSecurePort=0, ipcPort=38205, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) storage 04fa600d-9223-4e33-b0a1-d4242966c7f0
2020-04-02 05:08:54,959 [IPC Server handler 7 on 41191] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33931
2020-04-02 05:08:54,959 [IPC Server handler 7 on 41191] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 04fa600d-9223-4e33-b0a1-d4242966c7f0 (127.0.0.1:33931).
2020-04-02 05:08:54,964 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-3f8ec3d4-2938-4c87-90b2-6481f726aa28): finished scanning block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:54,965 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid 04fa600d-9223-4e33-b0a1-d4242966c7f0) service to localhost/127.0.0.1:41191 successfully registered with NN
2020-04-02 05:08:54,965 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:41191 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:54,965 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-3f8ec3d4-2938-4c87-90b2-6481f726aa28): no suitable block pools found to scan.  Waiting 1814399972 ms.
2020-04-02 05:08:54,978 [IPC Server handler 0 on 41191] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3f8ec3d4-2938-4c87-90b2-6481f726aa28 for DN 127.0.0.1:33931
2020-04-02 05:08:54,978 [IPC Server handler 0 on 41191] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-653a74b1-1e06-48c8-9fc4-adfe2a024aaf for DN 127.0.0.1:33931
2020-04-02 05:08:54,990 [IPC Server handler 8 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:33931, datanodeUuid=04fa600d-9223-4e33-b0a1-d4242966c7f0, infoPort=45217, infoSecurePort=0, ipcPort=38205, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366), reports.length=2
2020-04-02 05:08:54,994 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa4b1ac0d39727c27: Processing first storage report for DS-653a74b1-1e06-48c8-9fc4-adfe2a024aaf from datanode 04fa600d-9223-4e33-b0a1-d4242966c7f0
2020-04-02 05:08:54,994 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa4b1ac0d39727c27: from storage DS-653a74b1-1e06-48c8-9fc4-adfe2a024aaf node DatanodeRegistration(127.0.0.1:33931, datanodeUuid=04fa600d-9223-4e33-b0a1-d4242966c7f0, infoPort=45217, infoSecurePort=0, ipcPort=38205, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:54,994 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa4b1ac0d39727c27: Processing first storage report for DS-3f8ec3d4-2938-4c87-90b2-6481f726aa28 from datanode 04fa600d-9223-4e33-b0a1-d4242966c7f0
2020-04-02 05:08:54,994 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa4b1ac0d39727c27: from storage DS-3f8ec3d4-2938-4c87-90b2-6481f726aa28 node DatanodeRegistration(127.0.0.1:33931, datanodeUuid=04fa600d-9223-4e33-b0a1-d4242966c7f0, infoPort=45217, infoSecurePort=0, ipcPort=38205, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:54,994 [IPC Server handler 8 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xa4b1ac0d39727c27
2020-04-02 05:08:54,995 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xa4b1ac0d39727c27,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 12 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:54,996 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:55,310 [IPC Server handler 3 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:08:55,329 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:08:55,354 [IPC Server handler 5 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-1024k	dst=null	perm=null	proto=rpc
2020-04-02 05:08:55,383 [IPC Server handler 6 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[0]
[msx] unitTestCounterInClass = 0
2020-04-02 05:08:55,396 [Thread-358] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithBlockCorrupted(203)) - testReadWithBlockCorrupted: file = /deleted_1_0, dataBlkDelNum = 1, parityBlkDelNum = 0, deleteBlockFile? true
2020-04-02 05:08:55,511 [IPC Server handler 1 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/deleted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:08:55,530 [IPC Server handler 9 on 41191] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /deleted_1_0 for DFSClient_NONMAPREDUCE_-1389971812_1 at 127.0.0.1
2020-04-02 05:08:55,531 [IPC Server handler 9 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/deleted_1_0, holder=DFSClient_NONMAPREDUCE_-1389971812_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:08:55,545 [IPC Server handler 9 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: deleted_1_0 is added
2020-04-02 05:08:55,547 [IPC Server handler 9 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /deleted_1_0 inode 16386 DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:08:55,556 [IPC Server handler 9 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/deleted_1_0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:55,590 [Thread-358] WARN  erasurecode.ErasureCodeNative (ErasureCodeNative.java:<clinit>(55)) - ISA-L support is not available in your platform... using builtin-java codec where applicable
2020-04-02 05:08:55,786 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:08:56,149 [IPC Server handler 3 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /deleted_1_0  inodeId 16386 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:08:56,153 [IPC Server handler 3 on 41191] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:08:56,159 [IPC Server handler 3 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /deleted_1_0 with blk_-9223372036854775792_1001 block is added to the in-memory file system
2020-04-02 05:08:56,160 [IPC Server handler 3 on 41191] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775792_1001, replicas=127.0.0.1:33931, 127.0.0.1:33488, 127.0.0.1:41818, 127.0.0.1:34596, 127.0.0.1:39776, 127.0.0.1:38083, 127.0.0.1:38003, 127.0.0.1:45304, 127.0.0.1:45517 for /deleted_1_0
2020-04-02 05:08:56,160 [IPC Server handler 3 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /deleted_1_0 with new block blk_-9223372036854775792_1001, current total block count is 1
2020-04-02 05:08:56,433 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:35866 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775792_1001 src: /127.0.0.1:35866 dest: /127.0.0.1:33931
2020-04-02 05:08:56,434 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:41136 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775791_1001 src: /127.0.0.1:41136 dest: /127.0.0.1:33488
2020-04-02 05:08:56,434 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:60628 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775787_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775787_1001 src: /127.0.0.1:60628 dest: /127.0.0.1:38083
2020-04-02 05:08:56,435 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:60538 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001 src: /127.0.0.1:60538 dest: /127.0.0.1:39776
2020-04-02 05:08:56,437 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:35326 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775790_1001 src: /127.0.0.1:35326 dest: /127.0.0.1:41818
2020-04-02 05:08:56,461 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:60698 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775789_1001 src: /127.0.0.1:60698 dest: /127.0.0.1:34596
2020-04-02 05:08:56,804 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:53702 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775786_1001 src: /127.0.0.1:53702 dest: /127.0.0.1:38003
2020-04-02 05:08:56,852 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:59994 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775785_1001 src: /127.0.0.1:59994 dest: /127.0.0.1:45304
2020-04-02 05:08:56,913 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50494 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775784_1001 src: /127.0.0.1:50494 dest: /127.0.0.1:45517
2020-04-02 05:08:57,037 [IPC Server handler 7 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:41818, datanodeUuid=138c0d7d-7e58-4339-8b75-15c135daf76d, infoPort=42795, infoSecurePort=0, ipcPort=43620, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:08:57,038 [IPC Server handler 3 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:08:57,040 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775790_1001 on 127.0.0.1:41818 size 4194304 replicaState = RBW
2020-04-02 05:08:57,040 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:57,040 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775790_1001 is received from 127.0.0.1:41818
2020-04-02 05:08:57,040 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:41818 receiving: 1, received: 0, deleted: 0
2020-04-02 05:08:57,041 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775786_1001 on 127.0.0.1:38003 size 4194304 replicaState = RBW
2020-04-02 05:08:57,041 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:57,041 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775786_1001 is received from 127.0.0.1:38003
2020-04-02 05:08:57,041 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38003 receiving: 1, received: 0, deleted: 0
2020-04-02 05:08:57,044 [IPC Server handler 5 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366), reports.length=2
2020-04-02 05:08:57,044 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x86382032b63e8c6d: Processing first storage report for DS-8ed92d4e-a113-43e3-89fc-e65f907cbe5e from datanode fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0
2020-04-02 05:08:57,044 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x86382032b63e8c6d: from storage DS-8ed92d4e-a113-43e3-89fc-e65f907cbe5e node DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:57,044 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x86382032b63e8c6d: Processing first storage report for DS-cd20bec6-61af-4cee-a017-bfc56735fa58 from datanode fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0
2020-04-02 05:08:57,045 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processFirstBlockReport(2778)) - Initial report of block blk_-9223372036854775786 on 127.0.0.1:38003 size 1032192 replicaState = RBW
2020-04-02 05:08:57,045 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x86382032b63e8c6d: from storage DS-cd20bec6-61af-4cee-a017-bfc56735fa58 node DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:57,045 [IPC Server handler 5 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x86382032b63e8c6d
2020-04-02 05:08:57,050 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x86382032b63e8c6d,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 8 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:57,050 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:08:57,058 [IPC Server handler 1 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33488, datanodeUuid=f1177179-f009-4517-a835-ba14c97e85ff, infoPort=42409, infoSecurePort=0, ipcPort=46631, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:08:57,060 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775791_1001 on 127.0.0.1:33488 size 4194304 replicaState = RBW
2020-04-02 05:08:57,061 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:57,061 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775791_1001 is received from 127.0.0.1:33488
2020-04-02 05:08:57,061 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33488 receiving: 1, received: 0, deleted: 0
2020-04-02 05:08:57,072 [IPC Server handler 4 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45517, datanodeUuid=30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, infoPort=41207, infoSecurePort=0, ipcPort=44568, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:08:57,072 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775784_1001 on 127.0.0.1:45517 size 4194304 replicaState = RBW
2020-04-02 05:08:57,072 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:57,073 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775784_1001 is received from 127.0.0.1:45517
2020-04-02 05:08:57,073 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45517 receiving: 1, received: 0, deleted: 0
2020-04-02 05:08:57,175 [IPC Server handler 7 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34596, datanodeUuid=690f7552-c4c3-4286-845f-64b6525bf551, infoPort=44049, infoSecurePort=0, ipcPort=36235, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:08:57,184 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775789_1001 on 127.0.0.1:34596 size 4194304 replicaState = RBW
2020-04-02 05:08:57,184 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:57,184 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775789_1001 is received from 127.0.0.1:34596
2020-04-02 05:08:57,184 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34596 receiving: 1, received: 0, deleted: 0
2020-04-02 05:08:57,185 [IPC Server handler 3 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:08:57,185 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775788_1001 on 127.0.0.1:39776 size 4194304 replicaState = RBW
2020-04-02 05:08:57,185 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:57,185 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775788_1001 is received from 127.0.0.1:39776
2020-04-02 05:08:57,185 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39776 receiving: 1, received: 0, deleted: 0
2020-04-02 05:08:57,186 [IPC Server handler 5 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45304, datanodeUuid=31f7c920-c39d-4ae7-b315-1227a3caafd0, infoPort=37250, infoSecurePort=0, ipcPort=45067, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:08:57,186 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775785_1001 on 127.0.0.1:45304 size 4194304 replicaState = RBW
2020-04-02 05:08:57,186 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:57,186 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775785_1001 is received from 127.0.0.1:45304
2020-04-02 05:08:57,186 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45304 receiving: 1, received: 0, deleted: 0
2020-04-02 05:08:57,383 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35866, dest: /127.0.0.1:33931, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 04fa600d-9223-4e33-b0a1-d4242966c7f0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775792_1001, duration(ns): 816977110
2020-04-02 05:08:57,383 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:57,385 [IPC Server handler 6 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33931, datanodeUuid=04fa600d-9223-4e33-b0a1-d4242966c7f0, infoPort=45217, infoSecurePort=0, ipcPort=38205, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:08:57,386 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775792_1001 on 127.0.0.1:33931 size 4194304 replicaState = FINALIZED
2020-04-02 05:08:57,386 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:57,388 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33931 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:08:57,390 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775792_1001 is received from 127.0.0.1:33931
2020-04-02 05:08:57,390 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33931 receiving: 0, received: 1, deleted: 0
2020-04-02 05:08:57,395 [IPC Server handler 1 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33488, datanodeUuid=f1177179-f009-4517-a835-ba14c97e85ff, infoPort=42409, infoSecurePort=0, ipcPort=46631, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:08:57,396 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775791_1001 on 127.0.0.1:33488 size 4194304 replicaState = FINALIZED
2020-04-02 05:08:57,396 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:57,396 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33488 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:08:57,396 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775791_1001 is received from 127.0.0.1:33488
2020-04-02 05:08:57,396 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33488 receiving: 0, received: 1, deleted: 0
2020-04-02 05:08:57,393 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41136, dest: /127.0.0.1:33488, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: f1177179-f009-4517-a835-ba14c97e85ff, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775791_1001, duration(ns): 832277540
2020-04-02 05:08:57,398 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:57,406 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35326, dest: /127.0.0.1:41818, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 138c0d7d-7e58-4339-8b75-15c135daf76d, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775790_1001, duration(ns): 839998317
2020-04-02 05:08:57,406 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:57,424 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60698, dest: /127.0.0.1:34596, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 690f7552-c4c3-4286-845f-64b6525bf551, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775789_1001, duration(ns): 862463391
2020-04-02 05:08:57,424 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:57,430 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60538, dest: /127.0.0.1:39776, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: ca9828e1-172e-4a2c-a1a8-917b3485899c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001, duration(ns): 869083250
2020-04-02 05:08:57,430 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:57,431 [IPC Server handler 9 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:41818, datanodeUuid=138c0d7d-7e58-4339-8b75-15c135daf76d, infoPort=42795, infoSecurePort=0, ipcPort=43620, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:08:57,434 [IPC Server handler 2 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:08:57,434 [IPC Server handler 4 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34596, datanodeUuid=690f7552-c4c3-4286-845f-64b6525bf551, infoPort=44049, infoSecurePort=0, ipcPort=36235, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:08:57,434 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775790_1001 on 127.0.0.1:41818 size 4194304 replicaState = FINALIZED
2020-04-02 05:08:57,434 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:57,434 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:41818 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:08:57,434 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775790_1001 is received from 127.0.0.1:41818
2020-04-02 05:08:57,434 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:41818 receiving: 0, received: 1, deleted: 0
2020-04-02 05:08:57,435 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775788_1001 on 127.0.0.1:39776 size 4194304 replicaState = FINALIZED
2020-04-02 05:08:57,435 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:57,435 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39776 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:08:57,435 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775788_1001 is received from 127.0.0.1:39776
2020-04-02 05:08:57,435 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39776 receiving: 0, received: 1, deleted: 0
2020-04-02 05:08:57,435 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775789_1001 on 127.0.0.1:34596 size 4194304 replicaState = FINALIZED
2020-04-02 05:08:57,435 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:57,435 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34596 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:08:57,435 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775789_1001 is received from 127.0.0.1:34596
2020-04-02 05:08:57,435 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34596 receiving: 0, received: 1, deleted: 0
2020-04-02 05:08:57,448 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60628, dest: /127.0.0.1:38083, bytes: 4194181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 3d038cc2-f80f-4a72-8c2c-febccfb87908, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775787_1001, duration(ns): 886994387
2020-04-02 05:08:57,449 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:57,449 [IPC Server handler 0 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38083, datanodeUuid=3d038cc2-f80f-4a72-8c2c-febccfb87908, infoPort=37146, infoSecurePort=0, ipcPort=37392, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:08:57,459 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775787_1001 on 127.0.0.1:38083 size 4194181 replicaState = FINALIZED
2020-04-02 05:08:57,459 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:57,459 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38083 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:08:57,459 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775787_1001 is received from 127.0.0.1:38083
2020-04-02 05:08:57,459 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38083 receiving: 0, received: 1, deleted: 0
2020-04-02 05:08:57,488 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53702, dest: /127.0.0.1:38003, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775786_1001, duration(ns): 670368593
2020-04-02 05:08:57,488 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:57,498 [IPC Server handler 7 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:08:57,504 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775786_1001 on 127.0.0.1:38003 size 4194304 replicaState = FINALIZED
2020-04-02 05:08:57,504 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:57,504 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38003 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:08:57,511 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775786_1001 is received from 127.0.0.1:38003
2020-04-02 05:08:57,511 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38003 receiving: 0, received: 1, deleted: 0
2020-04-02 05:08:57,512 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59994, dest: /127.0.0.1:45304, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 31f7c920-c39d-4ae7-b315-1227a3caafd0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775785_1001, duration(ns): 649577994
2020-04-02 05:08:57,512 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:57,518 [IPC Server handler 8 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45304, datanodeUuid=31f7c920-c39d-4ae7-b315-1227a3caafd0, infoPort=37250, infoSecurePort=0, ipcPort=45067, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:08:57,520 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775785_1001 on 127.0.0.1:45304 size 4194304 replicaState = FINALIZED
2020-04-02 05:08:57,520 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:57,520 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45304 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:08:57,520 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775785_1001 is received from 127.0.0.1:45304
2020-04-02 05:08:57,521 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45304 receiving: 0, received: 1, deleted: 0
2020-04-02 05:08:57,521 [IPC Server handler 3 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45517, datanodeUuid=30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, infoPort=41207, infoSecurePort=0, ipcPort=44568, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:08:57,522 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775784_1001 on 127.0.0.1:45517 size 4194304 replicaState = FINALIZED
2020-04-02 05:08:57,522 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:57,522 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45517 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:08:57,522 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50494, dest: /127.0.0.1:45517, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775784_1001, duration(ns): 602254541
2020-04-02 05:08:57,522 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775784_1001 is received from 127.0.0.1:45517
2020-04-02 05:08:57,522 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45517 receiving: 0, received: 1, deleted: 0
2020-04-02 05:08:57,523 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:57,541 [IPC Server handler 5 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /deleted_1_0 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:08:57,543 [IPC Server handler 5 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /deleted_1_0 with 1 blocks is persisted to the file system
2020-04-02 05:08:57,544 [IPC Server handler 5 on 41191] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /deleted_1_0 is closed by DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:08:57,547 [Thread-358] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(231)) - corruptBlocks on path /deleted_1_0
2020-04-02 05:08:57,557 [IPC Server handler 6 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:08:57,571 [IPC Server handler 6 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:08:57,596 [Thread-358] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(258)) - Deleting block file BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001
2020-04-02 05:08:57,600 [Thread-358] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:08:57,603 [Thread-358] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:deleteData(153)) - Deleting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775788
2020-04-02 05:08:57,605 [Thread-358] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:08:57,606 [Thread-358] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:08:57,606 [Thread-358] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:08:57,610 [Thread-358] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:08:57,614 [Thread-358] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:08:57,615 [Thread-358] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:08:57,622 [Thread-358] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:08:57,623 [Thread-358] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /deleted_1_0
2020-04-02 05:08:57,628 [Thread-358] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /deleted_1_0
2020-04-02 05:08:57,633 [IPC Server handler 1 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/deleted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:08:57,634 [Thread-358] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /deleted_1_0
2020-04-02 05:08:57,638 [IPC Server handler 9 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:08:57,646 [IPC Server handler 4 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:08:57,647 [IPC Server handler 4 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:08:57,828 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:33102 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001]] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775788_1001 replica FinalizedReplica, blk_-9223372036854775788_1001, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775788 for deletion
2020-04-02 05:08:57,831 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775788_1001 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775788
2020-04-02 05:08:57,836 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:33102 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001]] INFO  datanode.DataNode (DataXceiver.java:readBlock(598)) - opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001 received exception java.io.FileNotFoundException: BlockId -9223372036854775788 is not valid.
2020-04-02 05:08:57,838 [Thread-358] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001 received exception java.io.FileNotFoundException: BlockId -9223372036854775788 is not valid., for OP_READ_BLOCK, self=/127.0.0.1:33102, remote=/127.0.0.1:39776, for file /deleted_1_0, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775788_1001
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:08:57,839 [Thread-358] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:39776 for blockBP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001 received exception java.io.FileNotFoundException: BlockId -9223372036854775788 is not valid., for OP_READ_BLOCK, self=/127.0.0.1:33102, remote=/127.0.0.1:39776, for file /deleted_1_0, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775788_1001
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:08:57,841 [IPC Server handler 0 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:08:57,843 [IPC Server handler 0 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:08:57,846 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:33102 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(643)) - DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366):Got exception while serving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001 to /127.0.0.1:33102
java.io.FileNotFoundException: BlockId -9223372036854775788 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:08:57,848 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:33102 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775788_1001]] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:39776:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:33102 dst: /127.0.0.1:39776
java.io.FileNotFoundException: BlockId -9223372036854775788 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:08:57,865 [Thread-358] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:39776,DS-0a0c2452-7424-4ea5-a7af-8c6055bbad34,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:08:58,787 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:09:00,148 [IPC Server handler 5 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:09:00,162 [Block report processor] DEBUG BlockStateChange (BlockManager.java:removeStoredBlock(3781)) - BLOCK* removeStoredBlock: blk_-9223372036854775792_1001 from 127.0.0.1:39776
2020-04-02 05:09:00,164 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 8 curExpectedReplicas 9 oldReplicas 9 oldExpectedReplicas  9 curPri  2 oldPri  3
2020-04-02 05:09:00,164 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 8 replicas and needs 9 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:09:00,170 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block DELETED_BLOCK: blk_-9223372036854775788_1001 is received from 127.0.0.1:39776
2020-04-02 05:09:00,170 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39776 receiving: 0, received: 0, deleted: 1
2020-04-02 05:09:01,792 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:01,792 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-04-02 05:09:04,794 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:04,795 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-04-02 05:09:07,795 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:07,795 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-04-02 05:09:10,810 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:10,811 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-04-02 05:09:13,812 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:13,813 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-04-02 05:09:16,813 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:16,814 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-04-02 05:09:19,814 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:19,815 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-04-02 05:09:20,135 [Thread-358] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /deleted_1_0
2020-04-02 05:09:20,151 [IPC Server handler 2 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:09:20,153 [IPC Server handler 2 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:09:22,815 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:22,815 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-04-02 05:09:24,673 [Thread-358] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /deleted_1_0
2020-04-02 05:09:24,679 [IPC Server handler 4 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:09:24,680 [IPC Server handler 4 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:09:25,874 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:25,874 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-04-02 05:09:28,876 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:28,877 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-04-02 05:09:30,611 [Thread-358] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /deleted_1_0
2020-04-02 05:09:30,616 [IPC Server handler 8 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:09:30,618 [IPC Server handler 8 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:09:31,878 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:31,879 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-04-02 05:09:34,880 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:34,880 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-04-02 05:09:37,881 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:37,882 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[0]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[0]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[1]
[msx] perform reset as unitTestCounterInClass 1 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:38,396 [Thread-436] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithBlockCorrupted(203)) - testReadWithBlockCorrupted: file = /deleted_1_1, dataBlkDelNum = 1, parityBlkDelNum = 1, deleteBlockFile? true
2020-04-02 05:09:38,460 [IPC Server handler 6 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/deleted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:09:38,463 [IPC Server handler 9 on 41191] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /deleted_1_1 for DFSClient_NONMAPREDUCE_-1389971812_1 at 127.0.0.1
2020-04-02 05:09:38,464 [IPC Server handler 9 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/deleted_1_1, holder=DFSClient_NONMAPREDUCE_-1389971812_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:09:38,465 [IPC Server handler 9 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: deleted_1_1 is added
2020-04-02 05:09:38,465 [IPC Server handler 9 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /deleted_1_1 inode 16387 DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:09:38,466 [IPC Server handler 9 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/deleted_1_1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:38,492 [IPC Server handler 5 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /deleted_1_1  inodeId 16387 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:09:38,493 [IPC Server handler 5 on 41191] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:09:38,495 [IPC Server handler 5 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /deleted_1_1 with blk_-9223372036854775776_1002 block is added to the in-memory file system
2020-04-02 05:09:38,495 [IPC Server handler 5 on 41191] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775776_1002, replicas=127.0.0.1:45304, 127.0.0.1:38083, 127.0.0.1:33488, 127.0.0.1:34596, 127.0.0.1:45517, 127.0.0.1:41818, 127.0.0.1:33931, 127.0.0.1:39776, 127.0.0.1:38003 for /deleted_1_1
2020-04-02 05:09:38,496 [IPC Server handler 5 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /deleted_1_1 with new block blk_-9223372036854775776_1002, current total block count is 1
2020-04-02 05:09:38,504 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:33152 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775776_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775776_1002 src: /127.0.0.1:33152 dest: /127.0.0.1:45304
2020-04-02 05:09:38,535 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:34032 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002 src: /127.0.0.1:34032 dest: /127.0.0.1:38083
2020-04-02 05:09:38,539 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:42864 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775774_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775774_1002 src: /127.0.0.1:42864 dest: /127.0.0.1:33488
2020-04-02 05:09:38,539 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:37044 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775771_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775771_1002 src: /127.0.0.1:37044 dest: /127.0.0.1:41818
2020-04-02 05:09:38,539 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:34190 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775773_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775773_1002 src: /127.0.0.1:34190 dest: /127.0.0.1:34596
2020-04-02 05:09:38,540 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:51910 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775772_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775772_1002 src: /127.0.0.1:51910 dest: /127.0.0.1:45517
2020-04-02 05:09:38,639 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:34132 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775769_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775769_1002 src: /127.0.0.1:34132 dest: /127.0.0.1:39776
2020-04-02 05:09:38,641 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:37762 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002 src: /127.0.0.1:37762 dest: /127.0.0.1:33931
2020-04-02 05:09:38,678 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:55312 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775768_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775768_1002 src: /127.0.0.1:55312 dest: /127.0.0.1:38003
2020-04-02 05:09:39,038 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775776_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33152, dest: /127.0.0.1:45304, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 31f7c920-c39d-4ae7-b315-1227a3caafd0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775776_1002, duration(ns): 526464442
2020-04-02 05:09:39,038 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775776_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775776_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:39,042 [IPC Server handler 1 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45304, datanodeUuid=31f7c920-c39d-4ae7-b315-1227a3caafd0, infoPort=37250, infoSecurePort=0, ipcPort=45067, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:09:39,042 [IPC Server handler 4 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:41818, datanodeUuid=138c0d7d-7e58-4339-8b75-15c135daf76d, infoPort=42795, infoSecurePort=0, ipcPort=43620, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:09:39,059 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34032, dest: /127.0.0.1:38083, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 3d038cc2-f80f-4a72-8c2c-febccfb87908, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002, duration(ns): 508062102
2020-04-02 05:09:39,059 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:39,060 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775776_1002 on 127.0.0.1:45304 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:39,065 [IPC Server handler 0 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:09:39,065 [IPC Server handler 8 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38083, datanodeUuid=3d038cc2-f80f-4a72-8c2c-febccfb87908, infoPort=37146, infoSecurePort=0, ipcPort=37392, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:09:39,065 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:39,066 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45304 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:09:39,066 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775776_1002 is received from 127.0.0.1:45304
2020-04-02 05:09:39,066 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45304 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:39,066 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775771_1002 on 127.0.0.1:41818 size 4194304 replicaState = RBW
2020-04-02 05:09:39,066 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:39,066 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775771_1002 is received from 127.0.0.1:41818
2020-04-02 05:09:39,066 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:41818 receiving: 1, received: 0, deleted: 0
2020-04-02 05:09:39,066 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775768_1002 on 127.0.0.1:38003 size 4194304 replicaState = RBW
2020-04-02 05:09:39,066 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:39,067 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775768_1002 is received from 127.0.0.1:38003
2020-04-02 05:09:39,067 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38003 receiving: 1, received: 0, deleted: 0
2020-04-02 05:09:39,067 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775775_1002 on 127.0.0.1:38083 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:39,067 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:39,067 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38083 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:09:39,067 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775775_1002 is received from 127.0.0.1:38083
2020-04-02 05:09:39,067 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38083 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:39,073 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775774_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42864, dest: /127.0.0.1:33488, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: f1177179-f009-4517-a835-ba14c97e85ff, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775774_1002, duration(ns): 529689498
2020-04-02 05:09:39,073 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775774_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775774_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:39,085 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775773_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34190, dest: /127.0.0.1:34596, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 690f7552-c4c3-4286-845f-64b6525bf551, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775773_1002, duration(ns): 532208679
2020-04-02 05:09:39,086 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775773_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775773_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:39,091 [IPC Server handler 7 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33488, datanodeUuid=f1177179-f009-4517-a835-ba14c97e85ff, infoPort=42409, infoSecurePort=0, ipcPort=46631, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:09:39,092 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775774_1002 on 127.0.0.1:33488 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:39,092 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:39,092 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33488 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:09:39,092 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775774_1002 is received from 127.0.0.1:33488
2020-04-02 05:09:39,092 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33488 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:39,095 [IPC Server handler 6 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34596, datanodeUuid=690f7552-c4c3-4286-845f-64b6525bf551, infoPort=44049, infoSecurePort=0, ipcPort=36235, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:09:39,095 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775773_1002 on 127.0.0.1:34596 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:39,097 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:39,097 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775772_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51910, dest: /127.0.0.1:45517, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775772_1002, duration(ns): 548688419
2020-04-02 05:09:39,097 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775772_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775772_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:39,097 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34596 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:09:39,102 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775773_1002 is received from 127.0.0.1:34596
2020-04-02 05:09:39,102 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34596 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:39,105 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775771_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37044, dest: /127.0.0.1:41818, bytes: 4194181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 138c0d7d-7e58-4339-8b75-15c135daf76d, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775771_1002, duration(ns): 561566043
2020-04-02 05:09:39,105 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775771_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775771_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:39,120 [IPC Server handler 9 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45517, datanodeUuid=30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, infoPort=41207, infoSecurePort=0, ipcPort=44568, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:09:39,120 [IPC Server handler 5 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:41818, datanodeUuid=138c0d7d-7e58-4339-8b75-15c135daf76d, infoPort=42795, infoSecurePort=0, ipcPort=43620, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:09:39,121 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775772_1002 on 127.0.0.1:45517 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:39,121 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:39,121 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45517 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:09:39,121 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775772_1002 is received from 127.0.0.1:45517
2020-04-02 05:09:39,121 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45517 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:39,121 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775771_1002 on 127.0.0.1:41818 size 4194181 replicaState = FINALIZED
2020-04-02 05:09:39,123 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:39,123 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:41818 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:09:39,123 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775771_1002 is received from 127.0.0.1:41818
2020-04-02 05:09:39,123 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:41818 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:39,126 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37762, dest: /127.0.0.1:33931, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 04fa600d-9223-4e33-b0a1-d4242966c7f0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002, duration(ns): 464095511
2020-04-02 05:09:39,126 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:39,130 [IPC Server handler 2 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33931, datanodeUuid=04fa600d-9223-4e33-b0a1-d4242966c7f0, infoPort=45217, infoSecurePort=0, ipcPort=38205, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:09:39,134 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775769_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34132, dest: /127.0.0.1:39776, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: ca9828e1-172e-4a2c-a1a8-917b3485899c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775769_1002, duration(ns): 484290313
2020-04-02 05:09:39,140 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775769_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775769_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:39,140 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775770_1002 on 127.0.0.1:33931 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:39,140 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:39,140 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33931 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:09:39,140 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775770_1002 is received from 127.0.0.1:33931
2020-04-02 05:09:39,140 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33931 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:39,142 [IPC Server handler 1 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:09:39,142 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775769_1002 on 127.0.0.1:39776 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:39,143 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:39,143 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39776 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:09:39,143 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775769_1002 is received from 127.0.0.1:39776
2020-04-02 05:09:39,143 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39776 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:39,153 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775768_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55312, dest: /127.0.0.1:38003, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775768_1002, duration(ns): 470029859
2020-04-02 05:09:39,153 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775768_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775768_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:39,154 [IPC Server handler 8 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:09:39,155 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775768_1002 on 127.0.0.1:38003 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:39,155 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:39,155 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38003 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:09:39,155 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775768_1002 is received from 127.0.0.1:38003
2020-04-02 05:09:39,155 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38003 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:39,158 [IPC Server handler 6 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /deleted_1_1 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:09:39,159 [IPC Server handler 6 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /deleted_1_1 with 1 blocks is persisted to the file system
2020-04-02 05:09:39,159 [IPC Server handler 6 on 41191] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /deleted_1_1 is closed by DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:09:39,160 [Thread-436] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(231)) - corruptBlocks on path /deleted_1_1
2020-04-02 05:09:39,166 [IPC Server handler 9 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775776_1002]
2020-04-02 05:09:39,167 [IPC Server handler 9 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:09:39,171 [Thread-436] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(258)) - Deleting block file BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002
2020-04-02 05:09:39,172 [Thread-436] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:39,172 [Thread-436] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:39,173 [Thread-436] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:39,173 [Thread-436] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:39,174 [Thread-436] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:39,176 [Thread-436] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:39,177 [Thread-436] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:39,178 [Thread-436] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:deleteData(153)) - Deleting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775775
2020-04-02 05:09:39,180 [Thread-436] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:39,180 [Thread-436] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(258)) - Deleting block file BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002
2020-04-02 05:09:39,180 [Thread-436] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:39,181 [Thread-436] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:39,181 [Thread-436] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:39,182 [Thread-436] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:39,192 [Thread-436] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:39,193 [Thread-436] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:39,195 [Thread-436] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:39,196 [Thread-436] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:39,196 [Thread-436] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:deleteData(153)) - Deleting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775770
2020-04-02 05:09:39,199 [Thread-436] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /deleted_1_1
2020-04-02 05:09:39,208 [Thread-436] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /deleted_1_1
2020-04-02 05:09:39,209 [IPC Server handler 2 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/deleted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:09:39,216 [Thread-436] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /deleted_1_1
2020-04-02 05:09:39,218 [IPC Server handler 1 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:39,220 [IPC Server handler 4 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775776_1002]
2020-04-02 05:09:39,222 [IPC Server handler 4 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:09:39,235 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:54966 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002]] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775775_1002 replica FinalizedReplica, blk_-9223372036854775775_1002, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775775 for deletion
2020-04-02 05:09:39,237 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:54966 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002]] INFO  datanode.DataNode (DataXceiver.java:readBlock(598)) - opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002 received exception java.io.FileNotFoundException: BlockId -9223372036854775775 is not valid.
2020-04-02 05:09:39,237 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:54966 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(643)) - DatanodeRegistration(127.0.0.1:38083, datanodeUuid=3d038cc2-f80f-4a72-8c2c-febccfb87908, infoPort=37146, infoSecurePort=0, ipcPort=37392, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366):Got exception while serving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002 to /127.0.0.1:54966
java.io.FileNotFoundException: BlockId -9223372036854775775 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:09:39,238 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:54966 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002]] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:38083:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:54966 dst: /127.0.0.1:38083
java.io.FileNotFoundException: BlockId -9223372036854775775 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:09:39,239 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:34466 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002]] INFO  datanode.DataNode (DataXceiver.java:readBlock(598)) - opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002
2020-04-02 05:09:39,243 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:34466 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(643)) - DatanodeRegistration(127.0.0.1:38083, datanodeUuid=3d038cc2-f80f-4a72-8c2c-febccfb87908, infoPort=37146, infoSecurePort=0, ipcPort=37392, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366):Got exception while serving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002 to /127.0.0.1:34466
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.getReplica(BlockSender.java:492)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:256)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:09:39,243 [Thread-436] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002, for OP_READ_BLOCK, self=/127.0.0.1:34466, remote=/127.0.0.1:38083, for file /deleted_1_1, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775775_1002
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:39,244 [Thread-436] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:38083 for blockBP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002, for OP_READ_BLOCK, self=/127.0.0.1:34466, remote=/127.0.0.1:38083, for file /deleted_1_1, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775775_1002
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:39,237 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775775_1002 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775775
2020-04-02 05:09:39,249 [IPC Server handler 0 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775776_1002]
2020-04-02 05:09:39,247 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:34466 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002]] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:38083:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:34466 dst: /127.0.0.1:38083
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775775_1002
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.getReplica(BlockSender.java:492)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:256)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:09:39,251 [IPC Server handler 0 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:09:39,254 [Thread-436] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:38083,DS-94f6e665-b2d5-46c4-969f-c9b2db0add83,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:09:39,269 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:58548 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002]] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775770_1002 replica FinalizedReplica, blk_-9223372036854775770_1002, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775770 for deletion
2020-04-02 05:09:39,271 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:58548 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002]] INFO  datanode.DataNode (DataXceiver.java:readBlock(598)) - opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002 received exception java.io.FileNotFoundException: BlockId -9223372036854775770 is not valid.
2020-04-02 05:09:39,272 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:58548 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(643)) - DatanodeRegistration(127.0.0.1:33931, datanodeUuid=04fa600d-9223-4e33-b0a1-d4242966c7f0, infoPort=45217, infoSecurePort=0, ipcPort=38205, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366):Got exception while serving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002 to /127.0.0.1:58548
java.io.FileNotFoundException: BlockId -9223372036854775770 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:09:39,272 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775770_1002 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775770
2020-04-02 05:09:39,286 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:38042 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002]] INFO  datanode.DataNode (DataXceiver.java:readBlock(598)) - opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002
2020-04-02 05:09:39,303 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:38042 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(643)) - DatanodeRegistration(127.0.0.1:33931, datanodeUuid=04fa600d-9223-4e33-b0a1-d4242966c7f0, infoPort=45217, infoSecurePort=0, ipcPort=38205, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366):Got exception while serving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002 to /127.0.0.1:38042
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.getReplica(BlockSender.java:492)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:256)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:09:39,286 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:58548 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:33931:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:58548 dst: /127.0.0.1:33931
java.io.FileNotFoundException: BlockId -9223372036854775770 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:09:39,305 [Thread-436] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002, for OP_READ_BLOCK, self=/127.0.0.1:38042, remote=/127.0.0.1:33931, for file /deleted_1_1, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775770_1002
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:203)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:340)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:39,318 [Thread-436] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:33931 for blockBP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002, for OP_READ_BLOCK, self=/127.0.0.1:38042, remote=/127.0.0.1:33931, for file /deleted_1_1, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775770_1002
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:203)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:340)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:39,319 [IPC Server handler 3 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775776_1002]
2020-04-02 05:09:39,319 [IPC Server handler 3 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:09:39,304 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:38042 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:33931:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:38042 dst: /127.0.0.1:33931
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775770_1002
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.getReplica(BlockSender.java:492)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:256)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:09:39,322 [Thread-436] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:33931,DS-653a74b1-1e06-48c8-9fc4-adfe2a024aaf,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:09:39,797 [IPC Server handler 7 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38083, datanodeUuid=3d038cc2-f80f-4a72-8c2c-febccfb87908, infoPort=37146, infoSecurePort=0, ipcPort=37392, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:09:39,797 [Block report processor] DEBUG BlockStateChange (BlockManager.java:removeStoredBlock(3781)) - BLOCK* removeStoredBlock: blk_-9223372036854775776_1002 from 127.0.0.1:38083
2020-04-02 05:09:39,797 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775776_1002 curReplicas 8 curExpectedReplicas 9 oldReplicas 9 oldExpectedReplicas  9 curPri  2 oldPri  3
2020-04-02 05:09:39,798 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775776_1002 has only 8 replicas and needs 9 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:09:39,798 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block DELETED_BLOCK: blk_-9223372036854775775_1002 is received from 127.0.0.1:38083
2020-04-02 05:09:39,798 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38083 receiving: 0, received: 0, deleted: 1
2020-04-02 05:09:40,035 [IPC Server handler 9 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33931, datanodeUuid=04fa600d-9223-4e33-b0a1-d4242966c7f0, infoPort=45217, infoSecurePort=0, ipcPort=38205, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:09:40,036 [Block report processor] DEBUG BlockStateChange (BlockManager.java:removeStoredBlock(3781)) - BLOCK* removeStoredBlock: blk_-9223372036854775776_1002 from 127.0.0.1:33931
2020-04-02 05:09:40,036 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775776_1002 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-04-02 05:09:40,036 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775776_1002 from priority queue 2
2020-04-02 05:09:40,036 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775776_1002 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-04-02 05:09:40,037 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block DELETED_BLOCK: blk_-9223372036854775770_1002 is received from 127.0.0.1:33931
2020-04-02 05:09:40,037 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33931 receiving: 0, received: 0, deleted: 1
2020-04-02 05:09:40,944 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:09:40,944 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:40,944 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:09:43,945 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:09:43,945 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:43,945 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:09:46,946 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:09:46,946 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:46,947 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:09:49,950 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:09:49,950 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:49,951 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:09:52,951 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:09:52,951 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:52,951 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:09:56,007 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:09:56,007 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:56,007 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:09:59,008 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:09:59,008 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:59,008 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:09:59,616 [Thread-436] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /deleted_1_1
2020-04-02 05:09:59,621 [IPC Server handler 6 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775776_1002]
2020-04-02 05:09:59,625 [IPC Server handler 6 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:10:02,009 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:02,009 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:02,010 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:10:04,027 [Thread-436] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /deleted_1_1
2020-04-02 05:10:04,044 [IPC Server handler 1 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775776_1002]
2020-04-02 05:10:04,046 [IPC Server handler 1 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:10:05,010 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:05,010 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:05,010 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:10:08,011 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:08,012 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:08,012 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:10:08,490 [Thread-436] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /deleted_1_1
2020-04-02 05:10:08,495 [IPC Server handler 9 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775776_1002]
2020-04-02 05:10:08,496 [IPC Server handler 9 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:10:11,013 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:11,014 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:11,014 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:10:14,015 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:14,016 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:14,016 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[1]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[1]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[2]
[msx] perform reset as unitTestCounterInClass 2 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:10:14,463 [Thread-494] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithBlockCorrupted(203)) - testReadWithBlockCorrupted: file = /deleted_1_2, dataBlkDelNum = 1, parityBlkDelNum = 2, deleteBlockFile? true
2020-04-02 05:10:14,523 [IPC Server handler 4 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/deleted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:10:14,526 [IPC Server handler 5 on 41191] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /deleted_1_2 for DFSClient_NONMAPREDUCE_-1389971812_1 at 127.0.0.1
2020-04-02 05:10:14,527 [IPC Server handler 5 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/deleted_1_2, holder=DFSClient_NONMAPREDUCE_-1389971812_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:10:14,528 [IPC Server handler 5 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: deleted_1_2 is added
2020-04-02 05:10:14,529 [IPC Server handler 5 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /deleted_1_2 inode 16388 DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:10:14,529 [IPC Server handler 5 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/deleted_1_2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:10:14,530 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 14 Total time for transactions(ms): 29 Number of transactions batched in Syncs: 1 Number of syncs: 13 SyncTimes(ms): 1 1 
2020-04-02 05:10:14,555 [IPC Server handler 6 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /deleted_1_2  inodeId 16388 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:10:14,558 [IPC Server handler 6 on 41191] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:10:14,562 [IPC Server handler 6 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /deleted_1_2 with blk_-9223372036854775760_1003 block is added to the in-memory file system
2020-04-02 05:10:14,562 [IPC Server handler 6 on 41191] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775760_1003, replicas=127.0.0.1:45517, 127.0.0.1:38083, 127.0.0.1:33931, 127.0.0.1:34596, 127.0.0.1:45304, 127.0.0.1:41818, 127.0.0.1:33488, 127.0.0.1:38003, 127.0.0.1:39776 for /deleted_1_2
2020-04-02 05:10:14,562 [IPC Server handler 6 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /deleted_1_2 with new block blk_-9223372036854775760_1003, current total block count is 1
2020-04-02 05:10:14,569 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:39064 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003 src: /127.0.0.1:39064 dest: /127.0.0.1:45517
2020-04-02 05:10:14,575 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49442 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775759_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775759_1003 src: /127.0.0.1:49442 dest: /127.0.0.1:38083
2020-04-02 05:10:14,609 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:53012 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775758_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775758_1003 src: /127.0.0.1:53012 dest: /127.0.0.1:33931
2020-04-02 05:10:14,612 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49568 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775757_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775757_1003 src: /127.0.0.1:49568 dest: /127.0.0.1:34596
2020-04-02 05:10:14,630 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:48588 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775756_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775756_1003 src: /127.0.0.1:48588 dest: /127.0.0.1:45304
2020-04-02 05:10:14,640 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:52440 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775755_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775755_1003 src: /127.0.0.1:52440 dest: /127.0.0.1:41818
2020-04-02 05:10:14,686 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:58264 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003 src: /127.0.0.1:58264 dest: /127.0.0.1:33488
2020-04-02 05:10:14,695 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:42330 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003 src: /127.0.0.1:42330 dest: /127.0.0.1:38003
2020-04-02 05:10:14,703 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49396 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775752_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775752_1003 src: /127.0.0.1:49396 dest: /127.0.0.1:39776
2020-04-02 05:10:14,918 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39064, dest: /127.0.0.1:45517, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003, duration(ns): 339202451
2020-04-02 05:10:14,918 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:14,924 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775759_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49442, dest: /127.0.0.1:38083, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 3d038cc2-f80f-4a72-8c2c-febccfb87908, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775759_1003, duration(ns): 324760757
2020-04-02 05:10:14,924 [IPC Server handler 0 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45517, datanodeUuid=30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, infoPort=41207, infoSecurePort=0, ipcPort=44568, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:10:14,924 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775759_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775759_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:14,927 [IPC Server handler 2 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38083, datanodeUuid=3d038cc2-f80f-4a72-8c2c-febccfb87908, infoPort=37146, infoSecurePort=0, ipcPort=37392, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:10:14,927 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775760_1003 on 127.0.0.1:45517 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:14,927 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:14,927 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775758_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53012, dest: /127.0.0.1:33931, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 04fa600d-9223-4e33-b0a1-d4242966c7f0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775758_1003, duration(ns): 298618954
2020-04-02 05:10:14,927 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45517 is added to blk_-9223372036854775760_1003 (size=0)
2020-04-02 05:10:14,927 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775758_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775758_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:14,927 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775760_1003 is received from 127.0.0.1:45517
2020-04-02 05:10:14,928 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45517 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:14,929 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775759_1003 on 127.0.0.1:38083 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:14,929 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:14,929 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38083 is added to blk_-9223372036854775760_1003 (size=0)
2020-04-02 05:10:14,929 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775759_1003 is received from 127.0.0.1:38083
2020-04-02 05:10:14,929 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38083 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:14,929 [IPC Server handler 1 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33931, datanodeUuid=04fa600d-9223-4e33-b0a1-d4242966c7f0, infoPort=45217, infoSecurePort=0, ipcPort=38205, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:10:14,929 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775757_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49568, dest: /127.0.0.1:34596, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 690f7552-c4c3-4286-845f-64b6525bf551, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775757_1003, duration(ns): 303411056
2020-04-02 05:10:14,930 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775758_1003 on 127.0.0.1:33931 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:14,930 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775757_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775757_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:14,930 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:14,931 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33931 is added to blk_-9223372036854775760_1003 (size=0)
2020-04-02 05:10:14,931 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775758_1003 is received from 127.0.0.1:33931
2020-04-02 05:10:14,931 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33931 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:14,931 [IPC Server handler 8 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34596, datanodeUuid=690f7552-c4c3-4286-845f-64b6525bf551, infoPort=44049, infoSecurePort=0, ipcPort=36235, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:10:14,932 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775756_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:48588, dest: /127.0.0.1:45304, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 31f7c920-c39d-4ae7-b315-1227a3caafd0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775756_1003, duration(ns): 298279514
2020-04-02 05:10:14,932 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775757_1003 on 127.0.0.1:34596 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:14,932 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775756_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775756_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:14,932 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:14,933 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34596 is added to blk_-9223372036854775760_1003 (size=0)
2020-04-02 05:10:14,933 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775757_1003 is received from 127.0.0.1:34596
2020-04-02 05:10:14,933 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34596 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:14,933 [IPC Server handler 9 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45304, datanodeUuid=31f7c920-c39d-4ae7-b315-1227a3caafd0, infoPort=37250, infoSecurePort=0, ipcPort=45067, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:10:14,934 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775756_1003 on 127.0.0.1:45304 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:14,934 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775755_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52440, dest: /127.0.0.1:41818, bytes: 4194181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 138c0d7d-7e58-4339-8b75-15c135daf76d, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775755_1003, duration(ns): 291543024
2020-04-02 05:10:14,934 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:14,934 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775755_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775755_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:14,934 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45304 is added to blk_-9223372036854775760_1003 (size=0)
2020-04-02 05:10:14,934 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775756_1003 is received from 127.0.0.1:45304
2020-04-02 05:10:14,934 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45304 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:14,936 [IPC Server handler 3 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:41818, datanodeUuid=138c0d7d-7e58-4339-8b75-15c135daf76d, infoPort=42795, infoSecurePort=0, ipcPort=43620, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:10:14,936 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58264, dest: /127.0.0.1:33488, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: f1177179-f009-4517-a835-ba14c97e85ff, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003, duration(ns): 248331376
2020-04-02 05:10:14,936 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775755_1003 on 127.0.0.1:41818 size 4194181 replicaState = FINALIZED
2020-04-02 05:10:14,936 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:14,937 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:41818 is added to blk_-9223372036854775760_1003 (size=0)
2020-04-02 05:10:14,937 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775755_1003 is received from 127.0.0.1:41818
2020-04-02 05:10:14,938 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:41818 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:14,936 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:14,938 [IPC Server handler 7 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33488, datanodeUuid=f1177179-f009-4517-a835-ba14c97e85ff, infoPort=42409, infoSecurePort=0, ipcPort=46631, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:10:14,938 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775754_1003 on 127.0.0.1:33488 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:14,938 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42330, dest: /127.0.0.1:38003, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003, duration(ns): 241715215
2020-04-02 05:10:14,938 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:14,939 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:14,939 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33488 is added to blk_-9223372036854775760_1003 (size=0)
2020-04-02 05:10:14,939 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775754_1003 is received from 127.0.0.1:33488
2020-04-02 05:10:14,940 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33488 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:14,941 [IPC Server handler 4 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:10:14,942 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775752_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49396, dest: /127.0.0.1:39776, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: ca9828e1-172e-4a2c-a1a8-917b3485899c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775752_1003, duration(ns): 237131051
2020-04-02 05:10:14,942 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775753_1003 on 127.0.0.1:38003 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:14,942 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775752_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775752_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:14,942 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:14,943 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38003 is added to blk_-9223372036854775760_1003 (size=0)
2020-04-02 05:10:14,943 [IPC Server handler 5 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:10:14,944 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775753_1003 is received from 127.0.0.1:38003
2020-04-02 05:10:14,948 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38003 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:14,950 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775752_1003 on 127.0.0.1:39776 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:14,950 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:14,950 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39776 is added to blk_-9223372036854775760_1003 (size=0)
2020-04-02 05:10:14,950 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775752_1003 is received from 127.0.0.1:39776
2020-04-02 05:10:14,950 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39776 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:14,951 [IPC Server handler 6 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /deleted_1_2 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:10:14,952 [IPC Server handler 6 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /deleted_1_2 with 1 blocks is persisted to the file system
2020-04-02 05:10:14,952 [IPC Server handler 6 on 41191] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /deleted_1_2 is closed by DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:10:14,953 [Thread-494] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(231)) - corruptBlocks on path /deleted_1_2
2020-04-02 05:10:14,958 [IPC Server handler 0 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775760_1003]
2020-04-02 05:10:14,959 [IPC Server handler 0 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:10:14,962 [Thread-494] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(258)) - Deleting block file BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003
2020-04-02 05:10:14,963 [Thread-494] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:14,964 [Thread-494] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:14,964 [Thread-494] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:14,965 [Thread-494] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:deleteData(153)) - Deleting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775760
2020-04-02 05:10:14,967 [Thread-494] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:14,967 [Thread-494] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:14,968 [Thread-494] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:14,968 [Thread-494] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:14,969 [Thread-494] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:14,969 [Thread-494] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(258)) - Deleting block file BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003
2020-04-02 05:10:14,969 [Thread-494] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:14,970 [Thread-494] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:14,970 [Thread-494] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:14,970 [Thread-494] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:14,971 [Thread-494] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:14,971 [Thread-494] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:deleteData(153)) - Deleting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775753
2020-04-02 05:10:14,973 [Thread-494] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:14,973 [Thread-494] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:14,973 [Thread-494] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:14,974 [Thread-494] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(258)) - Deleting block file BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003
2020-04-02 05:10:14,974 [Thread-494] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:14,974 [Thread-494] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:14,974 [Thread-494] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:deleteData(153)) - Deleting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775754
2020-04-02 05:10:14,976 [Thread-494] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:14,976 [Thread-494] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:14,979 [Thread-494] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:14,980 [Thread-494] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:14,980 [Thread-494] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:14,980 [Thread-494] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:14,980 [Thread-494] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /deleted_1_2
2020-04-02 05:10:14,984 [Thread-494] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /deleted_1_2
2020-04-02 05:10:14,985 [IPC Server handler 2 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/deleted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:10:14,986 [Thread-494] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /deleted_1_2
2020-04-02 05:10:14,987 [IPC Server handler 1 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:10:14,988 [IPC Server handler 8 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775760_1003]
2020-04-02 05:10:14,989 [IPC Server handler 8 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:10:14,997 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:38976 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003]] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775760_1003 replica FinalizedReplica, blk_-9223372036854775760_1003, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775760 for deletion
2020-04-02 05:10:14,998 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:38976 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003]] INFO  datanode.DataNode (DataXceiver.java:readBlock(598)) - opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003 received exception java.io.FileNotFoundException: BlockId -9223372036854775760 is not valid.
2020-04-02 05:10:14,999 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:38976 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003]] WARN  datanode.DataNode (DataXceiver.java:readBlock(643)) - DatanodeRegistration(127.0.0.1:45517, datanodeUuid=30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, infoPort=41207, infoSecurePort=0, ipcPort=44568, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366):Got exception while serving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003 to /127.0.0.1:38976
java.io.FileNotFoundException: BlockId -9223372036854775760 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:10:14,999 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775760_1003 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775760
2020-04-02 05:10:15,001 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:38976 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003]] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:45517:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:38976 dst: /127.0.0.1:45517
java.io.FileNotFoundException: BlockId -9223372036854775760 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:10:15,002 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:39082 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003]] INFO  datanode.DataNode (DataXceiver.java:readBlock(598)) - opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003
2020-04-02 05:10:15,002 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:39082 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003]] WARN  datanode.DataNode (DataXceiver.java:readBlock(643)) - DatanodeRegistration(127.0.0.1:45517, datanodeUuid=30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, infoPort=41207, infoSecurePort=0, ipcPort=44568, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366):Got exception while serving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003 to /127.0.0.1:39082
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.getReplica(BlockSender.java:492)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:256)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:10:15,002 [Thread-494] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003, for OP_READ_BLOCK, self=/127.0.0.1:39082, remote=/127.0.0.1:45517, for file /deleted_1_2, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775760_1003
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:15,003 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:39082 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003]] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:45517:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:39082 dst: /127.0.0.1:45517
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.getReplica(BlockSender.java:492)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:256)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:10:15,005 [Thread-494] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:45517 for blockBP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775760_1003, for OP_READ_BLOCK, self=/127.0.0.1:39082, remote=/127.0.0.1:45517, for file /deleted_1_2, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775760_1003
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:15,007 [IPC Server handler 9 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775760_1003]
2020-04-02 05:10:15,007 [IPC Server handler 9 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:10:15,009 [Thread-494] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:45517,DS-bd9fc205-c45f-48b9-85ed-311ae68dcf33,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:10:15,017 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:58160 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003]] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775754_1003 replica FinalizedReplica, blk_-9223372036854775754_1003, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775754 for deletion
2020-04-02 05:10:15,019 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:58160 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003]] INFO  datanode.DataNode (DataXceiver.java:readBlock(598)) - opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003 received exception java.io.FileNotFoundException: BlockId -9223372036854775754 is not valid.
2020-04-02 05:10:15,019 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:58160 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003]] WARN  datanode.DataNode (DataXceiver.java:readBlock(643)) - DatanodeRegistration(127.0.0.1:33488, datanodeUuid=f1177179-f009-4517-a835-ba14c97e85ff, infoPort=42409, infoSecurePort=0, ipcPort=46631, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366):Got exception while serving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003 to /127.0.0.1:58160
java.io.FileNotFoundException: BlockId -9223372036854775754 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:10:15,020 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775754_1003 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775754
2020-04-02 05:10:15,021 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:58160 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003]] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:33488:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:58160 dst: /127.0.0.1:33488
java.io.FileNotFoundException: BlockId -9223372036854775754 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:10:15,023 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:58276 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003]] INFO  datanode.DataNode (DataXceiver.java:readBlock(598)) - opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003
2020-04-02 05:10:15,023 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:58276 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003]] WARN  datanode.DataNode (DataXceiver.java:readBlock(643)) - DatanodeRegistration(127.0.0.1:33488, datanodeUuid=f1177179-f009-4517-a835-ba14c97e85ff, infoPort=42409, infoSecurePort=0, ipcPort=46631, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366):Got exception while serving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003 to /127.0.0.1:58276
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.getReplica(BlockSender.java:492)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:256)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:10:15,023 [Thread-494] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003, for OP_READ_BLOCK, self=/127.0.0.1:58276, remote=/127.0.0.1:33488, for file /deleted_1_2, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775754_1003
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:203)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:340)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:15,024 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:58276 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003]] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:33488:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:58276 dst: /127.0.0.1:33488
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.getReplica(BlockSender.java:492)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:256)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:10:15,025 [Thread-494] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:33488 for blockBP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775754_1003, for OP_READ_BLOCK, self=/127.0.0.1:58276, remote=/127.0.0.1:33488, for file /deleted_1_2, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775754_1003
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:203)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:340)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:15,027 [IPC Server handler 3 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775760_1003]
2020-04-02 05:10:15,027 [IPC Server handler 3 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:10:15,029 [Thread-494] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:33488,DS-473eb806-1eb7-4944-8753-5f4b73aff970,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:10:15,031 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:42342 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003]] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775753_1003 replica FinalizedReplica, blk_-9223372036854775753_1003, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775753 for deletion
2020-04-02 05:10:15,033 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:42342 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003]] INFO  datanode.DataNode (DataXceiver.java:readBlock(598)) - opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003 received exception java.io.FileNotFoundException: BlockId -9223372036854775753 is not valid.
2020-04-02 05:10:15,033 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:42342 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003]] WARN  datanode.DataNode (DataXceiver.java:readBlock(643)) - DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366):Got exception while serving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003 to /127.0.0.1:42342
java.io.FileNotFoundException: BlockId -9223372036854775753 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:10:15,033 [Thread-494] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003 received exception java.io.FileNotFoundException: BlockId -9223372036854775753 is not valid., for OP_READ_BLOCK, self=/127.0.0.1:42342, remote=/127.0.0.1:38003, for file /deleted_1_2, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775753_1003
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:203)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:340)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:15,033 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775753_1003 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775753
2020-04-02 05:10:15,036 [Thread-494] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:38003 for blockBP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003 received exception java.io.FileNotFoundException: BlockId -9223372036854775753 is not valid., for OP_READ_BLOCK, self=/127.0.0.1:42342, remote=/127.0.0.1:38003, for file /deleted_1_2, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775753_1003
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:203)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:340)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:15,044 [IPC Server handler 7 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775760_1003]
2020-04-02 05:10:15,045 [IPC Server handler 7 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:10:15,046 [Thread-494] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:38003,DS-cd20bec6-61af-4cee-a017-bfc56735fa58,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:10:15,035 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:42342 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775753_1003]] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:38003:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:42342 dst: /127.0.0.1:38003
java.io.FileNotFoundException: BlockId -9223372036854775753 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:10:15,053 [IPC Server handler 6 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:10:15,053 [Block report processor] DEBUG BlockStateChange (BlockManager.java:removeStoredBlock(3781)) - BLOCK* removeStoredBlock: blk_-9223372036854775760_1003 from 127.0.0.1:38003
2020-04-02 05:10:15,053 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775760_1003 curReplicas 8 curExpectedReplicas 9 oldReplicas 9 oldExpectedReplicas  9 curPri  2 oldPri  3
2020-04-02 05:10:15,053 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775760_1003 has only 8 replicas and needs 9 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:10:15,053 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block DELETED_BLOCK: blk_-9223372036854775753_1003 is received from 127.0.0.1:38003
2020-04-02 05:10:15,053 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38003 receiving: 0, received: 0, deleted: 1
2020-04-02 05:10:15,179 [IPC Server handler 9 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33488, datanodeUuid=f1177179-f009-4517-a835-ba14c97e85ff, infoPort=42409, infoSecurePort=0, ipcPort=46631, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:10:15,179 [IPC Server handler 3 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45517, datanodeUuid=30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, infoPort=41207, infoSecurePort=0, ipcPort=44568, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:10:15,179 [Block report processor] DEBUG BlockStateChange (BlockManager.java:removeStoredBlock(3781)) - BLOCK* removeStoredBlock: blk_-9223372036854775760_1003 from 127.0.0.1:33488
2020-04-02 05:10:15,179 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775760_1003 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-04-02 05:10:15,180 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775760_1003 from priority queue 2
2020-04-02 05:10:15,180 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775760_1003 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-04-02 05:10:15,180 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block DELETED_BLOCK: blk_-9223372036854775754_1003 is received from 127.0.0.1:33488
2020-04-02 05:10:15,180 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33488 receiving: 0, received: 0, deleted: 1
2020-04-02 05:10:15,180 [Block report processor] DEBUG BlockStateChange (BlockManager.java:removeStoredBlock(3781)) - BLOCK* removeStoredBlock: blk_-9223372036854775760_1003 from 127.0.0.1:45517
2020-04-02 05:10:15,180 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775760_1003 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:10:15,180 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775760_1003 from priority queue 1
2020-04-02 05:10:15,181 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775760_1003 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:10:15,181 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block DELETED_BLOCK: blk_-9223372036854775760_1003 is received from 127.0.0.1:45517
2020-04-02 05:10:15,181 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45517 receiving: 0, received: 0, deleted: 1
2020-04-02 05:10:17,016 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:17,017 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:17,017 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:17,017 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:10:20,018 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:20,018 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:20,018 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:20,019 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:10:23,020 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:23,021 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:23,021 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:23,022 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:10:26,023 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:26,024 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:26,024 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:26,024 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:10:29,026 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:29,026 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:29,027 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:29,027 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:10:29,923 [Thread-494] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /deleted_1_2
2020-04-02 05:10:29,929 [IPC Server handler 5 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775760_1003]
2020-04-02 05:10:29,931 [IPC Server handler 5 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:10:32,028 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:32,029 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:32,029 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:32,030 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:10:33,922 [Thread-494] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /deleted_1_2
2020-04-02 05:10:33,938 [IPC Server handler 8 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775760_1003]
2020-04-02 05:10:33,940 [IPC Server handler 8 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:10:35,031 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:35,032 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:35,032 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:35,032 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:10:38,003 [Thread-494] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /deleted_1_2
2020-04-02 05:10:38,007 [IPC Server handler 9 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775760_1003]
2020-04-02 05:10:38,008 [IPC Server handler 9 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:10:38,033 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:38,033 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:38,033 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:38,033 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:10:41,034 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:41,034 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:41,034 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:41,034 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[2]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[2]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[3]
[msx] perform reset as unitTestCounterInClass 3 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:10:43,365 [Thread-540] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithBlockCorrupted(203)) - testReadWithBlockCorrupted: file = /deleted_2_0, dataBlkDelNum = 2, parityBlkDelNum = 0, deleteBlockFile? true
2020-04-02 05:10:43,422 [IPC Server handler 8 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/deleted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:10:43,424 [IPC Server handler 9 on 41191] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /deleted_2_0 for DFSClient_NONMAPREDUCE_-1389971812_1 at 127.0.0.1
2020-04-02 05:10:43,424 [IPC Server handler 9 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/deleted_2_0, holder=DFSClient_NONMAPREDUCE_-1389971812_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:10:43,425 [IPC Server handler 9 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: deleted_2_0 is added
2020-04-02 05:10:43,425 [IPC Server handler 9 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /deleted_2_0 inode 16389 DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:10:43,426 [IPC Server handler 9 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/deleted_2_0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:10:43,447 [IPC Server handler 7 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /deleted_2_0  inodeId 16389 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:10:43,448 [IPC Server handler 7 on 41191] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:10:43,451 [IPC Server handler 7 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /deleted_2_0 with blk_-9223372036854775744_1004 block is added to the in-memory file system
2020-04-02 05:10:43,451 [IPC Server handler 7 on 41191] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775744_1004, replicas=127.0.0.1:45517, 127.0.0.1:38003, 127.0.0.1:33931, 127.0.0.1:33488, 127.0.0.1:39776, 127.0.0.1:45304, 127.0.0.1:34596, 127.0.0.1:41818, 127.0.0.1:38083 for /deleted_2_0
2020-04-02 05:10:43,451 [IPC Server handler 7 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /deleted_2_0 with new block blk_-9223372036854775744_1004, current total block count is 1
2020-04-02 05:10:43,456 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:39204 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775744_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775744_1004 src: /127.0.0.1:39204 dest: /127.0.0.1:45517
2020-04-02 05:10:43,460 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:42458 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775743_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775743_1004 src: /127.0.0.1:42458 dest: /127.0.0.1:38003
2020-04-02 05:10:43,485 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:53152 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775742_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775742_1004 src: /127.0.0.1:53152 dest: /127.0.0.1:33931
2020-04-02 05:10:43,493 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:58398 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775741_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775741_1004 src: /127.0.0.1:58398 dest: /127.0.0.1:33488
2020-04-02 05:10:43,510 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49528 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004 src: /127.0.0.1:49528 dest: /127.0.0.1:39776
2020-04-02 05:10:43,511 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:48730 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004 src: /127.0.0.1:48730 dest: /127.0.0.1:45304
2020-04-02 05:10:43,563 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49714 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775738_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775738_1004 src: /127.0.0.1:49714 dest: /127.0.0.1:34596
2020-04-02 05:10:43,575 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:52584 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775737_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775737_1004 src: /127.0.0.1:52584 dest: /127.0.0.1:41818
2020-04-02 05:10:43,584 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49596 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775736_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775736_1004 src: /127.0.0.1:49596 dest: /127.0.0.1:38083
2020-04-02 05:10:43,761 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775744_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39204, dest: /127.0.0.1:45517, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775744_1004, duration(ns): 301435889
2020-04-02 05:10:43,762 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775744_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775744_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:43,765 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775743_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42458, dest: /127.0.0.1:38003, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775743_1004, duration(ns): 292958748
2020-04-02 05:10:43,765 [IPC Server handler 2 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45517, datanodeUuid=30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, infoPort=41207, infoSecurePort=0, ipcPort=44568, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:10:43,765 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775743_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775743_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:43,767 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775744_1004 on 127.0.0.1:45517 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:43,767 [IPC Server handler 3 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:10:43,767 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:43,768 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775742_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53152, dest: /127.0.0.1:33931, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 04fa600d-9223-4e33-b0a1-d4242966c7f0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775742_1004, duration(ns): 272968672
2020-04-02 05:10:43,768 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45517 is added to blk_-9223372036854775744_1004 (size=0)
2020-04-02 05:10:43,768 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775742_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775742_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:43,768 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775744_1004 is received from 127.0.0.1:45517
2020-04-02 05:10:43,768 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45517 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:43,768 [IPC Server handler 0 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33931, datanodeUuid=04fa600d-9223-4e33-b0a1-d4242966c7f0, infoPort=45217, infoSecurePort=0, ipcPort=38205, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:10:43,770 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775743_1004 on 127.0.0.1:38003 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:43,770 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775741_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58398, dest: /127.0.0.1:33488, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: f1177179-f009-4517-a835-ba14c97e85ff, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775741_1004, duration(ns): 269826727
2020-04-02 05:10:43,770 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:43,771 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775741_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775741_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:43,771 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38003 is added to blk_-9223372036854775744_1004 (size=0)
2020-04-02 05:10:43,771 [IPC Server handler 4 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33488, datanodeUuid=f1177179-f009-4517-a835-ba14c97e85ff, infoPort=42409, infoSecurePort=0, ipcPort=46631, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:10:43,771 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775743_1004 is received from 127.0.0.1:38003
2020-04-02 05:10:43,772 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38003 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:43,772 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775742_1004 on 127.0.0.1:33931 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:43,773 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:43,773 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49528, dest: /127.0.0.1:39776, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: ca9828e1-172e-4a2c-a1a8-917b3485899c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004, duration(ns): 256646662
2020-04-02 05:10:43,773 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33931 is added to blk_-9223372036854775744_1004 (size=0)
2020-04-02 05:10:43,773 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:43,773 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775742_1004 is received from 127.0.0.1:33931
2020-04-02 05:10:43,773 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33931 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:43,773 [IPC Server handler 6 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:10:43,774 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775741_1004 on 127.0.0.1:33488 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:43,774 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:43,775 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33488 is added to blk_-9223372036854775744_1004 (size=0)
2020-04-02 05:10:43,775 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775741_1004 is received from 127.0.0.1:33488
2020-04-02 05:10:43,775 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33488 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:43,775 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:48730, dest: /127.0.0.1:45304, bytes: 4194181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 31f7c920-c39d-4ae7-b315-1227a3caafd0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004, duration(ns): 261421442
2020-04-02 05:10:43,776 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775740_1004 on 127.0.0.1:39776 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:43,776 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:43,776 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:43,776 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39776 is added to blk_-9223372036854775744_1004 (size=0)
2020-04-02 05:10:43,776 [IPC Server handler 1 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45304, datanodeUuid=31f7c920-c39d-4ae7-b315-1227a3caafd0, infoPort=37250, infoSecurePort=0, ipcPort=45067, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:10:43,776 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775740_1004 is received from 127.0.0.1:39776
2020-04-02 05:10:43,777 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39776 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:43,777 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775739_1004 on 127.0.0.1:45304 size 4194181 replicaState = FINALIZED
2020-04-02 05:10:43,777 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:43,778 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45304 is added to blk_-9223372036854775744_1004 (size=0)
2020-04-02 05:10:43,778 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775739_1004 is received from 127.0.0.1:45304
2020-04-02 05:10:43,778 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775738_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49714, dest: /127.0.0.1:34596, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 690f7552-c4c3-4286-845f-64b6525bf551, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775738_1004, duration(ns): 212237870
2020-04-02 05:10:43,778 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45304 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:43,778 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775738_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775738_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:43,779 [IPC Server handler 5 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34596, datanodeUuid=690f7552-c4c3-4286-845f-64b6525bf551, infoPort=44049, infoSecurePort=0, ipcPort=36235, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:10:43,780 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775738_1004 on 127.0.0.1:34596 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:43,780 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:43,781 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34596 is added to blk_-9223372036854775744_1004 (size=0)
2020-04-02 05:10:43,781 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775737_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52584, dest: /127.0.0.1:41818, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 138c0d7d-7e58-4339-8b75-15c135daf76d, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775737_1004, duration(ns): 202304824
2020-04-02 05:10:43,781 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775738_1004 is received from 127.0.0.1:34596
2020-04-02 05:10:43,781 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34596 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:43,781 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775737_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775737_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:43,782 [IPC Server handler 8 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:41818, datanodeUuid=138c0d7d-7e58-4339-8b75-15c135daf76d, infoPort=42795, infoSecurePort=0, ipcPort=43620, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:10:43,782 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775737_1004 on 127.0.0.1:41818 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:43,782 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:43,783 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:41818 is added to blk_-9223372036854775744_1004 (size=0)
2020-04-02 05:10:43,783 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775737_1004 is received from 127.0.0.1:41818
2020-04-02 05:10:43,783 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775736_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49596, dest: /127.0.0.1:38083, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 3d038cc2-f80f-4a72-8c2c-febccfb87908, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775736_1004, duration(ns): 196215543
2020-04-02 05:10:43,783 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:41818 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:43,783 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775736_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775736_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:43,783 [IPC Server handler 9 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38083, datanodeUuid=3d038cc2-f80f-4a72-8c2c-febccfb87908, infoPort=37146, infoSecurePort=0, ipcPort=37392, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:10:43,784 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775736_1004 on 127.0.0.1:38083 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:43,784 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:43,784 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38083 is added to blk_-9223372036854775744_1004 (size=0)
2020-04-02 05:10:43,784 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775736_1004 is received from 127.0.0.1:38083
2020-04-02 05:10:43,784 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38083 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:43,784 [IPC Server handler 7 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /deleted_2_0 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:10:43,785 [IPC Server handler 7 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /deleted_2_0 with 1 blocks is persisted to the file system
2020-04-02 05:10:43,786 [IPC Server handler 7 on 41191] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /deleted_2_0 is closed by DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:10:43,786 [Thread-540] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(231)) - corruptBlocks on path /deleted_2_0
2020-04-02 05:10:43,792 [IPC Server handler 2 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775744_1004]
2020-04-02 05:10:43,793 [IPC Server handler 2 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:10:43,795 [Thread-540] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(258)) - Deleting block file BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004
2020-04-02 05:10:43,795 [Thread-540] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:43,796 [Thread-540] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:43,796 [Thread-540] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:43,796 [Thread-540] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:43,797 [Thread-540] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:43,797 [Thread-540] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:43,797 [Thread-540] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:deleteData(153)) - Deleting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775739
2020-04-02 05:10:43,800 [Thread-540] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:43,800 [Thread-540] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:43,800 [Thread-540] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(258)) - Deleting block file BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004
2020-04-02 05:10:43,801 [Thread-540] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:43,801 [Thread-540] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:deleteData(153)) - Deleting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775740
2020-04-02 05:10:43,803 [Thread-540] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:43,803 [Thread-540] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:43,804 [Thread-540] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:43,804 [Thread-540] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:43,804 [Thread-540] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:43,805 [Thread-540] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:43,805 [Thread-540] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:43,805 [Thread-540] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /deleted_2_0
2020-04-02 05:10:43,812 [Thread-540] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /deleted_2_0
2020-04-02 05:10:43,813 [IPC Server handler 3 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/deleted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:10:43,814 [Thread-540] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /deleted_2_0
2020-04-02 05:10:43,814 [IPC Server handler 0 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:10:43,815 [IPC Server handler 4 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775744_1004]
2020-04-02 05:10:43,816 [IPC Server handler 4 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:10:43,831 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49294 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004]] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775740_1004 replica FinalizedReplica, blk_-9223372036854775740_1004, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775740 for deletion
2020-04-02 05:10:43,831 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49294 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004]] INFO  datanode.DataNode (DataXceiver.java:readBlock(598)) - opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004 received exception java.io.FileNotFoundException: BlockId -9223372036854775740 is not valid.
2020-04-02 05:10:43,831 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49294 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004]] WARN  datanode.DataNode (DataXceiver.java:readBlock(643)) - DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366):Got exception while serving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004 to /127.0.0.1:49294
java.io.FileNotFoundException: BlockId -9223372036854775740 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:10:43,832 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775740_1004 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775740
2020-04-02 05:10:43,833 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49294 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004]] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:39776:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:49294 dst: /127.0.0.1:39776
java.io.FileNotFoundException: BlockId -9223372036854775740 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:10:43,835 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49544 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004]] INFO  datanode.DataNode (DataXceiver.java:readBlock(598)) - opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004
2020-04-02 05:10:43,835 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49544 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004]] WARN  datanode.DataNode (DataXceiver.java:readBlock(643)) - DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366):Got exception while serving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004 to /127.0.0.1:49544
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.getReplica(BlockSender.java:492)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:256)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:10:43,835 [Thread-540] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004, for OP_READ_BLOCK, self=/127.0.0.1:49544, remote=/127.0.0.1:39776, for file /deleted_2_0, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775740_1004
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:43,835 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49544 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004]] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:39776:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:49544 dst: /127.0.0.1:39776
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.getReplica(BlockSender.java:492)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:256)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:10:43,837 [Thread-540] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:39776 for blockBP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775740_1004, for OP_READ_BLOCK, self=/127.0.0.1:49544, remote=/127.0.0.1:39776, for file /deleted_2_0, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775740_1004
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:43,838 [IPC Server handler 6 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775744_1004]
2020-04-02 05:10:43,838 [IPC Server handler 6 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:10:43,840 [Thread-540] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:39776,DS-c37ee172-cb9b-4f05-84aa-bcebbe58c663,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:10:43,842 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:48486 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004]] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775739_1004 replica FinalizedReplica, blk_-9223372036854775739_1004, FINALIZED
  getNumBytes()     = 4194181
  getBytesOnDisk()  = 4194181
  getVisibleLength()= 4194181
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775739 for deletion
2020-04-02 05:10:43,843 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:48486 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004]] INFO  datanode.DataNode (DataXceiver.java:readBlock(598)) - opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004 received exception java.io.FileNotFoundException: BlockId -9223372036854775739 is not valid.
2020-04-02 05:10:43,843 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:48486 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004]] WARN  datanode.DataNode (DataXceiver.java:readBlock(643)) - DatanodeRegistration(127.0.0.1:45304, datanodeUuid=31f7c920-c39d-4ae7-b315-1227a3caafd0, infoPort=37250, infoSecurePort=0, ipcPort=45067, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366):Got exception while serving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004 to /127.0.0.1:48486
java.io.FileNotFoundException: BlockId -9223372036854775739 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:10:43,843 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775739_1004 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775739
2020-04-02 05:10:43,844 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:48486 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004]] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:45304:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:48486 dst: /127.0.0.1:45304
java.io.FileNotFoundException: BlockId -9223372036854775739 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:10:43,847 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:48746 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004]] INFO  datanode.DataNode (DataXceiver.java:readBlock(598)) - opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004
2020-04-02 05:10:43,848 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:48746 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004]] WARN  datanode.DataNode (DataXceiver.java:readBlock(643)) - DatanodeRegistration(127.0.0.1:45304, datanodeUuid=31f7c920-c39d-4ae7-b315-1227a3caafd0, infoPort=37250, infoSecurePort=0, ipcPort=45067, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366):Got exception while serving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004 to /127.0.0.1:48746
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.getReplica(BlockSender.java:492)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:256)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:10:43,848 [Thread-540] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004, for OP_READ_BLOCK, self=/127.0.0.1:48746, remote=/127.0.0.1:45304, for file /deleted_2_0, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775739_1004
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:43,849 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:48746 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004]] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:45304:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:48746 dst: /127.0.0.1:45304
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.getReplica(BlockSender.java:492)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:256)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:10:43,850 [Thread-540] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:45304 for blockBP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775739_1004, for OP_READ_BLOCK, self=/127.0.0.1:48746, remote=/127.0.0.1:45304, for file /deleted_2_0, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775739_1004
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:43,851 [IPC Server handler 1 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775744_1004]
2020-04-02 05:10:43,851 [IPC Server handler 1 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:10:43,853 [Thread-540] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:45304,DS-52fa7b3d-3f2c-4afb-8e3c-b713e4545d8d,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:10:44,035 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:44,035 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:44,035 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:44,035 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:10:45,210 [IPC Server handler 4 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45304, datanodeUuid=31f7c920-c39d-4ae7-b315-1227a3caafd0, infoPort=37250, infoSecurePort=0, ipcPort=45067, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:10:45,210 [IPC Server handler 6 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:10:45,211 [Block report processor] DEBUG BlockStateChange (BlockManager.java:removeStoredBlock(3781)) - BLOCK* removeStoredBlock: blk_-9223372036854775744_1004 from 127.0.0.1:45304
2020-04-02 05:10:45,211 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775744_1004 curReplicas 8 curExpectedReplicas 9 oldReplicas 9 oldExpectedReplicas  9 curPri  2 oldPri  3
2020-04-02 05:10:45,211 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775744_1004 has only 8 replicas and needs 9 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:10:45,211 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block DELETED_BLOCK: blk_-9223372036854775739_1004 is received from 127.0.0.1:45304
2020-04-02 05:10:45,211 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45304 receiving: 0, received: 0, deleted: 1
2020-04-02 05:10:45,211 [Block report processor] DEBUG BlockStateChange (BlockManager.java:removeStoredBlock(3781)) - BLOCK* removeStoredBlock: blk_-9223372036854775744_1004 from 127.0.0.1:39776
2020-04-02 05:10:45,212 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775744_1004 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-04-02 05:10:45,212 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775744_1004 from priority queue 2
2020-04-02 05:10:45,212 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775744_1004 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-04-02 05:10:45,212 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block DELETED_BLOCK: blk_-9223372036854775740_1004 is received from 127.0.0.1:39776
2020-04-02 05:10:45,212 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39776 receiving: 0, received: 0, deleted: 1
2020-04-02 05:10:47,036 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:47,036 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:47,036 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:10:47,036 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:47,037 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:10:50,037 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:50,038 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:50,038 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:10:50,038 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:50,038 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:10:53,039 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:53,040 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:53,040 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:10:53,040 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:53,040 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:10:56,041 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:56,042 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:56,042 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:10:56,042 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:56,042 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:10:58,215 [Thread-540] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /deleted_2_0
2020-04-02 05:10:58,232 [IPC Server handler 3 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775744_1004]
2020-04-02 05:10:58,234 [IPC Server handler 3 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:10:59,043 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:59,043 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:59,043 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:10:59,043 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:59,043 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:11:02,044 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:02,045 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:02,045 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:02,045 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:02,045 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:11:02,283 [Thread-540] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /deleted_2_0
2020-04-02 05:11:02,299 [IPC Server handler 2 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775744_1004]
2020-04-02 05:11:02,301 [IPC Server handler 2 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:11:05,060 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:05,061 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:05,061 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:05,061 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:05,061 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:11:06,244 [Thread-540] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /deleted_2_0
2020-04-02 05:11:06,246 [IPC Server handler 6 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775744_1004]
2020-04-02 05:11:06,247 [IPC Server handler 6 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:11:08,062 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:08,062 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:08,062 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:08,063 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:08,063 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:11:11,064 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:11,064 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:11,064 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:11,064 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:11,065 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[3]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[3]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[4]
[msx] perform reset as unitTestCounterInClass 4 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:11:11,730 [Thread-589] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithBlockCorrupted(203)) - testReadWithBlockCorrupted: file = /deleted_2_1, dataBlkDelNum = 2, parityBlkDelNum = 1, deleteBlockFile? true
2020-04-02 05:11:11,783 [IPC Server handler 9 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/deleted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:11:11,785 [IPC Server handler 1 on 41191] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /deleted_2_1 for DFSClient_NONMAPREDUCE_-1389971812_1 at 127.0.0.1
2020-04-02 05:11:11,785 [IPC Server handler 1 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/deleted_2_1, holder=DFSClient_NONMAPREDUCE_-1389971812_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:11:11,787 [IPC Server handler 1 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: deleted_2_1 is added
2020-04-02 05:11:11,787 [IPC Server handler 1 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /deleted_2_1 inode 16390 DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:11:11,787 [IPC Server handler 1 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/deleted_2_1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:11:11,808 [IPC Server handler 4 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /deleted_2_1  inodeId 16390 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:11:11,809 [IPC Server handler 4 on 41191] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:11:11,811 [IPC Server handler 4 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /deleted_2_1 with blk_-9223372036854775728_1005 block is added to the in-memory file system
2020-04-02 05:11:11,811 [IPC Server handler 4 on 41191] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775728_1005, replicas=127.0.0.1:38003, 127.0.0.1:38083, 127.0.0.1:33488, 127.0.0.1:34596, 127.0.0.1:45304, 127.0.0.1:39776, 127.0.0.1:45517, 127.0.0.1:33931, 127.0.0.1:41818 for /deleted_2_1
2020-04-02 05:11:11,811 [IPC Server handler 4 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /deleted_2_1 with new block blk_-9223372036854775728_1005, current total block count is 1
2020-04-02 05:11:11,815 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:42622 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005 src: /127.0.0.1:42622 dest: /127.0.0.1:38003
2020-04-02 05:11:11,819 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49748 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005 src: /127.0.0.1:49748 dest: /127.0.0.1:38083
2020-04-02 05:11:11,840 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:58562 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775726_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775726_1005 src: /127.0.0.1:58562 dest: /127.0.0.1:33488
2020-04-02 05:11:11,857 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49874 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775725_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775725_1005 src: /127.0.0.1:49874 dest: /127.0.0.1:34596
2020-04-02 05:11:11,868 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:48894 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775724_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775724_1005 src: /127.0.0.1:48894 dest: /127.0.0.1:45304
2020-04-02 05:11:11,877 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49696 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775723_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775723_1005 src: /127.0.0.1:49696 dest: /127.0.0.1:39776
2020-04-02 05:11:11,930 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:39382 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005 src: /127.0.0.1:39382 dest: /127.0.0.1:45517
2020-04-02 05:11:11,942 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:53328 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775721_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775721_1005 src: /127.0.0.1:53328 dest: /127.0.0.1:33931
2020-04-02 05:11:11,963 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:52752 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775720_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775720_1005 src: /127.0.0.1:52752 dest: /127.0.0.1:41818
2020-04-02 05:11:12,057 [IPC Server handler 2 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:41818, datanodeUuid=138c0d7d-7e58-4339-8b75-15c135daf76d, infoPort=42795, infoSecurePort=0, ipcPort=43620, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:11:12,057 [IPC Server handler 5 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:11:12,057 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775720_1005 on 127.0.0.1:41818 size 4194304 replicaState = RBW
2020-04-02 05:11:12,057 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:12,057 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775720_1005 is received from 127.0.0.1:41818
2020-04-02 05:11:12,057 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:41818 receiving: 1, received: 0, deleted: 0
2020-04-02 05:11:12,057 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775728_1005 on 127.0.0.1:38003 size 4194304 replicaState = RBW
2020-04-02 05:11:12,057 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:12,058 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775728_1005 is received from 127.0.0.1:38003
2020-04-02 05:11:12,058 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38003 receiving: 1, received: 0, deleted: 0
2020-04-02 05:11:12,173 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42622, dest: /127.0.0.1:38003, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005, duration(ns): 354498239
2020-04-02 05:11:12,173 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:12,174 [IPC Server handler 0 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:11:12,175 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775728_1005 on 127.0.0.1:38003 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:12,176 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:12,176 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38003 is added to blk_-9223372036854775728_1005 (size=0)
2020-04-02 05:11:12,176 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49748, dest: /127.0.0.1:38083, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 3d038cc2-f80f-4a72-8c2c-febccfb87908, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005, duration(ns): 344980094
2020-04-02 05:11:12,176 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775728_1005 is received from 127.0.0.1:38003
2020-04-02 05:11:12,176 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38003 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:12,176 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:12,177 [IPC Server handler 3 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38083, datanodeUuid=3d038cc2-f80f-4a72-8c2c-febccfb87908, infoPort=37146, infoSecurePort=0, ipcPort=37392, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:11:12,178 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775727_1005 on 127.0.0.1:38083 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:12,178 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775726_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58562, dest: /127.0.0.1:33488, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: f1177179-f009-4517-a835-ba14c97e85ff, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775726_1005, duration(ns): 333609694
2020-04-02 05:11:12,178 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:12,178 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775726_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775726_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:12,178 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38083 is added to blk_-9223372036854775728_1005 (size=0)
2020-04-02 05:11:12,178 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775727_1005 is received from 127.0.0.1:38083
2020-04-02 05:11:12,179 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38083 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:12,179 [IPC Server handler 6 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33488, datanodeUuid=f1177179-f009-4517-a835-ba14c97e85ff, infoPort=42409, infoSecurePort=0, ipcPort=46631, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:11:12,180 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775725_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49874, dest: /127.0.0.1:34596, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 690f7552-c4c3-4286-845f-64b6525bf551, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775725_1005, duration(ns): 320373720
2020-04-02 05:11:12,180 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775725_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775725_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:12,180 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775726_1005 on 127.0.0.1:33488 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:12,180 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:12,181 [IPC Server handler 9 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34596, datanodeUuid=690f7552-c4c3-4286-845f-64b6525bf551, infoPort=44049, infoSecurePort=0, ipcPort=36235, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:11:12,181 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33488 is added to blk_-9223372036854775728_1005 (size=0)
2020-04-02 05:11:12,182 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775726_1005 is received from 127.0.0.1:33488
2020-04-02 05:11:12,182 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33488 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:12,182 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775725_1005 on 127.0.0.1:34596 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:12,182 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:12,182 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34596 is added to blk_-9223372036854775728_1005 (size=0)
2020-04-02 05:11:12,182 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775725_1005 is received from 127.0.0.1:34596
2020-04-02 05:11:12,182 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34596 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:12,183 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775724_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:48894, dest: /127.0.0.1:45304, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 31f7c920-c39d-4ae7-b315-1227a3caafd0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775724_1005, duration(ns): 311580593
2020-04-02 05:11:12,183 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775724_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775724_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:12,184 [IPC Server handler 1 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45304, datanodeUuid=31f7c920-c39d-4ae7-b315-1227a3caafd0, infoPort=37250, infoSecurePort=0, ipcPort=45067, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:11:12,185 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775724_1005 on 127.0.0.1:45304 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:12,185 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:12,185 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775723_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49696, dest: /127.0.0.1:39776, bytes: 4194181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: ca9828e1-172e-4a2c-a1a8-917b3485899c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775723_1005, duration(ns): 305165562
2020-04-02 05:11:12,185 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45304 is added to blk_-9223372036854775728_1005 (size=0)
2020-04-02 05:11:12,185 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775724_1005 is received from 127.0.0.1:45304
2020-04-02 05:11:12,185 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45304 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:12,185 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775723_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775723_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:12,186 [IPC Server handler 4 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:11:12,186 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775723_1005 on 127.0.0.1:39776 size 4194181 replicaState = FINALIZED
2020-04-02 05:11:12,186 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:12,186 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39776 is added to blk_-9223372036854775728_1005 (size=0)
2020-04-02 05:11:12,187 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775723_1005 is received from 127.0.0.1:39776
2020-04-02 05:11:12,187 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39776 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:12,187 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39382, dest: /127.0.0.1:45517, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005, duration(ns): 254184526
2020-04-02 05:11:12,187 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:12,188 [IPC Server handler 7 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45517, datanodeUuid=30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, infoPort=41207, infoSecurePort=0, ipcPort=44568, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:11:12,188 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775722_1005 on 127.0.0.1:45517 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:12,189 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:12,189 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775721_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53328, dest: /127.0.0.1:33931, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 04fa600d-9223-4e33-b0a1-d4242966c7f0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775721_1005, duration(ns): 243823369
2020-04-02 05:11:12,189 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45517 is added to blk_-9223372036854775728_1005 (size=0)
2020-04-02 05:11:12,189 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775721_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775721_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:12,189 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775722_1005 is received from 127.0.0.1:45517
2020-04-02 05:11:12,189 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45517 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:12,190 [IPC Server handler 8 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33931, datanodeUuid=04fa600d-9223-4e33-b0a1-d4242966c7f0, infoPort=45217, infoSecurePort=0, ipcPort=38205, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:11:12,191 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775721_1005 on 127.0.0.1:33931 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:12,191 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:12,191 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775720_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52752, dest: /127.0.0.1:41818, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 138c0d7d-7e58-4339-8b75-15c135daf76d, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775720_1005, duration(ns): 218568484
2020-04-02 05:11:12,191 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33931 is added to blk_-9223372036854775728_1005 (size=0)
2020-04-02 05:11:12,191 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775720_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775720_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:12,191 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775721_1005 is received from 127.0.0.1:33931
2020-04-02 05:11:12,191 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33931 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:12,192 [IPC Server handler 2 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:41818, datanodeUuid=138c0d7d-7e58-4339-8b75-15c135daf76d, infoPort=42795, infoSecurePort=0, ipcPort=43620, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:11:12,192 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775720_1005 on 127.0.0.1:41818 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:12,192 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:12,192 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:41818 is added to blk_-9223372036854775728_1005 (size=0)
2020-04-02 05:11:12,192 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775720_1005 is received from 127.0.0.1:41818
2020-04-02 05:11:12,192 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:41818 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:12,193 [IPC Server handler 5 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /deleted_2_1 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:11:12,193 [IPC Server handler 5 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /deleted_2_1 with 1 blocks is persisted to the file system
2020-04-02 05:11:12,193 [IPC Server handler 5 on 41191] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /deleted_2_1 is closed by DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:11:12,194 [Thread-589] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(231)) - corruptBlocks on path /deleted_2_1
2020-04-02 05:11:12,197 [IPC Server handler 0 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775728_1005]
2020-04-02 05:11:12,197 [IPC Server handler 0 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:11:12,199 [Thread-589] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(258)) - Deleting block file BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005
2020-04-02 05:11:12,200 [Thread-589] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,200 [Thread-589] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,208 [Thread-589] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,208 [Thread-589] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,209 [Thread-589] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,209 [Thread-589] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,209 [Thread-589] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,210 [Thread-589] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:deleteData(153)) - Deleting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775727
2020-04-02 05:11:12,212 [Thread-589] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,212 [Thread-589] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(258)) - Deleting block file BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005
2020-04-02 05:11:12,212 [Thread-589] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,213 [Thread-589] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,213 [Thread-589] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,214 [Thread-589] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,214 [Thread-589] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,214 [Thread-589] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:deleteData(153)) - Deleting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775728
2020-04-02 05:11:12,216 [Thread-589] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,217 [Thread-589] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,217 [Thread-589] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,217 [Thread-589] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(258)) - Deleting block file BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005
2020-04-02 05:11:12,217 [Thread-589] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,218 [Thread-589] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,218 [Thread-589] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,219 [Thread-589] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:deleteData(153)) - Deleting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775722
2020-04-02 05:11:12,220 [Thread-589] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,221 [Thread-589] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,221 [Thread-589] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,225 [Thread-589] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,225 [Thread-589] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,225 [Thread-589] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /deleted_2_1
2020-04-02 05:11:12,229 [Thread-589] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /deleted_2_1
2020-04-02 05:11:12,230 [IPC Server handler 7 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/deleted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:11:12,231 [Thread-589] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /deleted_2_1
2020-04-02 05:11:12,231 [IPC Server handler 8 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:11:12,232 [IPC Server handler 2 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775728_1005]
2020-04-02 05:11:12,233 [IPC Server handler 2 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:11:12,270 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:42476 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005]] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775728_1005 replica FinalizedReplica, blk_-9223372036854775728_1005, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775728 for deletion
2020-04-02 05:11:12,271 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:42476 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005]] INFO  datanode.DataNode (DataXceiver.java:readBlock(598)) - opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005 received exception java.io.FileNotFoundException: BlockId -9223372036854775728 is not valid.
2020-04-02 05:11:12,271 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775728_1005 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775728
2020-04-02 05:11:12,271 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:42476 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005]] WARN  datanode.DataNode (DataXceiver.java:readBlock(643)) - DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366):Got exception while serving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005 to /127.0.0.1:42476
java.io.FileNotFoundException: BlockId -9223372036854775728 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:11:12,273 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:42476 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005]] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:38003:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:42476 dst: /127.0.0.1:38003
java.io.FileNotFoundException: BlockId -9223372036854775728 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:11:12,273 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:42640 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005]] INFO  datanode.DataNode (DataXceiver.java:readBlock(598)) - opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005
2020-04-02 05:11:12,274 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:42640 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005]] WARN  datanode.DataNode (DataXceiver.java:readBlock(643)) - DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366):Got exception while serving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005 to /127.0.0.1:42640
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.getReplica(BlockSender.java:492)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:256)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:11:12,274 [Thread-589] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005, for OP_READ_BLOCK, self=/127.0.0.1:42640, remote=/127.0.0.1:38003, for file /deleted_2_1, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775728_1005
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,274 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:42640 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005]] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:38003:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:42640 dst: /127.0.0.1:38003
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.getReplica(BlockSender.java:492)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:256)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:11:12,275 [Thread-589] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:38003 for blockBP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775728_1005, for OP_READ_BLOCK, self=/127.0.0.1:42640, remote=/127.0.0.1:38003, for file /deleted_2_1, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775728_1005
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,275 [IPC Server handler 5 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775728_1005]
2020-04-02 05:11:12,276 [IPC Server handler 5 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:11:12,277 [Thread-589] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:38003,DS-cd20bec6-61af-4cee-a017-bfc56735fa58,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:11:12,279 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49766 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005]] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775727_1005 replica FinalizedReplica, blk_-9223372036854775727_1005, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775727 for deletion
2020-04-02 05:11:12,279 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49766 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005]] INFO  datanode.DataNode (DataXceiver.java:readBlock(598)) - opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005 received exception java.io.FileNotFoundException: BlockId -9223372036854775727 is not valid.
2020-04-02 05:11:12,280 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49766 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005]] WARN  datanode.DataNode (DataXceiver.java:readBlock(643)) - DatanodeRegistration(127.0.0.1:38083, datanodeUuid=3d038cc2-f80f-4a72-8c2c-febccfb87908, infoPort=37146, infoSecurePort=0, ipcPort=37392, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366):Got exception while serving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005 to /127.0.0.1:49766
java.io.FileNotFoundException: BlockId -9223372036854775727 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:11:12,280 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775727_1005 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775727
2020-04-02 05:11:12,280 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49766 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005]] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:38083:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:49766 dst: /127.0.0.1:38083
java.io.FileNotFoundException: BlockId -9223372036854775727 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:11:12,280 [Thread-589] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005 received exception java.io.FileNotFoundException: BlockId -9223372036854775727 is not valid., for OP_READ_BLOCK, self=/127.0.0.1:49766, remote=/127.0.0.1:38083, for file /deleted_2_1, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775727_1005
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,281 [Thread-589] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:38083 for blockBP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775727_1005 received exception java.io.FileNotFoundException: BlockId -9223372036854775727 is not valid., for OP_READ_BLOCK, self=/127.0.0.1:49766, remote=/127.0.0.1:38083, for file /deleted_2_1, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775727_1005
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,282 [IPC Server handler 0 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775728_1005]
2020-04-02 05:11:12,282 [IPC Server handler 0 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:11:12,283 [Thread-589] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:38083,DS-f29fcc8c-4f45-47a4-addd-01231a8988bd,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:11:12,289 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:39222 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005]] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775722_1005 replica FinalizedReplica, blk_-9223372036854775722_1005, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775722 for deletion
2020-04-02 05:11:12,290 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:39222 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005]] INFO  datanode.DataNode (DataXceiver.java:readBlock(598)) - opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005 received exception java.io.FileNotFoundException: BlockId -9223372036854775722 is not valid.
2020-04-02 05:11:12,290 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:39222 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005]] WARN  datanode.DataNode (DataXceiver.java:readBlock(643)) - DatanodeRegistration(127.0.0.1:45517, datanodeUuid=30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, infoPort=41207, infoSecurePort=0, ipcPort=44568, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366):Got exception while serving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005 to /127.0.0.1:39222
java.io.FileNotFoundException: BlockId -9223372036854775722 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:11:12,290 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775722_1005 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775722
2020-04-02 05:11:12,290 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:39222 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005]] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:45517:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:39222 dst: /127.0.0.1:45517
java.io.FileNotFoundException: BlockId -9223372036854775722 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:11:12,295 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:39396 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005]] INFO  datanode.DataNode (DataXceiver.java:readBlock(598)) - opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005
2020-04-02 05:11:12,295 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:39396 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005]] WARN  datanode.DataNode (DataXceiver.java:readBlock(643)) - DatanodeRegistration(127.0.0.1:45517, datanodeUuid=30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, infoPort=41207, infoSecurePort=0, ipcPort=44568, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366):Got exception while serving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005 to /127.0.0.1:39396
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.getReplica(BlockSender.java:492)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:256)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:11:12,295 [Thread-589] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005, for OP_READ_BLOCK, self=/127.0.0.1:39396, remote=/127.0.0.1:45517, for file /deleted_2_1, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775722_1005
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:203)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:340)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,295 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:39396 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005]] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:45517:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:39396 dst: /127.0.0.1:45517
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.getReplica(BlockSender.java:492)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:256)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:11:12,296 [Thread-589] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:45517 for blockBP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775722_1005, for OP_READ_BLOCK, self=/127.0.0.1:39396, remote=/127.0.0.1:45517, for file /deleted_2_1, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775722_1005
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:203)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:340)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:12,297 [IPC Server handler 3 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775728_1005]
2020-04-02 05:11:12,298 [IPC Server handler 3 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:11:12,300 [Thread-589] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:45517,DS-bd9fc205-c45f-48b9-85ed-311ae68dcf33,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:11:12,931 [IPC Server handler 6 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38083, datanodeUuid=3d038cc2-f80f-4a72-8c2c-febccfb87908, infoPort=37146, infoSecurePort=0, ipcPort=37392, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:11:12,931 [Block report processor] DEBUG BlockStateChange (BlockManager.java:removeStoredBlock(3781)) - BLOCK* removeStoredBlock: blk_-9223372036854775728_1005 from 127.0.0.1:38083
2020-04-02 05:11:12,931 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775728_1005 curReplicas 8 curExpectedReplicas 9 oldReplicas 9 oldExpectedReplicas  9 curPri  2 oldPri  3
2020-04-02 05:11:12,932 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775728_1005 has only 8 replicas and needs 9 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:11:12,932 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block DELETED_BLOCK: blk_-9223372036854775727_1005 is received from 127.0.0.1:38083
2020-04-02 05:11:12,932 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38083 receiving: 0, received: 0, deleted: 1
2020-04-02 05:11:14,065 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:14,065 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:14,065 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:14,066 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:14,066 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:14,066 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:11:15,056 [IPC Server handler 1 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:11:15,056 [Block report processor] DEBUG BlockStateChange (BlockManager.java:removeStoredBlock(3781)) - BLOCK* removeStoredBlock: blk_-9223372036854775728_1005 from 127.0.0.1:38003
2020-04-02 05:11:15,057 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775728_1005 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-04-02 05:11:15,057 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775728_1005 from priority queue 2
2020-04-02 05:11:15,057 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775728_1005 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-04-02 05:11:15,057 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block DELETED_BLOCK: blk_-9223372036854775728_1005 is received from 127.0.0.1:38003
2020-04-02 05:11:15,057 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38003 receiving: 0, received: 0, deleted: 1
2020-04-02 05:11:15,226 [IPC Server handler 9 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45517, datanodeUuid=30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, infoPort=41207, infoSecurePort=0, ipcPort=44568, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:11:15,227 [Block report processor] DEBUG BlockStateChange (BlockManager.java:removeStoredBlock(3781)) - BLOCK* removeStoredBlock: blk_-9223372036854775728_1005 from 127.0.0.1:45517
2020-04-02 05:11:15,227 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775728_1005 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:11:15,227 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775728_1005 from priority queue 1
2020-04-02 05:11:15,227 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775728_1005 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:11:15,227 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block DELETED_BLOCK: blk_-9223372036854775722_1005 is received from 127.0.0.1:45517
2020-04-02 05:11:15,227 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45517 receiving: 0, received: 0, deleted: 1
2020-04-02 05:11:17,066 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:17,066 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:17,066 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:17,067 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:17,067 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:17,067 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:11:20,067 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:20,068 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:20,068 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:20,068 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:20,068 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:20,069 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:11:23,069 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:23,070 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:23,070 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:23,070 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:23,071 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:23,071 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:11:26,071 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:26,071 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:26,072 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:26,072 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:26,072 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:26,072 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:11:26,628 [Thread-589] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /deleted_2_1
2020-04-02 05:11:26,637 [IPC Server handler 7 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775728_1005]
2020-04-02 05:11:26,638 [IPC Server handler 7 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:11:29,073 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:29,073 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:29,073 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:29,074 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:29,074 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:29,074 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:11:30,359 [Thread-589] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /deleted_2_1
2020-04-02 05:11:30,374 [IPC Server handler 7 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775728_1005]
2020-04-02 05:11:30,375 [IPC Server handler 7 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:11:32,075 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:32,075 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:32,075 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:32,076 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:32,076 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:32,076 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:11:34,368 [Thread-589] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /deleted_2_1
2020-04-02 05:11:34,370 [IPC Server handler 1 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775728_1005]
2020-04-02 05:11:34,374 [IPC Server handler 1 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:11:35,077 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:35,077 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:35,078 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:35,078 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:35,078 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:35,078 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:11:38,078 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:38,078 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:38,079 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:38,079 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:38,079 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:38,079 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[4]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[4]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
[msx] perform reset as unitTestCounterInClass 5 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:11:39,749 [Thread-633] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithBlockCorrupted(203)) - testReadWithBlockCorrupted: file = /deleted_3_0, dataBlkDelNum = 3, parityBlkDelNum = 0, deleteBlockFile? true
2020-04-02 05:11:39,812 [IPC Server handler 4 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/deleted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:11:39,817 [IPC Server handler 3 on 41191] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /deleted_3_0 for DFSClient_NONMAPREDUCE_-1389971812_1 at 127.0.0.1
2020-04-02 05:11:39,817 [IPC Server handler 3 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/deleted_3_0, holder=DFSClient_NONMAPREDUCE_-1389971812_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:11:39,818 [IPC Server handler 3 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: deleted_3_0 is added
2020-04-02 05:11:39,819 [IPC Server handler 3 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /deleted_3_0 inode 16391 DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:11:39,819 [IPC Server handler 3 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/deleted_3_0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:11:39,819 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 29 Total time for transactions(ms): 35 Number of transactions batched in Syncs: 4 Number of syncs: 25 SyncTimes(ms): 1 1 
2020-04-02 05:11:39,849 [IPC Server handler 8 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /deleted_3_0  inodeId 16391 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:11:39,850 [IPC Server handler 8 on 41191] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:11:39,853 [IPC Server handler 8 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /deleted_3_0 with blk_-9223372036854775712_1006 block is added to the in-memory file system
2020-04-02 05:11:39,853 [IPC Server handler 8 on 41191] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775712_1006, replicas=127.0.0.1:34596, 127.0.0.1:41818, 127.0.0.1:39776, 127.0.0.1:45304, 127.0.0.1:38083, 127.0.0.1:38003, 127.0.0.1:33931, 127.0.0.1:33488, 127.0.0.1:45517 for /deleted_3_0
2020-04-02 05:11:39,853 [IPC Server handler 8 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /deleted_3_0 with new block blk_-9223372036854775712_1006, current total block count is 1
2020-04-02 05:11:39,861 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50028 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006 src: /127.0.0.1:50028 dest: /127.0.0.1:34596
2020-04-02 05:11:39,862 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:52898 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775711_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775711_1006 src: /127.0.0.1:52898 dest: /127.0.0.1:41818
2020-04-02 05:11:39,875 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49850 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006 src: /127.0.0.1:49850 dest: /127.0.0.1:39776
2020-04-02 05:11:39,890 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49052 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775709_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775709_1006 src: /127.0.0.1:49052 dest: /127.0.0.1:45304
2020-04-02 05:11:39,897 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49914 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775708_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775708_1006 src: /127.0.0.1:49914 dest: /127.0.0.1:38083
2020-04-02 05:11:39,906 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:42792 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006 src: /127.0.0.1:42792 dest: /127.0.0.1:38003
2020-04-02 05:11:39,934 [IPC Server handler 9 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38083, datanodeUuid=3d038cc2-f80f-4a72-8c2c-febccfb87908, infoPort=37146, infoSecurePort=0, ipcPort=37392, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:11:39,934 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775708_1006 on 127.0.0.1:38083 size 4194304 replicaState = RBW
2020-04-02 05:11:39,934 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:39,934 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775708_1006 is received from 127.0.0.1:38083
2020-04-02 05:11:39,934 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38083 receiving: 1, received: 0, deleted: 0
2020-04-02 05:11:39,954 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:53486 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775706_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775706_1006 src: /127.0.0.1:53486 dest: /127.0.0.1:33931
2020-04-02 05:11:39,961 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:58732 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775705_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775705_1006 src: /127.0.0.1:58732 dest: /127.0.0.1:33488
2020-04-02 05:11:39,973 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:39546 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775704_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775704_1006 src: /127.0.0.1:39546 dest: /127.0.0.1:45517
2020-04-02 05:11:40,115 [IPC Server handler 0 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33931, datanodeUuid=04fa600d-9223-4e33-b0a1-d4242966c7f0, infoPort=45217, infoSecurePort=0, ipcPort=38205, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:11:40,115 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775706_1006 on 127.0.0.1:33931 size 4194304 replicaState = RBW
2020-04-02 05:11:40,116 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:40,116 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775706_1006 is received from 127.0.0.1:33931
2020-04-02 05:11:40,116 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33931 receiving: 1, received: 0, deleted: 0
2020-04-02 05:11:40,177 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50028, dest: /127.0.0.1:34596, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 690f7552-c4c3-4286-845f-64b6525bf551, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006, duration(ns): 312028055
2020-04-02 05:11:40,177 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:40,177 [IPC Server handler 7 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34596, datanodeUuid=690f7552-c4c3-4286-845f-64b6525bf551, infoPort=44049, infoSecurePort=0, ipcPort=36235, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:11:40,179 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775712_1006 on 127.0.0.1:34596 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:40,179 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:40,182 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34596 is added to blk_-9223372036854775712_1006 (size=0)
2020-04-02 05:11:40,182 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775711_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52898, dest: /127.0.0.1:41818, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 138c0d7d-7e58-4339-8b75-15c135daf76d, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775711_1006, duration(ns): 311915495
2020-04-02 05:11:40,182 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775712_1006 is received from 127.0.0.1:34596
2020-04-02 05:11:40,182 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775711_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775711_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:40,182 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34596 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:40,182 [IPC Server handler 1 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:41818, datanodeUuid=138c0d7d-7e58-4339-8b75-15c135daf76d, infoPort=42795, infoSecurePort=0, ipcPort=43620, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:11:40,183 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775711_1006 on 127.0.0.1:41818 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:40,183 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:40,184 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:41818 is added to blk_-9223372036854775712_1006 (size=0)
2020-04-02 05:11:40,184 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775711_1006 is received from 127.0.0.1:41818
2020-04-02 05:11:40,184 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49850, dest: /127.0.0.1:39776, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: ca9828e1-172e-4a2c-a1a8-917b3485899c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006, duration(ns): 305590801
2020-04-02 05:11:40,184 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:41818 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:40,184 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:40,184 [IPC Server handler 2 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:11:40,184 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775710_1006 on 127.0.0.1:39776 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:40,185 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:40,185 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39776 is added to blk_-9223372036854775712_1006 (size=0)
2020-04-02 05:11:40,185 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775710_1006 is received from 127.0.0.1:39776
2020-04-02 05:11:40,185 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39776 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:40,186 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775709_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49052, dest: /127.0.0.1:45304, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 31f7c920-c39d-4ae7-b315-1227a3caafd0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775709_1006, duration(ns): 294401635
2020-04-02 05:11:40,186 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775709_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775709_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:40,187 [IPC Server handler 4 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45304, datanodeUuid=31f7c920-c39d-4ae7-b315-1227a3caafd0, infoPort=37250, infoSecurePort=0, ipcPort=45067, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:11:40,187 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775709_1006 on 127.0.0.1:45304 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:40,187 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:40,187 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45304 is added to blk_-9223372036854775712_1006 (size=0)
2020-04-02 05:11:40,187 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775708_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49914, dest: /127.0.0.1:38083, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 3d038cc2-f80f-4a72-8c2c-febccfb87908, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775708_1006, duration(ns): 288933142
2020-04-02 05:11:40,187 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775709_1006 is received from 127.0.0.1:45304
2020-04-02 05:11:40,188 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45304 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:40,188 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775708_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775708_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:40,189 [IPC Server handler 3 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38083, datanodeUuid=3d038cc2-f80f-4a72-8c2c-febccfb87908, infoPort=37146, infoSecurePort=0, ipcPort=37392, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:11:40,189 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775708_1006 on 127.0.0.1:38083 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:40,189 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:40,189 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42792, dest: /127.0.0.1:38003, bytes: 4194181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006, duration(ns): 281512558
2020-04-02 05:11:40,189 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38083 is added to blk_-9223372036854775712_1006 (size=0)
2020-04-02 05:11:40,189 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:40,189 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775708_1006 is received from 127.0.0.1:38083
2020-04-02 05:11:40,189 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38083 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:40,191 [IPC Server handler 8 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:11:40,191 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775707_1006 on 127.0.0.1:38003 size 4194181 replicaState = FINALIZED
2020-04-02 05:11:40,191 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:40,191 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38003 is added to blk_-9223372036854775712_1006 (size=0)
2020-04-02 05:11:40,191 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775706_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53486, dest: /127.0.0.1:33931, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 04fa600d-9223-4e33-b0a1-d4242966c7f0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775706_1006, duration(ns): 235608260
2020-04-02 05:11:40,191 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775707_1006 is received from 127.0.0.1:38003
2020-04-02 05:11:40,192 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775706_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775706_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:40,192 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38003 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:40,193 [IPC Server handler 6 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33931, datanodeUuid=04fa600d-9223-4e33-b0a1-d4242966c7f0, infoPort=45217, infoSecurePort=0, ipcPort=38205, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:11:40,193 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775706_1006 on 127.0.0.1:33931 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:40,193 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:40,193 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775705_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58732, dest: /127.0.0.1:33488, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: f1177179-f009-4517-a835-ba14c97e85ff, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775705_1006, duration(ns): 230268591
2020-04-02 05:11:40,193 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33931 is added to blk_-9223372036854775712_1006 (size=0)
2020-04-02 05:11:40,194 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775705_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775705_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:40,194 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775706_1006 is received from 127.0.0.1:33931
2020-04-02 05:11:40,194 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33931 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:40,194 [IPC Server handler 9 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33488, datanodeUuid=f1177179-f009-4517-a835-ba14c97e85ff, infoPort=42409, infoSecurePort=0, ipcPort=46631, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:11:40,195 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775705_1006 on 127.0.0.1:33488 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:40,195 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:40,195 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33488 is added to blk_-9223372036854775712_1006 (size=0)
2020-04-02 05:11:40,195 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775704_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39546, dest: /127.0.0.1:45517, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775704_1006, duration(ns): 221044904
2020-04-02 05:11:40,195 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775705_1006 is received from 127.0.0.1:33488
2020-04-02 05:11:40,196 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775704_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775704_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:40,196 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33488 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:40,196 [IPC Server handler 5 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45517, datanodeUuid=30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, infoPort=41207, infoSecurePort=0, ipcPort=44568, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:11:40,201 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775704_1006 on 127.0.0.1:45517 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:40,203 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:40,203 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45517 is added to blk_-9223372036854775712_1006 (size=0)
2020-04-02 05:11:40,203 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775704_1006 is received from 127.0.0.1:45517
2020-04-02 05:11:40,203 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45517 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:40,203 [IPC Server handler 0 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /deleted_3_0 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:11:40,204 [IPC Server handler 0 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /deleted_3_0 with 1 blocks is persisted to the file system
2020-04-02 05:11:40,204 [IPC Server handler 0 on 41191] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /deleted_3_0 is closed by DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:11:40,208 [Thread-633] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(231)) - corruptBlocks on path /deleted_3_0
2020-04-02 05:11:40,210 [IPC Server handler 7 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775712_1006]
2020-04-02 05:11:40,210 [IPC Server handler 7 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:11:40,212 [Thread-633] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(258)) - Deleting block file BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006
2020-04-02 05:11:40,213 [Thread-633] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:deleteData(153)) - Deleting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775712
2020-04-02 05:11:40,215 [Thread-633] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,216 [Thread-633] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,216 [Thread-633] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,217 [Thread-633] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,217 [Thread-633] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,217 [Thread-633] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,218 [Thread-633] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,218 [Thread-633] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,218 [Thread-633] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(258)) - Deleting block file BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006
2020-04-02 05:11:40,219 [Thread-633] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,219 [Thread-633] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,219 [Thread-633] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,220 [Thread-633] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,220 [Thread-633] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,220 [Thread-633] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:deleteData(153)) - Deleting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775707
2020-04-02 05:11:40,222 [Thread-633] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,223 [Thread-633] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,223 [Thread-633] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,223 [Thread-633] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(258)) - Deleting block file BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006
2020-04-02 05:11:40,223 [Thread-633] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,224 [Thread-633] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:deleteData(153)) - Deleting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775710
2020-04-02 05:11:40,225 [Thread-633] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,226 [Thread-633] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,226 [Thread-633] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,226 [Thread-633] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,227 [Thread-633] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,227 [Thread-633] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,227 [Thread-633] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,228 [Thread-633] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /deleted_3_0
2020-04-02 05:11:40,242 [Thread-633] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /deleted_3_0
2020-04-02 05:11:40,243 [IPC Server handler 1 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/deleted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:11:40,244 [Thread-633] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /deleted_3_0
2020-04-02 05:11:40,244 [IPC Server handler 2 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:11:40,247 [IPC Server handler 4 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775712_1006]
2020-04-02 05:11:40,247 [IPC Server handler 4 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:11:40,263 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49798 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006]] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775712_1006 replica FinalizedReplica, blk_-9223372036854775712_1006, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775712 for deletion
2020-04-02 05:11:40,264 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49798 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006]] INFO  datanode.DataNode (DataXceiver.java:readBlock(598)) - opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006 received exception java.io.FileNotFoundException: BlockId -9223372036854775712 is not valid.
2020-04-02 05:11:40,265 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49798 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006]] WARN  datanode.DataNode (DataXceiver.java:readBlock(643)) - DatanodeRegistration(127.0.0.1:34596, datanodeUuid=690f7552-c4c3-4286-845f-64b6525bf551, infoPort=44049, infoSecurePort=0, ipcPort=36235, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366):Got exception while serving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006 to /127.0.0.1:49798
java.io.FileNotFoundException: BlockId -9223372036854775712 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:11:40,265 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775712_1006 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775712
2020-04-02 05:11:40,266 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49798 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006]] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:34596:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:49798 dst: /127.0.0.1:34596
java.io.FileNotFoundException: BlockId -9223372036854775712 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:11:40,267 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50046 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006]] INFO  datanode.DataNode (DataXceiver.java:readBlock(598)) - opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006
2020-04-02 05:11:40,267 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50046 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006]] WARN  datanode.DataNode (DataXceiver.java:readBlock(643)) - DatanodeRegistration(127.0.0.1:34596, datanodeUuid=690f7552-c4c3-4286-845f-64b6525bf551, infoPort=44049, infoSecurePort=0, ipcPort=36235, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366):Got exception while serving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006 to /127.0.0.1:50046
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.getReplica(BlockSender.java:492)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:256)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:11:40,267 [Thread-633] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006, for OP_READ_BLOCK, self=/127.0.0.1:50046, remote=/127.0.0.1:34596, for file /deleted_3_0, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775712_1006
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,268 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50046 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006]] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:34596:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:50046 dst: /127.0.0.1:34596
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.getReplica(BlockSender.java:492)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:256)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:11:40,269 [Thread-633] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:34596 for blockBP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775712_1006, for OP_READ_BLOCK, self=/127.0.0.1:50046, remote=/127.0.0.1:34596, for file /deleted_3_0, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775712_1006
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,270 [IPC Server handler 3 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775712_1006]
2020-04-02 05:11:40,271 [IPC Server handler 3 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:11:40,272 [Thread-633] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:34596,DS-244b1c01-4b44-4923-8631-0dc549a7ddde,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:11:40,274 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49710 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006]] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775710_1006 replica FinalizedReplica, blk_-9223372036854775710_1006, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775710 for deletion
2020-04-02 05:11:40,274 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49710 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006]] INFO  datanode.DataNode (DataXceiver.java:readBlock(598)) - opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006 received exception java.io.FileNotFoundException: BlockId -9223372036854775710 is not valid.
2020-04-02 05:11:40,274 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49710 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006]] WARN  datanode.DataNode (DataXceiver.java:readBlock(643)) - DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366):Got exception while serving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006 to /127.0.0.1:49710
java.io.FileNotFoundException: BlockId -9223372036854775710 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:11:40,274 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775710_1006 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775710
2020-04-02 05:11:40,275 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49710 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006]] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:39776:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:49710 dst: /127.0.0.1:39776
java.io.FileNotFoundException: BlockId -9223372036854775710 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:11:40,276 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49866 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006]] INFO  datanode.DataNode (DataXceiver.java:readBlock(598)) - opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006
2020-04-02 05:11:40,277 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49866 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006]] WARN  datanode.DataNode (DataXceiver.java:readBlock(643)) - DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366):Got exception while serving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006 to /127.0.0.1:49866
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.getReplica(BlockSender.java:492)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:256)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:11:40,277 [Thread-633] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006, for OP_READ_BLOCK, self=/127.0.0.1:49866, remote=/127.0.0.1:39776, for file /deleted_3_0, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775710_1006
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,277 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49866 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006]] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:39776:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:49866 dst: /127.0.0.1:39776
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.getReplica(BlockSender.java:492)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:256)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:11:40,278 [Thread-633] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:39776 for blockBP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775710_1006, for OP_READ_BLOCK, self=/127.0.0.1:49866, remote=/127.0.0.1:39776, for file /deleted_3_0, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775710_1006
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,279 [IPC Server handler 8 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775712_1006]
2020-04-02 05:11:40,280 [IPC Server handler 8 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:11:40,281 [Thread-633] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:39776,DS-c37ee172-cb9b-4f05-84aa-bcebbe58c663,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:11:40,284 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:42806 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006]] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775707_1006 replica FinalizedReplica, blk_-9223372036854775707_1006, FINALIZED
  getNumBytes()     = 4194181
  getBytesOnDisk()  = 4194181
  getVisibleLength()= 4194181
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775707 for deletion
2020-04-02 05:11:40,285 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:42806 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006]] INFO  datanode.DataNode (DataXceiver.java:readBlock(598)) - opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006 received exception java.io.FileNotFoundException: BlockId -9223372036854775707 is not valid.
2020-04-02 05:11:40,285 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:42806 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006]] WARN  datanode.DataNode (DataXceiver.java:readBlock(643)) - DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366):Got exception while serving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006 to /127.0.0.1:42806
java.io.FileNotFoundException: BlockId -9223372036854775707 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:11:40,285 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775707_1006 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775707
2020-04-02 05:11:40,285 [Thread-633] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006 received exception java.io.FileNotFoundException: BlockId -9223372036854775707 is not valid., for OP_READ_BLOCK, self=/127.0.0.1:42806, remote=/127.0.0.1:38003, for file /deleted_3_0, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775707_1006
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,286 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:42806 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006]] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:38003:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:42806 dst: /127.0.0.1:38003
java.io.FileNotFoundException: BlockId -9223372036854775707 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:11:40,288 [Thread-633] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:38003 for blockBP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775707_1006 received exception java.io.FileNotFoundException: BlockId -9223372036854775707 is not valid., for OP_READ_BLOCK, self=/127.0.0.1:42806, remote=/127.0.0.1:38003, for file /deleted_3_0, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775707_1006
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:40,289 [IPC Server handler 6 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775712_1006]
2020-04-02 05:11:40,289 [IPC Server handler 6 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:11:40,290 [Thread-633] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:38003,DS-8ed92d4e-a113-43e3-89fc-e65f907cbe5e,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:11:41,080 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:41,080 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:41,081 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:41,081 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:41,081 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:41,081 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:11:42,068 [IPC Server handler 0 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:11:42,068 [Block report processor] DEBUG BlockStateChange (BlockManager.java:removeStoredBlock(3781)) - BLOCK* removeStoredBlock: blk_-9223372036854775712_1006 from 127.0.0.1:38003
2020-04-02 05:11:42,069 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775712_1006 curReplicas 8 curExpectedReplicas 9 oldReplicas 9 oldExpectedReplicas  9 curPri  2 oldPri  3
2020-04-02 05:11:42,069 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775712_1006 has only 8 replicas and needs 9 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:11:42,069 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block DELETED_BLOCK: blk_-9223372036854775707_1006 is received from 127.0.0.1:38003
2020-04-02 05:11:42,069 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38003 receiving: 0, received: 0, deleted: 1
2020-04-02 05:11:42,226 [IPC Server handler 3 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34596, datanodeUuid=690f7552-c4c3-4286-845f-64b6525bf551, infoPort=44049, infoSecurePort=0, ipcPort=36235, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:11:42,226 [Block report processor] DEBUG BlockStateChange (BlockManager.java:removeStoredBlock(3781)) - BLOCK* removeStoredBlock: blk_-9223372036854775712_1006 from 127.0.0.1:34596
2020-04-02 05:11:42,226 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775712_1006 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-04-02 05:11:42,227 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775712_1006 from priority queue 2
2020-04-02 05:11:42,227 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775712_1006 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-04-02 05:11:42,227 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block DELETED_BLOCK: blk_-9223372036854775712_1006 is received from 127.0.0.1:34596
2020-04-02 05:11:42,227 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34596 receiving: 0, received: 0, deleted: 1
2020-04-02 05:11:42,228 [IPC Server handler 6 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:11:42,228 [Block report processor] DEBUG BlockStateChange (BlockManager.java:removeStoredBlock(3781)) - BLOCK* removeStoredBlock: blk_-9223372036854775712_1006 from 127.0.0.1:39776
2020-04-02 05:11:42,228 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775712_1006 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:11:42,228 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775712_1006 from priority queue 1
2020-04-02 05:11:42,229 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775712_1006 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:11:42,229 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block DELETED_BLOCK: blk_-9223372036854775710_1006 is received from 127.0.0.1:39776
2020-04-02 05:11:42,229 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39776 receiving: 0, received: 0, deleted: 1
2020-04-02 05:11:44,081 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:44,082 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:44,082 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:11:44,082 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:44,082 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:44,082 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:44,082 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 6 pendingReconstruction = 0
2020-04-02 05:11:47,086 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:47,086 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:47,087 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:11:47,087 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:47,087 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:47,087 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:47,087 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 6 pendingReconstruction = 0
2020-04-02 05:11:50,087 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:50,087 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:50,087 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:11:50,088 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:50,088 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:50,088 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:50,088 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 6 pendingReconstruction = 0
2020-04-02 05:11:53,088 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:53,088 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:53,088 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:11:53,088 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:53,089 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:53,089 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:53,089 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 6 pendingReconstruction = 0
2020-04-02 05:11:54,147 [Thread-633] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /deleted_3_0
2020-04-02 05:11:54,155 [IPC Server handler 4 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775712_1006]
2020-04-02 05:11:54,156 [IPC Server handler 4 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:11:56,089 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:56,089 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:56,090 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:11:56,090 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:56,090 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:56,090 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:56,090 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 6 pendingReconstruction = 0
2020-04-02 05:11:58,057 [Thread-633] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /deleted_3_0
2020-04-02 05:11:58,081 [IPC Server handler 4 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775712_1006]
2020-04-02 05:11:58,081 [IPC Server handler 4 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:11:59,090 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:59,090 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:59,090 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:11:59,091 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:59,091 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:59,091 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:59,091 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 6 pendingReconstruction = 0
2020-04-02 05:12:01,751 [Thread-633] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /deleted_3_0
2020-04-02 05:12:01,752 [IPC Server handler 1 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775712_1006]
2020-04-02 05:12:01,753 [IPC Server handler 1 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:12:02,091 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:02,091 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:02,091 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:02,091 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:12:02,091 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:02,092 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:12:02,092 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 6 pendingReconstruction = 0
2020-04-02 05:12:05,092 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:05,092 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:05,092 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:05,093 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:12:05,093 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:05,093 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:12:05,093 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 6 pendingReconstruction = 0
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[6]
[msx] perform reset as unitTestCounterInClass 6 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:12:06,888 [Thread-679] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithBlockCorrupted(203)) - testReadWithBlockCorrupted: file = /deleted_1_0, dataBlkDelNum = 1, parityBlkDelNum = 0, deleteBlockFile? true
2020-04-02 05:12:06,944 [IPC Server handler 2 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/deleted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:12:06,951 [IPC Server handler 7 on 41191] DEBUG hdfs.StateChange (NameNodeRpcServer.java:delete(1084)) - *DIR* Namenode.delete: src=/deleted_1_0, recursive=true
2020-04-02 05:12:06,954 [IPC Server handler 7 on 41191] DEBUG hdfs.StateChange (FSDirDeleteOp.java:deleteInternal(180)) - DIR* NameSystem.delete: /deleted_1_0
2020-04-02 05:12:06,954 [IPC Server handler 7 on 41191] DEBUG hdfs.StateChange (FSDirDeleteOp.java:delete(55)) - DIR* FSDirectory.delete: /deleted_1_0
2020-04-02 05:12:06,958 [IPC Server handler 7 on 41191] DEBUG hdfs.StateChange (FSDirDeleteOp.java:unprotectedDelete(269)) - DIR* FSDirectory.unprotectedDelete: /deleted_1_0 is removed
2020-04-02 05:12:06,960 [IPC Server handler 7 on 41191] DEBUG hdfs.StateChange (FSDirDeleteOp.java:deleteInternal(201)) - DIR* Namesystem.delete: /deleted_1_0 is removed
2020-04-02 05:12:06,960 [IPC Server handler 7 on 41191] DEBUG BlockStateChange (BlockManager.java:addToInvalidates(1598)) - BLOCK* addToInvalidates: blk_-9223372036854775792_1001 127.0.0.1:33931 127.0.0.1:33488 127.0.0.1:41818 127.0.0.1:34596 127.0.0.1:38083 127.0.0.1:38003 127.0.0.1:45304 127.0.0.1:45517 
2020-04-02 05:12:06,961 [IPC Server handler 7 on 41191] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 2
2020-04-02 05:12:06,961 [IPC Server handler 7 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/deleted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:12:06,966 [IPC Server handler 8 on 41191] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /deleted_1_0 for DFSClient_NONMAPREDUCE_-1389971812_1 at 127.0.0.1
2020-04-02 05:12:06,966 [IPC Server handler 8 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/deleted_1_0, holder=DFSClient_NONMAPREDUCE_-1389971812_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:12:06,966 [IPC Server handler 8 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: deleted_1_0 is added
2020-04-02 05:12:06,966 [IPC Server handler 8 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /deleted_1_0 inode 16392 DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:12:06,966 [IPC Server handler 8 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/deleted_1_0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:12:06,987 [IPC Server handler 6 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /deleted_1_0  inodeId 16392 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:12:06,988 [IPC Server handler 6 on 41191] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:12:06,989 [IPC Server handler 6 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /deleted_1_0 with blk_-9223372036854775696_1007 block is added to the in-memory file system
2020-04-02 05:12:06,990 [IPC Server handler 6 on 41191] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775696_1007, replicas=127.0.0.1:38083, 127.0.0.1:33931, 127.0.0.1:38003, 127.0.0.1:33488, 127.0.0.1:34596, 127.0.0.1:39776, 127.0.0.1:41818, 127.0.0.1:45304, 127.0.0.1:45517 for /deleted_1_0
2020-04-02 05:12:06,990 [IPC Server handler 6 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /deleted_1_0 with new block blk_-9223372036854775696_1007, current total block count is 1
2020-04-02 05:12:06,993 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50068 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775696_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775696_1007 src: /127.0.0.1:50068 dest: /127.0.0.1:38083
2020-04-02 05:12:06,997 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:53638 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775695_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775695_1007 src: /127.0.0.1:53638 dest: /127.0.0.1:33931
2020-04-02 05:12:07,013 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:42948 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775694_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775694_1007 src: /127.0.0.1:42948 dest: /127.0.0.1:38003
2020-04-02 05:12:07,028 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:58886 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775693_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775693_1007 src: /127.0.0.1:58886 dest: /127.0.0.1:33488
2020-04-02 05:12:07,033 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50198 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775692_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775692_1007 src: /127.0.0.1:50198 dest: /127.0.0.1:34596
2020-04-02 05:12:07,051 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50018 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775691_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775691_1007 src: /127.0.0.1:50018 dest: /127.0.0.1:39776
2020-04-02 05:12:07,099 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:53070 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775690_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775690_1007 src: /127.0.0.1:53070 dest: /127.0.0.1:41818
2020-04-02 05:12:07,111 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49222 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775689_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775689_1007 src: /127.0.0.1:49222 dest: /127.0.0.1:45304
2020-04-02 05:12:07,122 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:39708 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775688_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775688_1007 src: /127.0.0.1:39708 dest: /127.0.0.1:45517
2020-04-02 05:12:07,135 [IPC Server handler 9 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33931, datanodeUuid=04fa600d-9223-4e33-b0a1-d4242966c7f0, infoPort=45217, infoSecurePort=0, ipcPort=38205, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:07,135 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775695_1007 on 127.0.0.1:33931 size 4194304 replicaState = RBW
2020-04-02 05:12:07,138 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:07,138 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775695_1007 is received from 127.0.0.1:33931
2020-04-02 05:12:07,138 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33931 receiving: 1, received: 0, deleted: 0
2020-04-02 05:12:07,303 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775696_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50068, dest: /127.0.0.1:38083, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 3d038cc2-f80f-4a72-8c2c-febccfb87908, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775696_1007, duration(ns): 300984055
2020-04-02 05:12:07,303 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775696_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775696_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:07,307 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775692_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50198, dest: /127.0.0.1:34596, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 690f7552-c4c3-4286-845f-64b6525bf551, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775692_1007, duration(ns): 262706944
2020-04-02 05:12:07,307 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775695_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53638, dest: /127.0.0.1:33931, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 04fa600d-9223-4e33-b0a1-d4242966c7f0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775695_1007, duration(ns): 295069684
2020-04-02 05:12:07,308 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775692_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775692_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:07,308 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775695_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775695_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:07,308 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775690_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53070, dest: /127.0.0.1:41818, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 138c0d7d-7e58-4339-8b75-15c135daf76d, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775690_1007, duration(ns): 202278440
2020-04-02 05:12:07,308 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775690_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775690_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:07,308 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775688_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39708, dest: /127.0.0.1:45517, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775688_1007, duration(ns): 175596411
2020-04-02 05:12:07,308 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775694_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42948, dest: /127.0.0.1:38003, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775694_1007, duration(ns): 279087525
2020-04-02 05:12:07,309 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775688_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775688_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:07,309 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775694_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775694_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:07,309 [IPC Server handler 2 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45517, datanodeUuid=30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, infoPort=41207, infoSecurePort=0, ipcPort=44568, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:07,309 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775691_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50018, dest: /127.0.0.1:39776, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: ca9828e1-172e-4a2c-a1a8-917b3485899c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775691_1007, duration(ns): 249568152
2020-04-02 05:12:07,308 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775689_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49222, dest: /127.0.0.1:45304, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 31f7c920-c39d-4ae7-b315-1227a3caafd0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775689_1007, duration(ns): 186553218
2020-04-02 05:12:07,308 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775693_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58886, dest: /127.0.0.1:33488, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: f1177179-f009-4517-a835-ba14c97e85ff, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775693_1007, duration(ns): 266002069
2020-04-02 05:12:07,310 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775689_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775689_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:07,308 [IPC Server handler 4 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38083, datanodeUuid=3d038cc2-f80f-4a72-8c2c-febccfb87908, infoPort=37146, infoSecurePort=0, ipcPort=37392, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:07,310 [IPC Server handler 9 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:41818, datanodeUuid=138c0d7d-7e58-4339-8b75-15c135daf76d, infoPort=42795, infoSecurePort=0, ipcPort=43620, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:07,310 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775693_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775693_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:07,309 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775688_1007 on 127.0.0.1:45517 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:07,309 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775691_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775691_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:07,309 [IPC Server handler 3 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:07,309 [IPC Server handler 8 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33931, datanodeUuid=04fa600d-9223-4e33-b0a1-d4242966c7f0, infoPort=45217, infoSecurePort=0, ipcPort=38205, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:07,309 [IPC Server handler 7 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34596, datanodeUuid=690f7552-c4c3-4286-845f-64b6525bf551, infoPort=44049, infoSecurePort=0, ipcPort=36235, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:07,309 [IPC Server handler 6 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:07,311 [IPC Server handler 1 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33488, datanodeUuid=f1177179-f009-4517-a835-ba14c97e85ff, infoPort=42409, infoSecurePort=0, ipcPort=46631, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:07,311 [IPC Server handler 0 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45304, datanodeUuid=31f7c920-c39d-4ae7-b315-1227a3caafd0, infoPort=37250, infoSecurePort=0, ipcPort=45067, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:07,311 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:07,311 [IPC Server handler 5 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /deleted_1_0  inodeId 16392 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:12:07,312 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45517 is added to blk_-9223372036854775696_1007 (size=0)
2020-04-02 05:12:07,312 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775688_1007 is received from 127.0.0.1:45517
2020-04-02 05:12:07,312 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45517 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:07,312 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775696_1007 on 127.0.0.1:38083 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:07,313 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:07,313 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38083 is added to blk_-9223372036854775696_1007 (size=0)
2020-04-02 05:12:07,313 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775696_1007 is received from 127.0.0.1:38083
2020-04-02 05:12:07,313 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38083 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:07,313 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775690_1007 on 127.0.0.1:41818 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:07,313 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:07,313 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:41818 is added to blk_-9223372036854775696_1007 (size=0)
2020-04-02 05:12:07,313 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775690_1007 is received from 127.0.0.1:41818
2020-04-02 05:12:07,313 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:41818 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:07,313 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775691_1007 on 127.0.0.1:39776 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:07,313 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:07,314 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39776 is added to blk_-9223372036854775696_1007 (size=0)
2020-04-02 05:12:07,314 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775691_1007 is received from 127.0.0.1:39776
2020-04-02 05:12:07,314 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39776 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:07,314 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775695_1007 on 127.0.0.1:33931 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:07,314 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:07,314 [IPC Server handler 5 on 41191] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:12:07,314 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33931 is added to blk_-9223372036854775696_1007 (size=0)
2020-04-02 05:12:07,315 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775695_1007 is received from 127.0.0.1:33931
2020-04-02 05:12:07,315 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33931 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:07,315 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775692_1007 on 127.0.0.1:34596 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:07,315 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:07,315 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34596 is added to blk_-9223372036854775696_1007 (size=0)
2020-04-02 05:12:07,315 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775692_1007 is received from 127.0.0.1:34596
2020-04-02 05:12:07,315 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34596 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:07,315 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775694_1007 on 127.0.0.1:38003 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:07,315 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:07,315 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38003 is added to blk_-9223372036854775696_1007 (size=0)
2020-04-02 05:12:07,315 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775694_1007 is received from 127.0.0.1:38003
2020-04-02 05:12:07,316 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38003 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:07,316 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775693_1007 on 127.0.0.1:33488 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:07,316 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:07,316 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33488 is added to blk_-9223372036854775696_1007 (size=0)
2020-04-02 05:12:07,316 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775693_1007 is received from 127.0.0.1:33488
2020-04-02 05:12:07,316 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33488 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:07,316 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775689_1007 on 127.0.0.1:45304 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:07,316 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:07,316 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45304 is added to blk_-9223372036854775696_1007 (size=0)
2020-04-02 05:12:07,316 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775689_1007 is received from 127.0.0.1:45304
2020-04-02 05:12:07,316 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45304 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:07,317 [IPC Server handler 5 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /deleted_1_0 with blk_-9223372036854775680_1008 block is added to the in-memory file system
2020-04-02 05:12:07,317 [IPC Server handler 5 on 41191] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775680_1008, replicas=127.0.0.1:39776, 127.0.0.1:41818, 127.0.0.1:33931, 127.0.0.1:45304, 127.0.0.1:38083, 127.0.0.1:33488, 127.0.0.1:34596, 127.0.0.1:45517, 127.0.0.1:38003 for /deleted_1_0
2020-04-02 05:12:07,317 [IPC Server handler 5 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /deleted_1_0 with new block blk_-9223372036854775680_1008, current total block count is 2
2020-04-02 05:12:07,320 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50026 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775680_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775680_1008 src: /127.0.0.1:50026 dest: /127.0.0.1:39776
2020-04-02 05:12:07,320 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:42968 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775672_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775672_1008 src: /127.0.0.1:42968 dest: /127.0.0.1:38003
2020-04-02 05:12:07,320 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:39710 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775673_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775673_1008 src: /127.0.0.1:39710 dest: /127.0.0.1:45517
2020-04-02 05:12:07,320 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50208 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775674_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775674_1008 src: /127.0.0.1:50208 dest: /127.0.0.1:34596
2020-04-02 05:12:07,331 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775680_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50026, dest: /127.0.0.1:39776, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: ca9828e1-172e-4a2c-a1a8-917b3485899c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775680_1008, duration(ns): 9040872
2020-04-02 05:12:07,332 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775680_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775680_1008, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:07,332 [IPC Server handler 2 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:07,332 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775680_1008 on 127.0.0.1:39776 size 123 replicaState = FINALIZED
2020-04-02 05:12:07,333 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:07,333 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39776 is added to blk_-9223372036854775680_1008 (size=0)
2020-04-02 05:12:07,333 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775680_1008 is received from 127.0.0.1:39776
2020-04-02 05:12:07,333 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39776 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:07,334 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775674_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50208, dest: /127.0.0.1:34596, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 690f7552-c4c3-4286-845f-64b6525bf551, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775674_1008, duration(ns): 7641807
2020-04-02 05:12:07,334 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775674_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775674_1008, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:07,334 [IPC Server handler 4 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34596, datanodeUuid=690f7552-c4c3-4286-845f-64b6525bf551, infoPort=44049, infoSecurePort=0, ipcPort=36235, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:07,334 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775674_1008 on 127.0.0.1:34596 size 123 replicaState = FINALIZED
2020-04-02 05:12:07,335 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:07,335 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34596 is added to blk_-9223372036854775680_1008 (size=0)
2020-04-02 05:12:07,336 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775674_1008 is received from 127.0.0.1:34596
2020-04-02 05:12:07,336 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34596 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:07,336 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775673_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39710, dest: /127.0.0.1:45517, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775673_1008, duration(ns): 10373687
2020-04-02 05:12:07,336 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775673_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775673_1008, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:07,336 [IPC Server handler 9 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45517, datanodeUuid=30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, infoPort=41207, infoSecurePort=0, ipcPort=44568, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:07,337 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775673_1008 on 127.0.0.1:45517 size 123 replicaState = FINALIZED
2020-04-02 05:12:07,337 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:07,337 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45517 is added to blk_-9223372036854775680_1008 (size=0)
2020-04-02 05:12:07,337 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775673_1008 is received from 127.0.0.1:45517
2020-04-02 05:12:07,337 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45517 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:07,338 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775672_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42968, dest: /127.0.0.1:38003, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775672_1008, duration(ns): 14354513
2020-04-02 05:12:07,338 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775672_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775672_1008, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:07,339 [IPC Server handler 3 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:07,339 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775672_1008 on 127.0.0.1:38003 size 123 replicaState = FINALIZED
2020-04-02 05:12:07,339 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:07,339 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38003 is added to blk_-9223372036854775680_1008 (size=0)
2020-04-02 05:12:07,339 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775672_1008 is received from 127.0.0.1:38003
2020-04-02 05:12:07,339 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38003 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:07,343 [IPC Server handler 8 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /deleted_1_0 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:12:07,344 [IPC Server handler 8 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /deleted_1_0 with 2 blocks is persisted to the file system
2020-04-02 05:12:07,344 [IPC Server handler 8 on 41191] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /deleted_1_0 is closed by DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:12:07,345 [Thread-679] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(231)) - corruptBlocks on path /deleted_1_0
2020-04-02 05:12:07,346 [IPC Server handler 7 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775696_1007, blk_-9223372036854775680_1008]
2020-04-02 05:12:07,347 [IPC Server handler 7 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:12:07,348 [Thread-679] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(258)) - Deleting block file BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775677_1008
2020-04-02 05:12:07,349 [Thread-679] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775677_1008 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775677_1008
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:07,349 [Thread-679] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775677_1008 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775677_1008
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:07,350 [Thread-679] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775677_1008 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775677_1008
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:07,350 [Thread-679] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775677_1008 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775677_1008
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:07,350 [Thread-679] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775677_1008 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775677_1008
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:07,350 [Thread-679] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775677_1008 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775677_1008
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:07,351 [Thread-679] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775677_1008 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775677_1008
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:07,351 [Thread-679] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775677_1008 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775677_1008
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:07,351 [Thread-679] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775677_1008 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775677_1008
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:07,351 [Thread-679] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /deleted_1_0
2020-04-02 05:12:07,356 [Thread-679] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /deleted_1_0
2020-04-02 05:12:07,357 [IPC Server handler 6 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/deleted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:12:07,358 [Thread-679] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /deleted_1_0
2020-04-02 05:12:07,358 [IPC Server handler 1 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:12:07,359 [IPC Server handler 0 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775696_1007, blk_-9223372036854775680_1008]
2020-04-02 05:12:07,360 [IPC Server handler 0 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:12:08,093 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:08,093 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:08,094 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:08,094 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:12:08,094 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:08,094 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:12:08,094 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:33488 to delete [blk_-9223372036854775791_1001]
2020-04-02 05:12:08,094 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:45304 to delete [blk_-9223372036854775785_1001]
2020-04-02 05:12:08,094 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:33931 to delete [blk_-9223372036854775792_1001]
2020-04-02 05:12:09,253 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775785_1001 replica FinalizedReplica, blk_-9223372036854775785_1001, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775785 for deletion
2020-04-02 05:12:09,253 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775791_1001 replica FinalizedReplica, blk_-9223372036854775791_1001, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775791 for deletion
2020-04-02 05:12:09,260 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775785_1001 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775785
2020-04-02 05:12:09,264 [Async disk worker #1 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775791_1001 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775791
2020-04-02 05:12:10,152 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775792_1001 replica FinalizedReplica, blk_-9223372036854775792_1001, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775792 for deletion
2020-04-02 05:12:10,154 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775792_1001 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775792
2020-04-02 05:12:11,095 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:11,098 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:11,099 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:11,099 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:12:11,099 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:11,099 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:12:11,099 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:41818 to delete [blk_-9223372036854775790_1001]
2020-04-02 05:12:11,099 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:38003 to delete [blk_-9223372036854775786_1001]
2020-04-02 05:12:11,099 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34596 to delete [blk_-9223372036854775789_1001]
2020-04-02 05:12:12,067 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775790_1001 replica FinalizedReplica, blk_-9223372036854775790_1001, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775790 for deletion
2020-04-02 05:12:12,067 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775786_1001 replica FinalizedReplica, blk_-9223372036854775786_1001, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775786 for deletion
2020-04-02 05:12:12,069 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775790_1001 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775790
2020-04-02 05:12:12,086 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775786_1001 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775786
2020-04-02 05:12:12,243 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775789_1001 replica FinalizedReplica, blk_-9223372036854775789_1001, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775789 for deletion
2020-04-02 05:12:12,246 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775789_1001 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775789
2020-04-02 05:12:14,100 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:14,105 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:14,105 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:14,105 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:12:14,105 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:14,105 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:12:14,105 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:45517 to delete [blk_-9223372036854775784_1001]
2020-04-02 05:12:14,105 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:38083 to delete [blk_-9223372036854775787_1001]
2020-04-02 05:12:15,226 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775784_1001 replica FinalizedReplica, blk_-9223372036854775784_1001, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775784 for deletion
2020-04-02 05:12:15,233 [Async disk worker #1 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775784_1001 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775784
2020-04-02 05:12:15,933 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775787_1001 replica FinalizedReplica, blk_-9223372036854775787_1001, FINALIZED
  getNumBytes()     = 4194181
  getBytesOnDisk()  = 4194181
  getVisibleLength()= 4194181
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775787 for deletion
2020-04-02 05:12:15,945 [Async disk worker #1 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775787_1001 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775787
2020-04-02 05:12:17,106 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:17,111 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:17,111 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:17,111 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:12:17,111 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:17,112 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:12:19,751 [Thread-679] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /deleted_1_0
2020-04-02 05:12:19,755 [IPC Server handler 4 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775696_1007, blk_-9223372036854775680_1008]
2020-04-02 05:12:19,756 [IPC Server handler 4 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:12:20,112 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:20,112 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:20,112 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:20,112 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:12:20,112 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:20,112 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:12:23,113 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:23,113 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:23,113 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:23,113 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:12:23,114 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:23,114 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:12:23,492 [Thread-679] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /deleted_1_0
2020-04-02 05:12:23,497 [IPC Server handler 4 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775696_1007, blk_-9223372036854775680_1008]
2020-04-02 05:12:23,498 [IPC Server handler 4 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:12:26,114 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:26,114 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:26,114 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:26,114 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:12:26,114 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:26,115 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:12:27,073 [Thread-679] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /deleted_1_0
2020-04-02 05:12:27,074 [IPC Server handler 6 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775696_1007, blk_-9223372036854775680_1008]
2020-04-02 05:12:27,077 [IPC Server handler 6 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:12:29,116 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:29,116 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:29,116 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:29,117 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:12:29,117 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:29,117 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[6]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[6]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[7]
[msx] perform reset as unitTestCounterInClass 7 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:12:32,020 [Thread-749] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithBlockCorrupted(203)) - testReadWithBlockCorrupted: file = /deleted_1_1, dataBlkDelNum = 1, parityBlkDelNum = 1, deleteBlockFile? true
2020-04-02 05:12:32,077 [IPC Server handler 6 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/deleted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:12:32,079 [IPC Server handler 0 on 41191] DEBUG hdfs.StateChange (NameNodeRpcServer.java:delete(1084)) - *DIR* Namenode.delete: src=/deleted_1_1, recursive=true
2020-04-02 05:12:32,079 [IPC Server handler 0 on 41191] DEBUG hdfs.StateChange (FSDirDeleteOp.java:deleteInternal(180)) - DIR* NameSystem.delete: /deleted_1_1
2020-04-02 05:12:32,079 [IPC Server handler 0 on 41191] DEBUG hdfs.StateChange (FSDirDeleteOp.java:delete(55)) - DIR* FSDirectory.delete: /deleted_1_1
2020-04-02 05:12:32,079 [IPC Server handler 0 on 41191] DEBUG hdfs.StateChange (FSDirDeleteOp.java:unprotectedDelete(269)) - DIR* FSDirectory.unprotectedDelete: /deleted_1_1 is removed
2020-04-02 05:12:32,080 [IPC Server handler 0 on 41191] DEBUG hdfs.StateChange (FSDirDeleteOp.java:deleteInternal(201)) - DIR* Namesystem.delete: /deleted_1_1 is removed
2020-04-02 05:12:32,080 [IPC Server handler 0 on 41191] DEBUG BlockStateChange (BlockManager.java:addToInvalidates(1598)) - BLOCK* addToInvalidates: blk_-9223372036854775776_1002 127.0.0.1:45304 127.0.0.1:33488 127.0.0.1:34596 127.0.0.1:45517 127.0.0.1:41818 127.0.0.1:39776 127.0.0.1:38003 
2020-04-02 05:12:32,081 [IPC Server handler 0 on 41191] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775776_1002 from priority queue 1
2020-04-02 05:12:32,081 [IPC Server handler 0 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/deleted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:12:32,082 [IPC Server handler 3 on 41191] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /deleted_1_1 for DFSClient_NONMAPREDUCE_-1389971812_1 at 127.0.0.1
2020-04-02 05:12:32,082 [IPC Server handler 3 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/deleted_1_1, holder=DFSClient_NONMAPREDUCE_-1389971812_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:12:32,083 [IPC Server handler 3 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: deleted_1_1 is added
2020-04-02 05:12:32,083 [IPC Server handler 3 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /deleted_1_1 inode 16393 DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:12:32,084 [IPC Server handler 3 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/deleted_1_1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:12:32,109 [IPC Server handler 9 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /deleted_1_1  inodeId 16393 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:12:32,110 [IPC Server handler 9 on 41191] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:12:32,111 [IPC Server handler 9 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /deleted_1_1 with blk_-9223372036854775664_1009 block is added to the in-memory file system
2020-04-02 05:12:32,111 [IPC Server handler 9 on 41191] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775664_1009, replicas=127.0.0.1:39776, 127.0.0.1:38003, 127.0.0.1:38083, 127.0.0.1:33931, 127.0.0.1:41818, 127.0.0.1:45304, 127.0.0.1:34596, 127.0.0.1:45517, 127.0.0.1:33488 for /deleted_1_1
2020-04-02 05:12:32,112 [IPC Server handler 9 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /deleted_1_1 with new block blk_-9223372036854775664_1009, current total block count is 1
2020-04-02 05:12:32,115 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50164 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775664_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775664_1009 src: /127.0.0.1:50164 dest: /127.0.0.1:39776
2020-04-02 05:12:32,118 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:32,118 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:32,119 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:32,119 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:32,120 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:12:32,120 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:43102 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775663_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775663_1009 src: /127.0.0.1:43102 dest: /127.0.0.1:38003
2020-04-02 05:12:32,121 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34596 to delete [blk_-9223372036854775773_1002]
2020-04-02 05:12:32,121 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:45517 to delete [blk_-9223372036854775772_1002]
2020-04-02 05:12:32,121 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:39776 to delete [blk_-9223372036854775769_1002]
2020-04-02 05:12:32,140 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50228 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775662_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775662_1009 src: /127.0.0.1:50228 dest: /127.0.0.1:38083
2020-04-02 05:12:32,149 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:53798 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775661_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775661_1009 src: /127.0.0.1:53798 dest: /127.0.0.1:33931
2020-04-02 05:12:32,159 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:53222 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775660_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775660_1009 src: /127.0.0.1:53222 dest: /127.0.0.1:41818
2020-04-02 05:12:32,165 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49374 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775659_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775659_1009 src: /127.0.0.1:49374 dest: /127.0.0.1:45304
2020-04-02 05:12:32,212 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50358 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775658_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775658_1009 src: /127.0.0.1:50358 dest: /127.0.0.1:34596
2020-04-02 05:12:32,225 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:39862 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775657_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775657_1009 src: /127.0.0.1:39862 dest: /127.0.0.1:45517
2020-04-02 05:12:32,236 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:59052 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775656_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775656_1009 src: /127.0.0.1:59052 dest: /127.0.0.1:33488
2020-04-02 05:12:32,418 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775659_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49374, dest: /127.0.0.1:45304, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 31f7c920-c39d-4ae7-b315-1227a3caafd0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775659_1009, duration(ns): 245132187
2020-04-02 05:12:32,418 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775662_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50228, dest: /127.0.0.1:38083, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 3d038cc2-f80f-4a72-8c2c-febccfb87908, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775662_1009, duration(ns): 270276909
2020-04-02 05:12:32,418 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775661_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53798, dest: /127.0.0.1:33931, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 04fa600d-9223-4e33-b0a1-d4242966c7f0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775661_1009, duration(ns): 260401629
2020-04-02 05:12:32,418 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775658_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50358, dest: /127.0.0.1:34596, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 690f7552-c4c3-4286-845f-64b6525bf551, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775658_1009, duration(ns): 198016620
2020-04-02 05:12:32,418 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775663_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43102, dest: /127.0.0.1:38003, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775663_1009, duration(ns): 288962748
2020-04-02 05:12:32,418 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775662_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775662_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:32,419 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775656_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59052, dest: /127.0.0.1:33488, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: f1177179-f009-4517-a835-ba14c97e85ff, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775656_1009, duration(ns): 173933971
2020-04-02 05:12:32,418 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775664_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50164, dest: /127.0.0.1:39776, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: ca9828e1-172e-4a2c-a1a8-917b3485899c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775664_1009, duration(ns): 293540054
2020-04-02 05:12:32,418 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775660_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53222, dest: /127.0.0.1:41818, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 138c0d7d-7e58-4339-8b75-15c135daf76d, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775660_1009, duration(ns): 251127000
2020-04-02 05:12:32,419 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775664_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775664_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:32,419 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775660_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775660_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:32,419 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775656_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775656_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:32,419 [IPC Server handler 1 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38083, datanodeUuid=3d038cc2-f80f-4a72-8c2c-febccfb87908, infoPort=37146, infoSecurePort=0, ipcPort=37392, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:32,419 [IPC Server handler 0 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:32,419 [IPC Server handler 6 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:41818, datanodeUuid=138c0d7d-7e58-4339-8b75-15c135daf76d, infoPort=42795, infoSecurePort=0, ipcPort=43620, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:32,419 [IPC Server handler 5 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33931, datanodeUuid=04fa600d-9223-4e33-b0a1-d4242966c7f0, infoPort=45217, infoSecurePort=0, ipcPort=38205, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:32,419 [IPC Server handler 7 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45304, datanodeUuid=31f7c920-c39d-4ae7-b315-1227a3caafd0, infoPort=37250, infoSecurePort=0, ipcPort=45067, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:32,419 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775658_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775658_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:32,419 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775657_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39862, dest: /127.0.0.1:45517, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775657_1009, duration(ns): 183002554
2020-04-02 05:12:32,419 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775663_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775663_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:32,418 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775661_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775661_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:32,418 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775659_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775659_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:32,421 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775657_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775657_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:32,420 [IPC Server handler 1 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33488, datanodeUuid=f1177179-f009-4517-a835-ba14c97e85ff, infoPort=42409, infoSecurePort=0, ipcPort=46631, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:32,420 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775662_1009 on 127.0.0.1:38083 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:32,419 [IPC Server handler 4 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45517, datanodeUuid=30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, infoPort=41207, infoSecurePort=0, ipcPort=44568, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:32,419 [IPC Server handler 9 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34596, datanodeUuid=690f7552-c4c3-4286-845f-64b6525bf551, infoPort=44049, infoSecurePort=0, ipcPort=36235, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:32,419 [IPC Server handler 3 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:32,421 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:32,421 [IPC Server handler 8 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /deleted_1_1  inodeId 16393 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:12:32,422 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38083 is added to blk_-9223372036854775664_1009 (size=0)
2020-04-02 05:12:32,422 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775662_1009 is received from 127.0.0.1:38083
2020-04-02 05:12:32,422 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38083 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:32,422 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775663_1009 on 127.0.0.1:38003 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:32,422 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:32,422 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38003 is added to blk_-9223372036854775664_1009 (size=0)
2020-04-02 05:12:32,423 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775663_1009 is received from 127.0.0.1:38003
2020-04-02 05:12:32,423 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38003 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:32,423 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775660_1009 on 127.0.0.1:41818 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:32,423 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:32,423 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:41818 is added to blk_-9223372036854775664_1009 (size=0)
2020-04-02 05:12:32,423 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775660_1009 is received from 127.0.0.1:41818
2020-04-02 05:12:32,423 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:41818 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:32,423 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775661_1009 on 127.0.0.1:33931 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:32,423 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:32,423 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33931 is added to blk_-9223372036854775664_1009 (size=0)
2020-04-02 05:12:32,423 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775661_1009 is received from 127.0.0.1:33931
2020-04-02 05:12:32,423 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33931 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:32,424 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775659_1009 on 127.0.0.1:45304 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:32,424 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:32,424 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45304 is added to blk_-9223372036854775664_1009 (size=0)
2020-04-02 05:12:32,424 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775659_1009 is received from 127.0.0.1:45304
2020-04-02 05:12:32,424 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45304 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:32,424 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775656_1009 on 127.0.0.1:33488 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:32,424 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:32,424 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33488 is added to blk_-9223372036854775664_1009 (size=0)
2020-04-02 05:12:32,424 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775656_1009 is received from 127.0.0.1:33488
2020-04-02 05:12:32,424 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33488 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:32,424 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775657_1009 on 127.0.0.1:45517 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:32,424 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:32,425 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45517 is added to blk_-9223372036854775664_1009 (size=0)
2020-04-02 05:12:32,425 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775657_1009 is received from 127.0.0.1:45517
2020-04-02 05:12:32,425 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45517 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:32,425 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775658_1009 on 127.0.0.1:34596 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:32,425 [IPC Server handler 8 on 41191] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:12:32,425 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:32,426 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34596 is added to blk_-9223372036854775664_1009 (size=0)
2020-04-02 05:12:32,426 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775658_1009 is received from 127.0.0.1:34596
2020-04-02 05:12:32,426 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34596 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:32,426 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775664_1009 on 127.0.0.1:39776 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:32,426 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:32,426 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39776 is added to blk_-9223372036854775664_1009 (size=0)
2020-04-02 05:12:32,426 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775664_1009 is received from 127.0.0.1:39776
2020-04-02 05:12:32,426 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39776 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:32,427 [IPC Server handler 8 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /deleted_1_1 with blk_-9223372036854775648_1010 block is added to the in-memory file system
2020-04-02 05:12:32,427 [IPC Server handler 8 on 41191] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775648_1010, replicas=127.0.0.1:45304, 127.0.0.1:39776, 127.0.0.1:34596, 127.0.0.1:33931, 127.0.0.1:33488, 127.0.0.1:41818, 127.0.0.1:38003, 127.0.0.1:45517, 127.0.0.1:38083 for /deleted_1_1
2020-04-02 05:12:32,427 [IPC Server handler 8 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /deleted_1_1 with new block blk_-9223372036854775648_1010, current total block count is 2
2020-04-02 05:12:32,430 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49382 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775648_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775648_1010 src: /127.0.0.1:49382 dest: /127.0.0.1:45304
2020-04-02 05:12:32,430 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:39872 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775641_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775641_1010 src: /127.0.0.1:39872 dest: /127.0.0.1:45517
2020-04-02 05:12:32,430 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:43120 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775642_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775642_1010 src: /127.0.0.1:43120 dest: /127.0.0.1:38003
2020-04-02 05:12:32,430 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50246 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775640_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775640_1010 src: /127.0.0.1:50246 dest: /127.0.0.1:38083
2020-04-02 05:12:32,437 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775648_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49382, dest: /127.0.0.1:45304, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 31f7c920-c39d-4ae7-b315-1227a3caafd0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775648_1010, duration(ns): 4699322
2020-04-02 05:12:32,437 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775648_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775648_1010, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:32,437 [IPC Server handler 2 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45304, datanodeUuid=31f7c920-c39d-4ae7-b315-1227a3caafd0, infoPort=37250, infoSecurePort=0, ipcPort=45067, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:32,437 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775648_1010 on 127.0.0.1:45304 size 123 replicaState = FINALIZED
2020-04-02 05:12:32,438 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:32,438 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775642_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43120, dest: /127.0.0.1:38003, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775642_1010, duration(ns): 3151820
2020-04-02 05:12:32,438 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45304 is added to blk_-9223372036854775648_1010 (size=0)
2020-04-02 05:12:32,438 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775642_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775642_1010, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:32,438 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775648_1010 is received from 127.0.0.1:45304
2020-04-02 05:12:32,439 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45304 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:32,439 [IPC Server handler 0 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:32,439 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775642_1010 on 127.0.0.1:38003 size 123 replicaState = FINALIZED
2020-04-02 05:12:32,439 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:32,439 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38003 is added to blk_-9223372036854775648_1010 (size=0)
2020-04-02 05:12:32,439 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775642_1010 is received from 127.0.0.1:38003
2020-04-02 05:12:32,439 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38003 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:32,440 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775641_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39872, dest: /127.0.0.1:45517, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775641_1010, duration(ns): 5145681
2020-04-02 05:12:32,440 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775641_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775641_1010, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:32,441 [IPC Server handler 6 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45517, datanodeUuid=30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, infoPort=41207, infoSecurePort=0, ipcPort=44568, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:32,441 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775641_1010 on 127.0.0.1:45517 size 123 replicaState = FINALIZED
2020-04-02 05:12:32,441 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:32,442 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45517 is added to blk_-9223372036854775648_1010 (size=0)
2020-04-02 05:12:32,442 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775640_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50246, dest: /127.0.0.1:38083, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 3d038cc2-f80f-4a72-8c2c-febccfb87908, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775640_1010, duration(ns): 9467737
2020-04-02 05:12:32,442 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775641_1010 is received from 127.0.0.1:45517
2020-04-02 05:12:32,442 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775640_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775640_1010, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:32,442 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45517 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:32,442 [IPC Server handler 5 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38083, datanodeUuid=3d038cc2-f80f-4a72-8c2c-febccfb87908, infoPort=37146, infoSecurePort=0, ipcPort=37392, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:32,443 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775640_1010 on 127.0.0.1:38083 size 123 replicaState = FINALIZED
2020-04-02 05:12:32,443 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:32,443 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38083 is added to blk_-9223372036854775648_1010 (size=0)
2020-04-02 05:12:32,443 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775640_1010 is received from 127.0.0.1:38083
2020-04-02 05:12:32,443 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38083 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:32,443 [IPC Server handler 7 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /deleted_1_1 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:12:32,444 [IPC Server handler 7 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /deleted_1_1 with 2 blocks is persisted to the file system
2020-04-02 05:12:32,444 [IPC Server handler 7 on 41191] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /deleted_1_1 is closed by DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:12:32,445 [Thread-749] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(231)) - corruptBlocks on path /deleted_1_1
2020-04-02 05:12:32,449 [IPC Server handler 1 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775664_1009, blk_-9223372036854775648_1010]
2020-04-02 05:12:32,449 [IPC Server handler 1 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:12:32,451 [Thread-749] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(258)) - Deleting block file BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775643_1010
2020-04-02 05:12:32,451 [Thread-749] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775643_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775643_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:32,451 [Thread-749] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775643_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775643_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:32,452 [Thread-749] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775643_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775643_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:32,452 [Thread-749] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775643_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775643_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:32,452 [Thread-749] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775643_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775643_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:32,452 [Thread-749] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775643_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775643_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:32,453 [Thread-749] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775643_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775643_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:32,453 [Thread-749] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775643_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775643_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:32,453 [Thread-749] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775643_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775643_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:32,454 [Thread-749] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(258)) - Deleting block file BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775640_1010
2020-04-02 05:12:32,454 [Thread-749] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775640_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775640_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:32,454 [Thread-749] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775640_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775640_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:32,454 [Thread-749] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775640_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775640_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:32,455 [Thread-749] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775640_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775640_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:32,455 [Thread-749] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775640_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775640_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:32,455 [Thread-749] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775640_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775640_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:32,455 [Thread-749] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775640_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775640_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:32,456 [Thread-749] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:deleteData(153)) - Deleting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775640
2020-04-02 05:12:32,456 [Thread-749] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775640_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775640_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:32,456 [Thread-749] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /deleted_1_1
2020-04-02 05:12:32,461 [Thread-749] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /deleted_1_1
2020-04-02 05:12:32,463 [IPC Server handler 4 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/deleted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:12:32,464 [Thread-749] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /deleted_1_1
2020-04-02 05:12:32,464 [IPC Server handler 9 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:12:32,465 [IPC Server handler 3 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775664_1009, blk_-9223372036854775648_1010]
2020-04-02 05:12:32,466 [IPC Server handler 3 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:12:33,227 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775772_1002 replica FinalizedReplica, blk_-9223372036854775772_1002, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775772 for deletion
2020-04-02 05:12:33,229 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775769_1002 replica FinalizedReplica, blk_-9223372036854775769_1002, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775769 for deletion
2020-04-02 05:12:33,229 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775772_1002 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775772
2020-04-02 05:12:33,236 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775769_1002 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775769
2020-04-02 05:12:33,245 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775773_1002 replica FinalizedReplica, blk_-9223372036854775773_1002, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775773 for deletion
2020-04-02 05:12:33,246 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775773_1002 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775773
2020-04-02 05:12:35,121 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:35,127 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:35,127 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:35,127 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:35,127 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:12:35,127 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:38003 to delete [blk_-9223372036854775768_1002]
2020-04-02 05:12:35,128 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:33488 to delete [blk_-9223372036854775774_1002]
2020-04-02 05:12:35,128 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:45304 to delete [blk_-9223372036854775776_1002]
2020-04-02 05:12:36,069 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775768_1002 replica FinalizedReplica, blk_-9223372036854775768_1002, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775768 for deletion
2020-04-02 05:12:36,072 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775768_1002 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775768
2020-04-02 05:12:36,228 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775774_1002 replica FinalizedReplica, blk_-9223372036854775774_1002, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775774 for deletion
2020-04-02 05:12:36,233 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775774_1002 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775774
2020-04-02 05:12:36,238 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775776_1002 replica FinalizedReplica, blk_-9223372036854775776_1002, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775776 for deletion
2020-04-02 05:12:36,254 [Async disk worker #1 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775776_1002 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775776
2020-04-02 05:12:38,128 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:38,135 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:38,135 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:38,136 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:38,136 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:12:38,136 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:41818 to delete [blk_-9223372036854775771_1002]
2020-04-02 05:12:39,067 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775771_1002 replica FinalizedReplica, blk_-9223372036854775771_1002, FINALIZED
  getNumBytes()     = 4194181
  getBytesOnDisk()  = 4194181
  getVisibleLength()= 4194181
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775771 for deletion
2020-04-02 05:12:39,069 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775771_1002 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775771
2020-04-02 05:12:41,137 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:41,138 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:41,138 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:41,139 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:41,139 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:12:44,139 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:44,140 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:44,140 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:44,140 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:44,140 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:12:45,171 [Thread-749] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /deleted_1_1
2020-04-02 05:12:45,176 [IPC Server handler 1 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775664_1009, blk_-9223372036854775648_1010]
2020-04-02 05:12:45,178 [IPC Server handler 1 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:12:47,141 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:47,141 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:47,141 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:47,141 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:47,141 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:12:48,502 [Thread-749] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /deleted_1_1
2020-04-02 05:12:48,507 [IPC Server handler 0 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775664_1009, blk_-9223372036854775648_1010]
2020-04-02 05:12:48,509 [IPC Server handler 0 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:12:50,142 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:50,142 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:50,143 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:50,143 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:50,143 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:12:52,278 [Thread-749] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /deleted_1_1
2020-04-02 05:12:52,279 [IPC Server handler 0 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775664_1009, blk_-9223372036854775648_1010]
2020-04-02 05:12:52,280 [IPC Server handler 0 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:12:53,143 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:53,143 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:53,143 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:53,143 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:53,144 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:12:56,144 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:56,144 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:56,144 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:56,144 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:56,144 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[7]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[7]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[8]
[msx] perform reset as unitTestCounterInClass 8 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:12:57,091 [Thread-816] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithBlockCorrupted(203)) - testReadWithBlockCorrupted: file = /deleted_1_2, dataBlkDelNum = 1, parityBlkDelNum = 2, deleteBlockFile? true
2020-04-02 05:12:57,146 [IPC Server handler 7 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/deleted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:12:57,149 [IPC Server handler 4 on 41191] DEBUG hdfs.StateChange (NameNodeRpcServer.java:delete(1084)) - *DIR* Namenode.delete: src=/deleted_1_2, recursive=true
2020-04-02 05:12:57,149 [IPC Server handler 4 on 41191] DEBUG hdfs.StateChange (FSDirDeleteOp.java:deleteInternal(180)) - DIR* NameSystem.delete: /deleted_1_2
2020-04-02 05:12:57,149 [IPC Server handler 4 on 41191] DEBUG hdfs.StateChange (FSDirDeleteOp.java:delete(55)) - DIR* FSDirectory.delete: /deleted_1_2
2020-04-02 05:12:57,150 [IPC Server handler 4 on 41191] DEBUG hdfs.StateChange (FSDirDeleteOp.java:unprotectedDelete(269)) - DIR* FSDirectory.unprotectedDelete: /deleted_1_2 is removed
2020-04-02 05:12:57,150 [IPC Server handler 4 on 41191] DEBUG hdfs.StateChange (FSDirDeleteOp.java:deleteInternal(201)) - DIR* Namesystem.delete: /deleted_1_2 is removed
2020-04-02 05:12:57,150 [IPC Server handler 4 on 41191] DEBUG BlockStateChange (BlockManager.java:addToInvalidates(1598)) - BLOCK* addToInvalidates: blk_-9223372036854775760_1003 127.0.0.1:38083 127.0.0.1:33931 127.0.0.1:34596 127.0.0.1:45304 127.0.0.1:41818 127.0.0.1:39776 
2020-04-02 05:12:57,150 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 52 Total time for transactions(ms): 40 Number of transactions batched in Syncs: 9 Number of syncs: 43 SyncTimes(ms): 1 1 
2020-04-02 05:12:57,151 [IPC Server handler 4 on 41191] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775760_1003 from priority queue 0
2020-04-02 05:12:57,151 [IPC Server handler 4 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/deleted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:12:57,152 [IPC Server handler 9 on 41191] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /deleted_1_2 for DFSClient_NONMAPREDUCE_-1389971812_1 at 127.0.0.1
2020-04-02 05:12:57,152 [IPC Server handler 9 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/deleted_1_2, holder=DFSClient_NONMAPREDUCE_-1389971812_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:12:57,153 [IPC Server handler 9 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: deleted_1_2 is added
2020-04-02 05:12:57,153 [IPC Server handler 9 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /deleted_1_2 inode 16394 DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:12:57,153 [IPC Server handler 9 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/deleted_1_2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:12:57,176 [IPC Server handler 3 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /deleted_1_2  inodeId 16394 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:12:57,176 [IPC Server handler 3 on 41191] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:12:57,178 [IPC Server handler 3 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /deleted_1_2 with blk_-9223372036854775632_1011 block is added to the in-memory file system
2020-04-02 05:12:57,178 [IPC Server handler 3 on 41191] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775632_1011, replicas=127.0.0.1:33931, 127.0.0.1:38003, 127.0.0.1:33488, 127.0.0.1:41818, 127.0.0.1:34596, 127.0.0.1:39776, 127.0.0.1:38083, 127.0.0.1:45304, 127.0.0.1:45517 for /deleted_1_2
2020-04-02 05:12:57,178 [IPC Server handler 3 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /deleted_1_2 with new block blk_-9223372036854775632_1011, current total block count is 1
2020-04-02 05:12:57,182 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:53898 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775632_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775632_1011 src: /127.0.0.1:53898 dest: /127.0.0.1:33931
2020-04-02 05:12:57,193 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:43208 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775631_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775631_1011 src: /127.0.0.1:43208 dest: /127.0.0.1:38003
2020-04-02 05:12:57,209 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:59146 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775630_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775630_1011 src: /127.0.0.1:59146 dest: /127.0.0.1:33488
2020-04-02 05:12:57,224 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:53326 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775629_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775629_1011 src: /127.0.0.1:53326 dest: /127.0.0.1:41818
2020-04-02 05:12:57,234 [IPC Server handler 0 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33488, datanodeUuid=f1177179-f009-4517-a835-ba14c97e85ff, infoPort=42409, infoSecurePort=0, ipcPort=46631, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:57,234 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775630_1011 on 127.0.0.1:33488 size 4194304 replicaState = RBW
2020-04-02 05:12:57,234 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:57,234 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775630_1011 is received from 127.0.0.1:33488
2020-04-02 05:12:57,237 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50460 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775628_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775628_1011 src: /127.0.0.1:50460 dest: /127.0.0.1:34596
2020-04-02 05:12:57,237 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33488 receiving: 1, received: 0, deleted: 0
2020-04-02 05:12:57,242 [IPC Server handler 7 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34596, datanodeUuid=690f7552-c4c3-4286-845f-64b6525bf551, infoPort=44049, infoSecurePort=0, ipcPort=36235, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:57,243 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775628_1011 on 127.0.0.1:34596 size 4194304 replicaState = RBW
2020-04-02 05:12:57,244 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:57,244 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775628_1011 is received from 127.0.0.1:34596
2020-04-02 05:12:57,245 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34596 receiving: 1, received: 0, deleted: 0
2020-04-02 05:12:57,246 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50280 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775627_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775627_1011 src: /127.0.0.1:50280 dest: /127.0.0.1:39776
2020-04-02 05:12:57,292 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50342 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775626_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775626_1011 src: /127.0.0.1:50342 dest: /127.0.0.1:38083
2020-04-02 05:12:57,308 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49484 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775625_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775625_1011 src: /127.0.0.1:49484 dest: /127.0.0.1:45304
2020-04-02 05:12:57,325 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:39970 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775624_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775624_1011 src: /127.0.0.1:39970 dest: /127.0.0.1:45517
2020-04-02 05:12:57,503 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775624_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39970, dest: /127.0.0.1:45517, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775624_1011, duration(ns): 174060026
2020-04-02 05:12:57,505 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775629_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53326, dest: /127.0.0.1:41818, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 138c0d7d-7e58-4339-8b75-15c135daf76d, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775629_1011, duration(ns): 274573245
2020-04-02 05:12:57,506 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775627_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50280, dest: /127.0.0.1:39776, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: ca9828e1-172e-4a2c-a1a8-917b3485899c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775627_1011, duration(ns): 252132862
2020-04-02 05:12:57,506 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775631_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43208, dest: /127.0.0.1:38003, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775631_1011, duration(ns): 302661404
2020-04-02 05:12:57,506 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775627_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775627_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:57,506 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775631_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775631_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:57,507 [IPC Server handler 3 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:57,505 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775626_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50342, dest: /127.0.0.1:38083, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 3d038cc2-f80f-4a72-8c2c-febccfb87908, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775626_1011, duration(ns): 206636564
2020-04-02 05:12:57,507 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775631_1011 on 127.0.0.1:38003 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:57,507 [IPC Server handler 0 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:57,507 [IPC Server handler 2 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45304, datanodeUuid=31f7c920-c39d-4ae7-b315-1227a3caafd0, infoPort=37250, infoSecurePort=0, ipcPort=45067, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:57,507 [IPC Server handler 5 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33488, datanodeUuid=f1177179-f009-4517-a835-ba14c97e85ff, infoPort=42409, infoSecurePort=0, ipcPort=46631, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:57,507 [IPC Server handler 4 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:41818, datanodeUuid=138c0d7d-7e58-4339-8b75-15c135daf76d, infoPort=42795, infoSecurePort=0, ipcPort=43620, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:57,507 [IPC Server handler 9 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45517, datanodeUuid=30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, infoPort=41207, infoSecurePort=0, ipcPort=44568, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:57,507 [IPC Server handler 8 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38083, datanodeUuid=3d038cc2-f80f-4a72-8c2c-febccfb87908, infoPort=37146, infoSecurePort=0, ipcPort=37392, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:57,506 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775629_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775629_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:57,506 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775624_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775624_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:57,506 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775625_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49484, dest: /127.0.0.1:45304, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 31f7c920-c39d-4ae7-b315-1227a3caafd0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775625_1011, duration(ns): 189676447
2020-04-02 05:12:57,506 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775630_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59146, dest: /127.0.0.1:33488, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: f1177179-f009-4517-a835-ba14c97e85ff, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775630_1011, duration(ns): 289924052
2020-04-02 05:12:57,506 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775632_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53898, dest: /127.0.0.1:33931, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 04fa600d-9223-4e33-b0a1-d4242966c7f0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775632_1011, duration(ns): 308264613
2020-04-02 05:12:57,506 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775628_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50460, dest: /127.0.0.1:34596, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 690f7552-c4c3-4286-845f-64b6525bf551, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775628_1011, duration(ns): 261317864
2020-04-02 05:12:57,509 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775632_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775632_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:57,509 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775630_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775630_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:57,508 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775625_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775625_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:57,507 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:57,507 [IPC Server handler 6 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33931, datanodeUuid=04fa600d-9223-4e33-b0a1-d4242966c7f0, infoPort=45217, infoSecurePort=0, ipcPort=38205, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:57,507 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775626_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775626_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:57,507 [IPC Server handler 1 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34596, datanodeUuid=690f7552-c4c3-4286-845f-64b6525bf551, infoPort=44049, infoSecurePort=0, ipcPort=36235, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:57,509 [IPC Server handler 7 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /deleted_1_2  inodeId 16394 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:12:57,509 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38003 is added to blk_-9223372036854775632_1011 (size=0)
2020-04-02 05:12:57,509 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775628_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775628_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:57,510 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775631_1011 is received from 127.0.0.1:38003
2020-04-02 05:12:57,510 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38003 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:57,510 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775627_1011 on 127.0.0.1:39776 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:57,510 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:57,510 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39776 is added to blk_-9223372036854775632_1011 (size=0)
2020-04-02 05:12:57,510 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775627_1011 is received from 127.0.0.1:39776
2020-04-02 05:12:57,510 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39776 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:57,511 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775625_1011 on 127.0.0.1:45304 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:57,511 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:57,511 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45304 is added to blk_-9223372036854775632_1011 (size=0)
2020-04-02 05:12:57,511 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775625_1011 is received from 127.0.0.1:45304
2020-04-02 05:12:57,511 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45304 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:57,511 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775630_1011 on 127.0.0.1:33488 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:57,511 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:57,511 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33488 is added to blk_-9223372036854775632_1011 (size=0)
2020-04-02 05:12:57,511 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775630_1011 is received from 127.0.0.1:33488
2020-04-02 05:12:57,511 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33488 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:57,511 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775629_1011 on 127.0.0.1:41818 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:57,511 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:57,511 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:41818 is added to blk_-9223372036854775632_1011 (size=0)
2020-04-02 05:12:57,511 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775629_1011 is received from 127.0.0.1:41818
2020-04-02 05:12:57,512 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:41818 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:57,512 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775624_1011 on 127.0.0.1:45517 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:57,512 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:57,512 [IPC Server handler 7 on 41191] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:12:57,512 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45517 is added to blk_-9223372036854775632_1011 (size=0)
2020-04-02 05:12:57,512 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775624_1011 is received from 127.0.0.1:45517
2020-04-02 05:12:57,512 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45517 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:57,512 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775626_1011 on 127.0.0.1:38083 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:57,512 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:57,512 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38083 is added to blk_-9223372036854775632_1011 (size=0)
2020-04-02 05:12:57,513 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775626_1011 is received from 127.0.0.1:38083
2020-04-02 05:12:57,513 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38083 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:57,513 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775632_1011 on 127.0.0.1:33931 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:57,513 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:57,513 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33931 is added to blk_-9223372036854775632_1011 (size=0)
2020-04-02 05:12:57,513 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775632_1011 is received from 127.0.0.1:33931
2020-04-02 05:12:57,513 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33931 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:57,513 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775628_1011 on 127.0.0.1:34596 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:57,513 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:57,513 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34596 is added to blk_-9223372036854775632_1011 (size=0)
2020-04-02 05:12:57,513 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775628_1011 is received from 127.0.0.1:34596
2020-04-02 05:12:57,513 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34596 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:57,514 [IPC Server handler 7 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /deleted_1_2 with blk_-9223372036854775616_1012 block is added to the in-memory file system
2020-04-02 05:12:57,514 [IPC Server handler 7 on 41191] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775616_1012, replicas=127.0.0.1:39776, 127.0.0.1:38083, 127.0.0.1:41818, 127.0.0.1:45304, 127.0.0.1:45517, 127.0.0.1:33488, 127.0.0.1:38003, 127.0.0.1:33931, 127.0.0.1:34596 for /deleted_1_2
2020-04-02 05:12:57,514 [IPC Server handler 7 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /deleted_1_2 with new block blk_-9223372036854775616_1012, current total block count is 2
2020-04-02 05:12:57,516 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50470 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775608_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775608_1012 src: /127.0.0.1:50470 dest: /127.0.0.1:34596
2020-04-02 05:12:57,516 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:53916 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775609_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775609_1012 src: /127.0.0.1:53916 dest: /127.0.0.1:33931
2020-04-02 05:12:57,516 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50288 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775616_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775616_1012 src: /127.0.0.1:50288 dest: /127.0.0.1:39776
2020-04-02 05:12:57,516 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:43228 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775610_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775610_1012 src: /127.0.0.1:43228 dest: /127.0.0.1:38003
2020-04-02 05:12:57,522 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775616_1012, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50288, dest: /127.0.0.1:39776, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: ca9828e1-172e-4a2c-a1a8-917b3485899c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775616_1012, duration(ns): 2644538
2020-04-02 05:12:57,522 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775616_1012, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775616_1012, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:57,523 [IPC Server handler 3 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:57,523 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775616_1012 on 127.0.0.1:39776 size 123 replicaState = FINALIZED
2020-04-02 05:12:57,524 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:57,524 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775610_1012, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43228, dest: /127.0.0.1:38003, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775610_1012, duration(ns): 5749222
2020-04-02 05:12:57,524 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39776 is added to blk_-9223372036854775616_1012 (size=0)
2020-04-02 05:12:57,524 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775610_1012, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775610_1012, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:57,524 [IPC Server handler 0 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:57,524 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775616_1012 is received from 127.0.0.1:39776
2020-04-02 05:12:57,524 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39776 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:57,524 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775610_1012 on 127.0.0.1:38003 size 123 replicaState = FINALIZED
2020-04-02 05:12:57,525 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:57,525 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38003 is added to blk_-9223372036854775616_1012 (size=0)
2020-04-02 05:12:57,525 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775610_1012 is received from 127.0.0.1:38003
2020-04-02 05:12:57,525 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38003 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:57,525 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775609_1012, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53916, dest: /127.0.0.1:33931, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 04fa600d-9223-4e33-b0a1-d4242966c7f0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775609_1012, duration(ns): 5966773
2020-04-02 05:12:57,525 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775609_1012, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775609_1012, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:57,526 [IPC Server handler 2 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33931, datanodeUuid=04fa600d-9223-4e33-b0a1-d4242966c7f0, infoPort=45217, infoSecurePort=0, ipcPort=38205, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:57,526 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775609_1012 on 127.0.0.1:33931 size 123 replicaState = FINALIZED
2020-04-02 05:12:57,526 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:57,526 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33931 is added to blk_-9223372036854775616_1012 (size=0)
2020-04-02 05:12:57,526 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775609_1012 is received from 127.0.0.1:33931
2020-04-02 05:12:57,526 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33931 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:57,527 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775608_1012, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50470, dest: /127.0.0.1:34596, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 690f7552-c4c3-4286-845f-64b6525bf551, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775608_1012, duration(ns): 9410825
2020-04-02 05:12:57,527 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775608_1012, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775608_1012, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:57,530 [IPC Server handler 5 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34596, datanodeUuid=690f7552-c4c3-4286-845f-64b6525bf551, infoPort=44049, infoSecurePort=0, ipcPort=36235, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:12:57,532 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775608_1012 on 127.0.0.1:34596 size 123 replicaState = FINALIZED
2020-04-02 05:12:57,533 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:57,534 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34596 is added to blk_-9223372036854775616_1012 (size=0)
2020-04-02 05:12:57,534 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775608_1012 is received from 127.0.0.1:34596
2020-04-02 05:12:57,534 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34596 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:57,535 [IPC Server handler 4 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /deleted_1_2 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:12:57,535 [IPC Server handler 4 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /deleted_1_2 with 2 blocks is persisted to the file system
2020-04-02 05:12:57,536 [IPC Server handler 4 on 41191] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /deleted_1_2 is closed by DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:12:57,536 [Thread-816] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(231)) - corruptBlocks on path /deleted_1_2
2020-04-02 05:12:57,543 [IPC Server handler 9 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775632_1011, blk_-9223372036854775616_1012]
2020-04-02 05:12:57,543 [IPC Server handler 9 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:12:57,544 [Thread-816] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(258)) - Deleting block file BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775612_1012
2020-04-02 05:12:57,545 [Thread-816] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775612_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775612_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:57,545 [Thread-816] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775612_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775612_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:57,545 [Thread-816] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775612_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775612_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:57,546 [Thread-816] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775612_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775612_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:57,546 [Thread-816] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775612_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775612_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:57,546 [Thread-816] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775612_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775612_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:57,547 [Thread-816] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775612_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775612_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:57,547 [Thread-816] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775612_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775612_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:57,547 [Thread-816] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775612_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775612_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:57,547 [Thread-816] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(258)) - Deleting block file BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775609_1012
2020-04-02 05:12:57,548 [Thread-816] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775609_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775609_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:57,548 [Thread-816] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775609_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775609_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:57,548 [Thread-816] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775609_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775609_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:57,549 [Thread-816] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775609_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775609_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:57,549 [Thread-816] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775609_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775609_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:57,549 [Thread-816] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775609_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775609_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:57,549 [Thread-816] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775609_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775609_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:57,550 [Thread-816] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775609_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775609_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:57,550 [Thread-816] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:deleteData(153)) - Deleting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775609
2020-04-02 05:12:57,550 [Thread-816] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(258)) - Deleting block file BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775608_1012
2020-04-02 05:12:57,551 [Thread-816] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:deleteData(153)) - Deleting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775608
2020-04-02 05:12:57,551 [Thread-816] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775608_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775608_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:57,551 [Thread-816] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775608_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775608_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:57,552 [Thread-816] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775608_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775608_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:57,552 [Thread-816] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775608_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775608_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:57,552 [Thread-816] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775608_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775608_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:57,552 [Thread-816] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775608_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775608_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:57,553 [Thread-816] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775608_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775608_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:57,553 [Thread-816] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775608_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775608_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:57,553 [Thread-816] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /deleted_1_2
2020-04-02 05:12:57,560 [Thread-816] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /deleted_1_2
2020-04-02 05:12:57,561 [IPC Server handler 8 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/deleted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:12:57,562 [Thread-816] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /deleted_1_2
2020-04-02 05:12:57,563 [IPC Server handler 6 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:12:57,567 [IPC Server handler 1 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775632_1011, blk_-9223372036854775616_1012]
2020-04-02 05:12:57,567 [IPC Server handler 1 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:12:59,145 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:59,145 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:59,145 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:59,145 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:12:59,146 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:38083 to delete [blk_-9223372036854775759_1003]
2020-04-02 05:12:59,146 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:41818 to delete [blk_-9223372036854775755_1003]
2020-04-02 05:12:59,146 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:33931 to delete [blk_-9223372036854775758_1003]
2020-04-02 05:13:00,067 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775755_1003 replica FinalizedReplica, blk_-9223372036854775755_1003, FINALIZED
  getNumBytes()     = 4194181
  getBytesOnDisk()  = 4194181
  getVisibleLength()= 4194181
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775755 for deletion
2020-04-02 05:13:00,069 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775755_1003 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775755
2020-04-02 05:13:00,966 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775759_1003 replica FinalizedReplica, blk_-9223372036854775759_1003, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775759 for deletion
2020-04-02 05:13:00,969 [Async disk worker #1 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775759_1003 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775759
2020-04-02 05:13:01,236 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775758_1003 replica FinalizedReplica, blk_-9223372036854775758_1003, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775758 for deletion
2020-04-02 05:13:01,280 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775758_1003 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775758
2020-04-02 05:13:02,146 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:02,148 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:02,148 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:13:02,148 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:13:02,148 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:45304 to delete [blk_-9223372036854775756_1003]
2020-04-02 05:13:02,148 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:39776 to delete [blk_-9223372036854775752_1003]
2020-04-02 05:13:02,148 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34596 to delete [blk_-9223372036854775757_1003]
2020-04-02 05:13:03,233 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775752_1003 replica FinalizedReplica, blk_-9223372036854775752_1003, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775752 for deletion
2020-04-02 05:13:03,242 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775756_1003 replica FinalizedReplica, blk_-9223372036854775756_1003, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775756 for deletion
2020-04-02 05:13:03,242 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775757_1003 replica FinalizedReplica, blk_-9223372036854775757_1003, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775757 for deletion
2020-04-02 05:13:03,253 [Async disk worker #1 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775752_1003 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775752
2020-04-02 05:13:03,266 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775756_1003 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775756
2020-04-02 05:13:03,276 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775757_1003 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775757
2020-04-02 05:13:05,148 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:05,149 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:05,149 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:13:05,149 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:13:08,149 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:08,150 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:08,150 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:13:08,150 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:13:11,150 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:11,151 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:11,151 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:13:11,151 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:13:11,425 [Thread-816] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /deleted_1_2
2020-04-02 05:13:11,429 [IPC Server handler 8 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775632_1011, blk_-9223372036854775616_1012]
2020-04-02 05:13:11,431 [IPC Server handler 8 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:13:14,151 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:14,151 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:14,151 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:13:14,151 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:13:14,787 [Thread-816] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /deleted_1_2
2020-04-02 05:13:14,806 [IPC Server handler 6 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775632_1011, blk_-9223372036854775616_1012]
2020-04-02 05:13:14,809 [IPC Server handler 6 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:13:17,152 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:17,153 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:17,153 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:13:17,153 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:13:18,612 [Thread-816] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /deleted_1_2
2020-04-02 05:13:18,615 [IPC Server handler 4 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775632_1011, blk_-9223372036854775616_1012]
2020-04-02 05:13:18,616 [IPC Server handler 4 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:13:20,154 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:20,154 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:20,154 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:13:20,155 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:13:23,155 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:23,155 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:23,155 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:13:23,155 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[8]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[8]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[9]
[msx] perform reset as unitTestCounterInClass 9 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:13:23,951 [Thread-879] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithBlockCorrupted(203)) - testReadWithBlockCorrupted: file = /deleted_2_0, dataBlkDelNum = 2, parityBlkDelNum = 0, deleteBlockFile? true
2020-04-02 05:13:24,008 [IPC Server handler 2 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/deleted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:13:24,010 [IPC Server handler 0 on 41191] DEBUG hdfs.StateChange (NameNodeRpcServer.java:delete(1084)) - *DIR* Namenode.delete: src=/deleted_2_0, recursive=true
2020-04-02 05:13:24,011 [IPC Server handler 0 on 41191] DEBUG hdfs.StateChange (FSDirDeleteOp.java:deleteInternal(180)) - DIR* NameSystem.delete: /deleted_2_0
2020-04-02 05:13:24,011 [IPC Server handler 0 on 41191] DEBUG hdfs.StateChange (FSDirDeleteOp.java:delete(55)) - DIR* FSDirectory.delete: /deleted_2_0
2020-04-02 05:13:24,012 [IPC Server handler 0 on 41191] DEBUG hdfs.StateChange (FSDirDeleteOp.java:unprotectedDelete(269)) - DIR* FSDirectory.unprotectedDelete: /deleted_2_0 is removed
2020-04-02 05:13:24,012 [IPC Server handler 0 on 41191] DEBUG hdfs.StateChange (FSDirDeleteOp.java:deleteInternal(201)) - DIR* Namesystem.delete: /deleted_2_0 is removed
2020-04-02 05:13:24,013 [IPC Server handler 0 on 41191] DEBUG BlockStateChange (BlockManager.java:addToInvalidates(1598)) - BLOCK* addToInvalidates: blk_-9223372036854775744_1004 127.0.0.1:45517 127.0.0.1:38003 127.0.0.1:33931 127.0.0.1:33488 127.0.0.1:34596 127.0.0.1:41818 127.0.0.1:38083 
2020-04-02 05:13:24,014 [IPC Server handler 0 on 41191] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775744_1004 from priority queue 1
2020-04-02 05:13:24,014 [IPC Server handler 0 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/deleted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:13:24,016 [IPC Server handler 1 on 41191] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /deleted_2_0 for DFSClient_NONMAPREDUCE_-1389971812_1 at 127.0.0.1
2020-04-02 05:13:24,016 [IPC Server handler 1 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/deleted_2_0, holder=DFSClient_NONMAPREDUCE_-1389971812_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:13:24,017 [IPC Server handler 1 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: deleted_2_0 is added
2020-04-02 05:13:24,017 [IPC Server handler 1 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /deleted_2_0 inode 16395 DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:13:24,017 [IPC Server handler 1 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/deleted_2_0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:13:24,042 [IPC Server handler 5 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /deleted_2_0  inodeId 16395 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:13:24,043 [IPC Server handler 5 on 41191] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:13:24,045 [IPC Server handler 5 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /deleted_2_0 with blk_-9223372036854775600_1013 block is added to the in-memory file system
2020-04-02 05:13:24,045 [IPC Server handler 5 on 41191] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775600_1013, replicas=127.0.0.1:45304, 127.0.0.1:45517, 127.0.0.1:33488, 127.0.0.1:39776, 127.0.0.1:38083, 127.0.0.1:38003, 127.0.0.1:33931, 127.0.0.1:41818, 127.0.0.1:34596 for /deleted_2_0
2020-04-02 05:13:24,045 [IPC Server handler 5 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /deleted_2_0 with new block blk_-9223372036854775600_1013, current total block count is 1
2020-04-02 05:13:24,050 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49586 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775600_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775600_1013 src: /127.0.0.1:49586 dest: /127.0.0.1:45304
2020-04-02 05:13:24,057 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:40072 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775599_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775599_1013 src: /127.0.0.1:40072 dest: /127.0.0.1:45517
2020-04-02 05:13:24,067 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:59262 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775598_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775598_1013 src: /127.0.0.1:59262 dest: /127.0.0.1:33488
2020-04-02 05:13:24,083 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50392 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775597_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775597_1013 src: /127.0.0.1:50392 dest: /127.0.0.1:39776
2020-04-02 05:13:24,094 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50454 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775596_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775596_1013 src: /127.0.0.1:50454 dest: /127.0.0.1:38083
2020-04-02 05:13:24,106 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:43332 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775595_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775595_1013 src: /127.0.0.1:43332 dest: /127.0.0.1:38003
2020-04-02 05:13:24,150 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:54026 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775594_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775594_1013 src: /127.0.0.1:54026 dest: /127.0.0.1:33931
2020-04-02 05:13:24,161 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:53450 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775593_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775593_1013 src: /127.0.0.1:53450 dest: /127.0.0.1:41818
2020-04-02 05:13:24,174 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50584 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775592_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775592_1013 src: /127.0.0.1:50584 dest: /127.0.0.1:34596
2020-04-02 05:13:24,246 [IPC Server handler 7 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33488, datanodeUuid=f1177179-f009-4517-a835-ba14c97e85ff, infoPort=42409, infoSecurePort=0, ipcPort=46631, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:24,246 [IPC Server handler 3 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45304, datanodeUuid=31f7c920-c39d-4ae7-b315-1227a3caafd0, infoPort=37250, infoSecurePort=0, ipcPort=45067, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:24,246 [IPC Server handler 5 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:24,246 [IPC Server handler 8 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34596, datanodeUuid=690f7552-c4c3-4286-845f-64b6525bf551, infoPort=44049, infoSecurePort=0, ipcPort=36235, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:24,247 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775598_1013 on 127.0.0.1:33488 size 4194304 replicaState = RBW
2020-04-02 05:13:24,247 [IPC Server handler 4 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45517, datanodeUuid=30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, infoPort=41207, infoSecurePort=0, ipcPort=44568, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:24,247 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:24,247 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775598_1013 is received from 127.0.0.1:33488
2020-04-02 05:13:24,248 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33488 receiving: 1, received: 0, deleted: 0
2020-04-02 05:13:24,248 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775600_1013 on 127.0.0.1:45304 size 4194304 replicaState = RBW
2020-04-02 05:13:24,248 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:24,248 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775600_1013 is received from 127.0.0.1:45304
2020-04-02 05:13:24,248 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45304 receiving: 1, received: 0, deleted: 0
2020-04-02 05:13:24,248 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775597_1013 on 127.0.0.1:39776 size 4194304 replicaState = RBW
2020-04-02 05:13:24,248 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:24,248 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775597_1013 is received from 127.0.0.1:39776
2020-04-02 05:13:24,248 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39776 receiving: 1, received: 0, deleted: 0
2020-04-02 05:13:24,248 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775592_1013 on 127.0.0.1:34596 size 4194304 replicaState = RBW
2020-04-02 05:13:24,248 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:24,248 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775592_1013 is received from 127.0.0.1:34596
2020-04-02 05:13:24,248 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34596 receiving: 1, received: 0, deleted: 0
2020-04-02 05:13:24,249 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775599_1013 on 127.0.0.1:45517 size 4194304 replicaState = RBW
2020-04-02 05:13:24,249 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:24,249 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775599_1013 is received from 127.0.0.1:45517
2020-04-02 05:13:24,249 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45517 receiving: 1, received: 0, deleted: 0
2020-04-02 05:13:24,360 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775592_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50584, dest: /127.0.0.1:34596, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 690f7552-c4c3-4286-845f-64b6525bf551, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775592_1013, duration(ns): 175943419
2020-04-02 05:13:24,360 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775596_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50454, dest: /127.0.0.1:38083, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 3d038cc2-f80f-4a72-8c2c-febccfb87908, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775596_1013, duration(ns): 257566736
2020-04-02 05:13:24,360 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775592_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775592_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:24,360 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775599_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40072, dest: /127.0.0.1:45517, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775599_1013, duration(ns): 293499706
2020-04-02 05:13:24,360 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775600_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49586, dest: /127.0.0.1:45304, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 31f7c920-c39d-4ae7-b315-1227a3caafd0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775600_1013, duration(ns): 300087263
2020-04-02 05:13:24,360 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775594_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54026, dest: /127.0.0.1:33931, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 04fa600d-9223-4e33-b0a1-d4242966c7f0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775594_1013, duration(ns): 201450463
2020-04-02 05:13:24,360 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775593_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53450, dest: /127.0.0.1:41818, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 138c0d7d-7e58-4339-8b75-15c135daf76d, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775593_1013, duration(ns): 189452505
2020-04-02 05:13:24,360 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775595_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43332, dest: /127.0.0.1:38003, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775595_1013, duration(ns): 245373864
2020-04-02 05:13:24,360 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775598_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59262, dest: /127.0.0.1:33488, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: f1177179-f009-4517-a835-ba14c97e85ff, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775598_1013, duration(ns): 284956349
2020-04-02 05:13:24,360 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775597_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50392, dest: /127.0.0.1:39776, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: ca9828e1-172e-4a2c-a1a8-917b3485899c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775597_1013, duration(ns): 266750064
2020-04-02 05:13:24,362 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775598_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775598_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:24,362 [IPC Server handler 3 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45517, datanodeUuid=30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, infoPort=41207, infoSecurePort=0, ipcPort=44568, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:24,362 [IPC Server handler 5 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:41818, datanodeUuid=138c0d7d-7e58-4339-8b75-15c135daf76d, infoPort=42795, infoSecurePort=0, ipcPort=43620, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:24,361 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775595_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775595_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:24,361 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775593_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775593_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:24,361 [IPC Server handler 7 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:24,361 [IPC Server handler 9 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45304, datanodeUuid=31f7c920-c39d-4ae7-b315-1227a3caafd0, infoPort=37250, infoSecurePort=0, ipcPort=45067, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:24,361 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775594_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775594_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:24,361 [IPC Server handler 1 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38083, datanodeUuid=3d038cc2-f80f-4a72-8c2c-febccfb87908, infoPort=37146, infoSecurePort=0, ipcPort=37392, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:24,361 [IPC Server handler 0 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33931, datanodeUuid=04fa600d-9223-4e33-b0a1-d4242966c7f0, infoPort=45217, infoSecurePort=0, ipcPort=38205, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:24,361 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775600_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775600_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:24,361 [IPC Server handler 2 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34596, datanodeUuid=690f7552-c4c3-4286-845f-64b6525bf551, infoPort=44049, infoSecurePort=0, ipcPort=36235, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:24,361 [IPC Server handler 6 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:24,361 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775599_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775599_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:24,360 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775596_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775596_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:24,363 [IPC Server handler 4 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /deleted_2_0  inodeId 16395 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:13:24,362 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775599_1013 on 127.0.0.1:45517 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:24,362 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775597_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775597_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:24,362 [IPC Server handler 8 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33488, datanodeUuid=f1177179-f009-4517-a835-ba14c97e85ff, infoPort=42409, infoSecurePort=0, ipcPort=46631, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:24,364 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:24,365 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45517 is added to blk_-9223372036854775600_1013 (size=0)
2020-04-02 05:13:24,365 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775599_1013 is received from 127.0.0.1:45517
2020-04-02 05:13:24,365 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45517 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:24,365 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775593_1013 on 127.0.0.1:41818 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:24,365 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:24,365 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:41818 is added to blk_-9223372036854775600_1013 (size=0)
2020-04-02 05:13:24,365 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775593_1013 is received from 127.0.0.1:41818
2020-04-02 05:13:24,365 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:41818 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:24,365 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775595_1013 on 127.0.0.1:38003 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:24,365 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:24,366 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38003 is added to blk_-9223372036854775600_1013 (size=0)
2020-04-02 05:13:24,366 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775595_1013 is received from 127.0.0.1:38003
2020-04-02 05:13:24,366 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38003 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:24,366 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775600_1013 on 127.0.0.1:45304 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:24,366 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:24,366 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45304 is added to blk_-9223372036854775600_1013 (size=0)
2020-04-02 05:13:24,366 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775600_1013 is received from 127.0.0.1:45304
2020-04-02 05:13:24,366 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45304 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:24,366 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775596_1013 on 127.0.0.1:38083 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:24,366 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:24,366 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38083 is added to blk_-9223372036854775600_1013 (size=0)
2020-04-02 05:13:24,366 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775596_1013 is received from 127.0.0.1:38083
2020-04-02 05:13:24,367 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38083 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:24,367 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775594_1013 on 127.0.0.1:33931 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:24,367 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:24,367 [IPC Server handler 4 on 41191] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:13:24,367 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33931 is added to blk_-9223372036854775600_1013 (size=0)
2020-04-02 05:13:24,367 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775594_1013 is received from 127.0.0.1:33931
2020-04-02 05:13:24,367 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33931 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:24,367 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775592_1013 on 127.0.0.1:34596 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:24,367 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:24,368 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34596 is added to blk_-9223372036854775600_1013 (size=0)
2020-04-02 05:13:24,368 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775592_1013 is received from 127.0.0.1:34596
2020-04-02 05:13:24,368 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34596 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:24,368 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775597_1013 on 127.0.0.1:39776 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:24,368 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:24,368 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39776 is added to blk_-9223372036854775600_1013 (size=0)
2020-04-02 05:13:24,368 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775597_1013 is received from 127.0.0.1:39776
2020-04-02 05:13:24,368 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39776 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:24,368 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775598_1013 on 127.0.0.1:33488 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:24,368 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:24,368 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33488 is added to blk_-9223372036854775600_1013 (size=0)
2020-04-02 05:13:24,368 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775598_1013 is received from 127.0.0.1:33488
2020-04-02 05:13:24,368 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33488 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:24,369 [IPC Server handler 4 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /deleted_2_0 with blk_-9223372036854775584_1014 block is added to the in-memory file system
2020-04-02 05:13:24,369 [IPC Server handler 4 on 41191] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775584_1014, replicas=127.0.0.1:45304, 127.0.0.1:38083, 127.0.0.1:33488, 127.0.0.1:38003, 127.0.0.1:34596, 127.0.0.1:33931, 127.0.0.1:45517, 127.0.0.1:41818, 127.0.0.1:39776 for /deleted_2_0
2020-04-02 05:13:24,369 [IPC Server handler 4 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /deleted_2_0 with new block blk_-9223372036854775584_1014, current total block count is 2
2020-04-02 05:13:24,371 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50406 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775576_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775576_1014 src: /127.0.0.1:50406 dest: /127.0.0.1:39776
2020-04-02 05:13:24,372 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:40094 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775578_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775578_1014 src: /127.0.0.1:40094 dest: /127.0.0.1:45517
2020-04-02 05:13:24,372 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:53456 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775577_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775577_1014 src: /127.0.0.1:53456 dest: /127.0.0.1:41818
2020-04-02 05:13:24,380 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49604 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775584_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775584_1014 src: /127.0.0.1:49604 dest: /127.0.0.1:45304
2020-04-02 05:13:24,386 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775584_1014, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49604, dest: /127.0.0.1:45304, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 31f7c920-c39d-4ae7-b315-1227a3caafd0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775584_1014, duration(ns): 3338029
2020-04-02 05:13:24,386 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775584_1014, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775584_1014, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:24,388 [IPC Server handler 3 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45304, datanodeUuid=31f7c920-c39d-4ae7-b315-1227a3caafd0, infoPort=37250, infoSecurePort=0, ipcPort=45067, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:24,388 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775578_1014, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40094, dest: /127.0.0.1:45517, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775578_1014, duration(ns): 6335160
2020-04-02 05:13:24,388 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775584_1014 on 127.0.0.1:45304 size 123 replicaState = FINALIZED
2020-04-02 05:13:24,388 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:24,388 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775578_1014, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775578_1014, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:24,388 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45304 is added to blk_-9223372036854775584_1014 (size=0)
2020-04-02 05:13:24,388 [IPC Server handler 5 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45517, datanodeUuid=30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, infoPort=41207, infoSecurePort=0, ipcPort=44568, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:24,389 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775584_1014 is received from 127.0.0.1:45304
2020-04-02 05:13:24,389 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45304 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:24,390 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775578_1014 on 127.0.0.1:45517 size 123 replicaState = FINALIZED
2020-04-02 05:13:24,390 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:24,390 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775577_1014, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53456, dest: /127.0.0.1:41818, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 138c0d7d-7e58-4339-8b75-15c135daf76d, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775577_1014, duration(ns): 5976689
2020-04-02 05:13:24,390 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45517 is added to blk_-9223372036854775584_1014 (size=0)
2020-04-02 05:13:24,390 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775577_1014, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775577_1014, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:24,390 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775578_1014 is received from 127.0.0.1:45517
2020-04-02 05:13:24,391 [IPC Server handler 7 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:41818, datanodeUuid=138c0d7d-7e58-4339-8b75-15c135daf76d, infoPort=42795, infoSecurePort=0, ipcPort=43620, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:24,391 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45517 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:24,391 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775577_1014 on 127.0.0.1:41818 size 123 replicaState = FINALIZED
2020-04-02 05:13:24,391 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:24,391 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:41818 is added to blk_-9223372036854775584_1014 (size=0)
2020-04-02 05:13:24,392 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775577_1014 is received from 127.0.0.1:41818
2020-04-02 05:13:24,392 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775576_1014, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50406, dest: /127.0.0.1:39776, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: ca9828e1-172e-4a2c-a1a8-917b3485899c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775576_1014, duration(ns): 18431808
2020-04-02 05:13:24,392 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:41818 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:24,392 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775576_1014, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775576_1014, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:24,392 [IPC Server handler 9 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:24,393 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775576_1014 on 127.0.0.1:39776 size 123 replicaState = FINALIZED
2020-04-02 05:13:24,393 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:24,393 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39776 is added to blk_-9223372036854775584_1014 (size=0)
2020-04-02 05:13:24,393 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775576_1014 is received from 127.0.0.1:39776
2020-04-02 05:13:24,393 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39776 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:24,394 [IPC Server handler 1 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /deleted_2_0 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:13:24,394 [IPC Server handler 1 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /deleted_2_0 with 2 blocks is persisted to the file system
2020-04-02 05:13:24,394 [IPC Server handler 1 on 41191] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /deleted_2_0 is closed by DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:13:24,395 [Thread-879] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(231)) - corruptBlocks on path /deleted_2_0
2020-04-02 05:13:24,403 [IPC Server handler 0 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775600_1013, blk_-9223372036854775584_1014]
2020-04-02 05:13:24,404 [IPC Server handler 0 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:13:24,405 [Thread-879] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(258)) - Deleting block file BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775582_1014
2020-04-02 05:13:24,406 [Thread-879] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775582_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775582_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:24,406 [Thread-879] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775582_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775582_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:24,406 [Thread-879] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775582_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775582_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:24,407 [Thread-879] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775582_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775582_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:24,407 [Thread-879] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775582_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775582_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:24,407 [Thread-879] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775582_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775582_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:24,407 [Thread-879] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775582_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775582_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:24,408 [Thread-879] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775582_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775582_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:24,408 [Thread-879] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775582_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775582_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:24,408 [Thread-879] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(258)) - Deleting block file BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775583_1014
2020-04-02 05:13:24,408 [Thread-879] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775583_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775583_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:24,409 [Thread-879] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775583_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775583_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:24,409 [Thread-879] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775583_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775583_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:24,409 [Thread-879] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775583_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775583_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:24,409 [Thread-879] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775583_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775583_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:24,410 [Thread-879] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775583_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775583_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:24,410 [Thread-879] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775583_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775583_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:24,410 [Thread-879] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775583_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775583_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:24,410 [Thread-879] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775583_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775583_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:24,411 [Thread-879] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /deleted_2_0
2020-04-02 05:13:24,418 [Thread-879] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /deleted_2_0
2020-04-02 05:13:24,419 [IPC Server handler 2 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/deleted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:13:24,420 [Thread-879] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /deleted_2_0
2020-04-02 05:13:24,420 [IPC Server handler 6 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:13:24,421 [IPC Server handler 8 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775600_1013, blk_-9223372036854775584_1014]
2020-04-02 05:13:24,421 [IPC Server handler 8 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:13:26,156 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:26,156 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:26,157 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:13:26,157 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:33488 to delete [blk_-9223372036854775741_1004]
2020-04-02 05:13:26,157 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:41818 to delete [blk_-9223372036854775737_1004]
2020-04-02 05:13:26,157 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:45517 to delete [blk_-9223372036854775744_1004]
2020-04-02 05:13:27,098 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775737_1004 replica FinalizedReplica, blk_-9223372036854775737_1004, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775737 for deletion
2020-04-02 05:13:27,101 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775737_1004 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775737
2020-04-02 05:13:27,242 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775741_1004 replica FinalizedReplica, blk_-9223372036854775741_1004, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775741 for deletion
2020-04-02 05:13:27,245 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775744_1004 replica FinalizedReplica, blk_-9223372036854775744_1004, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775744 for deletion
2020-04-02 05:13:27,247 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775741_1004 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775741
2020-04-02 05:13:27,251 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775744_1004 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775744
2020-04-02 05:13:29,158 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:29,159 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:29,159 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:13:29,159 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34596 to delete [blk_-9223372036854775738_1004]
2020-04-02 05:13:29,159 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:33931 to delete [blk_-9223372036854775742_1004]
2020-04-02 05:13:29,159 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:38083 to delete [blk_-9223372036854775736_1004]
2020-04-02 05:13:30,243 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775738_1004 replica FinalizedReplica, blk_-9223372036854775738_1004, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775738 for deletion
2020-04-02 05:13:30,246 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775738_1004 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775738
2020-04-02 05:13:30,968 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775736_1004 replica FinalizedReplica, blk_-9223372036854775736_1004, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775736 for deletion
2020-04-02 05:13:30,983 [Async disk worker #1 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775736_1004 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775736
2020-04-02 05:13:31,261 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775742_1004 replica FinalizedReplica, blk_-9223372036854775742_1004, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775742 for deletion
2020-04-02 05:13:31,283 [Async disk worker #1 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775742_1004 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775742
2020-04-02 05:13:32,160 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:32,185 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:32,186 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:13:32,186 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:38003 to delete [blk_-9223372036854775743_1004]
2020-04-02 05:13:33,097 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775743_1004 replica FinalizedReplica, blk_-9223372036854775743_1004, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775743 for deletion
2020-04-02 05:13:33,099 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775743_1004 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775743
2020-04-02 05:13:35,187 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:35,193 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:35,193 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:13:38,193 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:38,194 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:38,194 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:13:38,562 [Thread-879] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /deleted_2_0
2020-04-02 05:13:38,568 [IPC Server handler 4 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775600_1013, blk_-9223372036854775584_1014]
2020-04-02 05:13:38,570 [IPC Server handler 4 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:13:41,195 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:41,195 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:41,195 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:13:42,002 [Thread-879] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /deleted_2_0
2020-04-02 05:13:42,007 [IPC Server handler 9 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775600_1013, blk_-9223372036854775584_1014]
2020-04-02 05:13:42,008 [IPC Server handler 9 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:13:44,196 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:44,197 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:44,197 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:13:45,609 [Thread-879] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /deleted_2_0
2020-04-02 05:13:45,611 [IPC Server handler 3 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775600_1013, blk_-9223372036854775584_1014]
2020-04-02 05:13:45,612 [IPC Server handler 3 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:13:47,197 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:47,197 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:47,197 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:13:49,786 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@7e7b159b] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-04-02 05:13:50,198 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:50,198 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:50,198 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[9]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[9]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[10]
[msx] perform reset as unitTestCounterInClass 10 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:13:50,746 [Thread-945] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithBlockCorrupted(203)) - testReadWithBlockCorrupted: file = /deleted_2_1, dataBlkDelNum = 2, parityBlkDelNum = 1, deleteBlockFile? true
2020-04-02 05:13:50,807 [IPC Server handler 8 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/deleted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:13:50,809 [IPC Server handler 4 on 41191] DEBUG hdfs.StateChange (NameNodeRpcServer.java:delete(1084)) - *DIR* Namenode.delete: src=/deleted_2_1, recursive=true
2020-04-02 05:13:50,809 [IPC Server handler 4 on 41191] DEBUG hdfs.StateChange (FSDirDeleteOp.java:deleteInternal(180)) - DIR* NameSystem.delete: /deleted_2_1
2020-04-02 05:13:50,810 [IPC Server handler 4 on 41191] DEBUG hdfs.StateChange (FSDirDeleteOp.java:delete(55)) - DIR* FSDirectory.delete: /deleted_2_1
2020-04-02 05:13:50,810 [IPC Server handler 4 on 41191] DEBUG hdfs.StateChange (FSDirDeleteOp.java:unprotectedDelete(269)) - DIR* FSDirectory.unprotectedDelete: /deleted_2_1 is removed
2020-04-02 05:13:50,811 [IPC Server handler 4 on 41191] DEBUG hdfs.StateChange (FSDirDeleteOp.java:deleteInternal(201)) - DIR* Namesystem.delete: /deleted_2_1 is removed
2020-04-02 05:13:50,811 [IPC Server handler 4 on 41191] DEBUG BlockStateChange (BlockManager.java:addToInvalidates(1598)) - BLOCK* addToInvalidates: blk_-9223372036854775728_1005 127.0.0.1:33488 127.0.0.1:34596 127.0.0.1:45304 127.0.0.1:39776 127.0.0.1:33931 127.0.0.1:41818 
2020-04-02 05:13:50,811 [IPC Server handler 4 on 41191] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775728_1005 from priority queue 0
2020-04-02 05:13:50,812 [IPC Server handler 4 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/deleted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:13:50,814 [IPC Server handler 6 on 41191] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /deleted_2_1 for DFSClient_NONMAPREDUCE_-1389971812_1 at 127.0.0.1
2020-04-02 05:13:50,814 [IPC Server handler 6 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/deleted_2_1, holder=DFSClient_NONMAPREDUCE_-1389971812_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:13:50,815 [IPC Server handler 6 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: deleted_2_1 is added
2020-04-02 05:13:50,815 [IPC Server handler 6 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /deleted_2_1 inode 16396 DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:13:50,815 [IPC Server handler 6 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/deleted_2_1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:13:50,840 [IPC Server handler 5 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /deleted_2_1  inodeId 16396 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:13:50,841 [IPC Server handler 5 on 41191] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:13:50,843 [IPC Server handler 5 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /deleted_2_1 with blk_-9223372036854775568_1015 block is added to the in-memory file system
2020-04-02 05:13:50,843 [IPC Server handler 5 on 41191] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775568_1015, replicas=127.0.0.1:39776, 127.0.0.1:33488, 127.0.0.1:34596, 127.0.0.1:45304, 127.0.0.1:41818, 127.0.0.1:33931, 127.0.0.1:45517, 127.0.0.1:38003, 127.0.0.1:38083 for /deleted_2_1
2020-04-02 05:13:50,843 [IPC Server handler 5 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /deleted_2_1 with new block blk_-9223372036854775568_1015, current total block count is 1
2020-04-02 05:13:50,847 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50496 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775568_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775568_1015 src: /127.0.0.1:50496 dest: /127.0.0.1:39776
2020-04-02 05:13:50,850 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:59370 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775567_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775567_1015 src: /127.0.0.1:59370 dest: /127.0.0.1:33488
2020-04-02 05:13:50,873 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50682 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775566_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775566_1015 src: /127.0.0.1:50682 dest: /127.0.0.1:34596
2020-04-02 05:13:50,881 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49702 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775565_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775565_1015 src: /127.0.0.1:49702 dest: /127.0.0.1:45304
2020-04-02 05:13:50,892 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:53554 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775564_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775564_1015 src: /127.0.0.1:53554 dest: /127.0.0.1:41818
2020-04-02 05:13:50,900 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:54134 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775563_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775563_1015 src: /127.0.0.1:54134 dest: /127.0.0.1:33931
2020-04-02 05:13:50,949 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:40192 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775562_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775562_1015 src: /127.0.0.1:40192 dest: /127.0.0.1:45517
2020-04-02 05:13:50,961 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:43446 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775561_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775561_1015 src: /127.0.0.1:43446 dest: /127.0.0.1:38003
2020-04-02 05:13:50,971 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50572 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775560_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775560_1015 src: /127.0.0.1:50572 dest: /127.0.0.1:38083
2020-04-02 05:13:51,097 [IPC Server handler 9 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:51,097 [IPC Server handler 1 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:41818, datanodeUuid=138c0d7d-7e58-4339-8b75-15c135daf76d, infoPort=42795, infoSecurePort=0, ipcPort=43620, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:51,097 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775561_1015 on 127.0.0.1:38003 size 4194304 replicaState = RBW
2020-04-02 05:13:51,097 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:51,097 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775561_1015 is received from 127.0.0.1:38003
2020-04-02 05:13:51,097 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38003 receiving: 1, received: 0, deleted: 0
2020-04-02 05:13:51,097 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775564_1015 on 127.0.0.1:41818 size 4194304 replicaState = RBW
2020-04-02 05:13:51,098 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:51,098 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775564_1015 is received from 127.0.0.1:41818
2020-04-02 05:13:51,098 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:41818 receiving: 1, received: 0, deleted: 0
2020-04-02 05:13:51,178 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775567_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59370, dest: /127.0.0.1:33488, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: f1177179-f009-4517-a835-ba14c97e85ff, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775567_1015, duration(ns): 319081144
2020-04-02 05:13:51,178 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775567_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775567_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:51,180 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775568_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50496, dest: /127.0.0.1:39776, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: ca9828e1-172e-4a2c-a1a8-917b3485899c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775568_1015, duration(ns): 323416830
2020-04-02 05:13:51,180 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775566_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50682, dest: /127.0.0.1:34596, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 690f7552-c4c3-4286-845f-64b6525bf551, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775566_1015, duration(ns): 298877677
2020-04-02 05:13:51,181 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775561_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43446, dest: /127.0.0.1:38003, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775561_1015, duration(ns): 211350786
2020-04-02 05:13:51,181 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775568_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775568_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:51,181 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775561_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775561_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:51,181 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775560_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50572, dest: /127.0.0.1:38083, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 3d038cc2-f80f-4a72-8c2c-febccfb87908, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775560_1015, duration(ns): 200816659
2020-04-02 05:13:51,181 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775564_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53554, dest: /127.0.0.1:41818, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 138c0d7d-7e58-4339-8b75-15c135daf76d, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775564_1015, duration(ns): 278452916
2020-04-02 05:13:51,181 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775560_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775560_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:51,181 [IPC Server handler 2 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34596, datanodeUuid=690f7552-c4c3-4286-845f-64b6525bf551, infoPort=44049, infoSecurePort=0, ipcPort=36235, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:51,181 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775564_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775564_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:51,181 [IPC Server handler 8 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45517, datanodeUuid=30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, infoPort=41207, infoSecurePort=0, ipcPort=44568, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:51,181 [IPC Server handler 6 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:41818, datanodeUuid=138c0d7d-7e58-4339-8b75-15c135daf76d, infoPort=42795, infoSecurePort=0, ipcPort=43620, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:51,181 [IPC Server handler 4 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38083, datanodeUuid=3d038cc2-f80f-4a72-8c2c-febccfb87908, infoPort=37146, infoSecurePort=0, ipcPort=37392, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:51,181 [IPC Server handler 0 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33488, datanodeUuid=f1177179-f009-4517-a835-ba14c97e85ff, infoPort=42409, infoSecurePort=0, ipcPort=46631, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:51,181 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775565_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49702, dest: /127.0.0.1:45304, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 31f7c920-c39d-4ae7-b315-1227a3caafd0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775565_1015, duration(ns): 289728493
2020-04-02 05:13:51,181 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775563_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54134, dest: /127.0.0.1:33931, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 04fa600d-9223-4e33-b0a1-d4242966c7f0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775563_1015, duration(ns): 274799445
2020-04-02 05:13:51,181 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775566_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775566_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:51,183 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775563_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775563_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:51,181 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775562_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40192, dest: /127.0.0.1:45517, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775562_1015, duration(ns): 222482748
2020-04-02 05:13:51,182 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775565_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775565_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:51,183 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775562_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775562_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:51,182 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775566_1015 on 127.0.0.1:34596 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:51,182 [IPC Server handler 9 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33931, datanodeUuid=04fa600d-9223-4e33-b0a1-d4242966c7f0, infoPort=45217, infoSecurePort=0, ipcPort=38205, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:51,182 [IPC Server handler 3 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45304, datanodeUuid=31f7c920-c39d-4ae7-b315-1227a3caafd0, infoPort=37250, infoSecurePort=0, ipcPort=45067, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:51,182 [IPC Server handler 7 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:51,181 [IPC Server handler 5 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:51,183 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:51,184 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34596 is added to blk_-9223372036854775568_1015 (size=0)
2020-04-02 05:13:51,184 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775566_1015 is received from 127.0.0.1:34596
2020-04-02 05:13:51,184 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34596 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:51,184 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775562_1015 on 127.0.0.1:45517 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:51,184 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:51,184 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45517 is added to blk_-9223372036854775568_1015 (size=0)
2020-04-02 05:13:51,184 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775562_1015 is received from 127.0.0.1:45517
2020-04-02 05:13:51,184 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45517 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:51,184 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775564_1015 on 127.0.0.1:41818 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:51,185 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:51,185 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:41818 is added to blk_-9223372036854775568_1015 (size=0)
2020-04-02 05:13:51,185 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775564_1015 is received from 127.0.0.1:41818
2020-04-02 05:13:51,185 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:41818 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:51,185 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775560_1015 on 127.0.0.1:38083 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:51,185 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:51,185 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38083 is added to blk_-9223372036854775568_1015 (size=0)
2020-04-02 05:13:51,185 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775560_1015 is received from 127.0.0.1:38083
2020-04-02 05:13:51,185 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38083 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:51,185 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775567_1015 on 127.0.0.1:33488 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:51,185 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:51,185 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33488 is added to blk_-9223372036854775568_1015 (size=0)
2020-04-02 05:13:51,185 [IPC Server handler 1 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /deleted_2_1  inodeId 16396 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:13:51,185 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775567_1015 is received from 127.0.0.1:33488
2020-04-02 05:13:51,186 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33488 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:51,186 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775563_1015 on 127.0.0.1:33931 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:51,186 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:51,186 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33931 is added to blk_-9223372036854775568_1015 (size=0)
2020-04-02 05:13:51,186 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775563_1015 is received from 127.0.0.1:33931
2020-04-02 05:13:51,186 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33931 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:51,186 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775565_1015 on 127.0.0.1:45304 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:51,186 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:51,186 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45304 is added to blk_-9223372036854775568_1015 (size=0)
2020-04-02 05:13:51,186 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775565_1015 is received from 127.0.0.1:45304
2020-04-02 05:13:51,186 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45304 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:51,186 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775561_1015 on 127.0.0.1:38003 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:51,186 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:51,186 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38003 is added to blk_-9223372036854775568_1015 (size=0)
2020-04-02 05:13:51,187 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775561_1015 is received from 127.0.0.1:38003
2020-04-02 05:13:51,187 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38003 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:51,187 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775568_1015 on 127.0.0.1:39776 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:51,187 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:51,187 [IPC Server handler 1 on 41191] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:13:51,187 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39776 is added to blk_-9223372036854775568_1015 (size=0)
2020-04-02 05:13:51,187 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775568_1015 is received from 127.0.0.1:39776
2020-04-02 05:13:51,187 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39776 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:51,190 [IPC Server handler 1 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /deleted_2_1 with blk_-9223372036854775552_1016 block is added to the in-memory file system
2020-04-02 05:13:51,190 [IPC Server handler 1 on 41191] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775552_1016, replicas=127.0.0.1:45304, 127.0.0.1:39776, 127.0.0.1:34596, 127.0.0.1:33488, 127.0.0.1:41818, 127.0.0.1:45517, 127.0.0.1:33931, 127.0.0.1:38083, 127.0.0.1:38003 for /deleted_2_1
2020-04-02 05:13:51,190 [IPC Server handler 1 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /deleted_2_1 with new block blk_-9223372036854775552_1016, current total block count is 2
2020-04-02 05:13:51,192 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50574 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775545_1016]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775545_1016 src: /127.0.0.1:50574 dest: /127.0.0.1:38083
2020-04-02 05:13:51,192 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49714 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016 src: /127.0.0.1:49714 dest: /127.0.0.1:45304
2020-04-02 05:13:51,192 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:43450 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775544_1016]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775544_1016 src: /127.0.0.1:43450 dest: /127.0.0.1:38003
2020-04-02 05:13:51,193 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:54146 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775546_1016]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775546_1016 src: /127.0.0.1:54146 dest: /127.0.0.1:33931
2020-04-02 05:13:51,201 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49714, dest: /127.0.0.1:45304, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 31f7c920-c39d-4ae7-b315-1227a3caafd0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016, duration(ns): 3190118
2020-04-02 05:13:51,201 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:51,201 [IPC Server handler 2 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45304, datanodeUuid=31f7c920-c39d-4ae7-b315-1227a3caafd0, infoPort=37250, infoSecurePort=0, ipcPort=45067, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:51,202 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775552_1016 on 127.0.0.1:45304 size 123 replicaState = FINALIZED
2020-04-02 05:13:51,202 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775546_1016, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54146, dest: /127.0.0.1:33931, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 04fa600d-9223-4e33-b0a1-d4242966c7f0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775546_1016, duration(ns): 6019194
2020-04-02 05:13:51,202 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:51,202 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775546_1016, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775546_1016, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:51,202 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45304 is added to blk_-9223372036854775552_1016 (size=0)
2020-04-02 05:13:51,203 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775552_1016 is received from 127.0.0.1:45304
2020-04-02 05:13:51,203 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45304 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:51,203 [IPC Server handler 8 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33931, datanodeUuid=04fa600d-9223-4e33-b0a1-d4242966c7f0, infoPort=45217, infoSecurePort=0, ipcPort=38205, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:51,203 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775546_1016 on 127.0.0.1:33931 size 123 replicaState = FINALIZED
2020-04-02 05:13:51,204 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775545_1016, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50574, dest: /127.0.0.1:38083, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 3d038cc2-f80f-4a72-8c2c-febccfb87908, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775545_1016, duration(ns): 7604526
2020-04-02 05:13:51,204 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:51,204 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775545_1016, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775545_1016, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:51,204 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33931 is added to blk_-9223372036854775552_1016 (size=0)
2020-04-02 05:13:51,204 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775546_1016 is received from 127.0.0.1:33931
2020-04-02 05:13:51,204 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33931 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:51,204 [IPC Server handler 6 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38083, datanodeUuid=3d038cc2-f80f-4a72-8c2c-febccfb87908, infoPort=37146, infoSecurePort=0, ipcPort=37392, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:51,204 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775545_1016 on 127.0.0.1:38083 size 123 replicaState = FINALIZED
2020-04-02 05:13:51,205 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775544_1016, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43450, dest: /127.0.0.1:38003, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775544_1016, duration(ns): 10524416
2020-04-02 05:13:51,205 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:51,206 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775544_1016, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775544_1016, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:51,206 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38083 is added to blk_-9223372036854775552_1016 (size=0)
2020-04-02 05:13:51,206 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775545_1016 is received from 127.0.0.1:38083
2020-04-02 05:13:51,206 [IPC Server handler 4 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:51,206 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38083 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:51,206 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775544_1016 on 127.0.0.1:38003 size 123 replicaState = FINALIZED
2020-04-02 05:13:51,206 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:51,206 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38003 is added to blk_-9223372036854775552_1016 (size=0)
2020-04-02 05:13:51,206 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775544_1016 is received from 127.0.0.1:38003
2020-04-02 05:13:51,206 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38003 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:51,207 [IPC Server handler 0 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /deleted_2_1 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:13:51,207 [IPC Server handler 0 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /deleted_2_1 with 2 blocks is persisted to the file system
2020-04-02 05:13:51,207 [IPC Server handler 0 on 41191] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /deleted_2_1 is closed by DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:13:51,208 [Thread-945] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(231)) - corruptBlocks on path /deleted_2_1
2020-04-02 05:13:51,214 [IPC Server handler 9 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775568_1015, blk_-9223372036854775552_1016]
2020-04-02 05:13:51,215 [IPC Server handler 9 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:13:51,216 [Thread-945] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(258)) - Deleting block file BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016
2020-04-02 05:13:51,217 [Thread-945] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:51,217 [Thread-945] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:51,217 [Thread-945] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:51,218 [Thread-945] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:51,218 [Thread-945] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:51,218 [Thread-945] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:51,219 [Thread-945] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:deleteData(153)) - Deleting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir1/blk_-9223372036854775552
2020-04-02 05:13:51,219 [Thread-945] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:51,219 [Thread-945] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:51,220 [Thread-945] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(258)) - Deleting block file BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775550_1016
2020-04-02 05:13:51,220 [Thread-945] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775550_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775550_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:51,220 [Thread-945] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775550_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775550_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:51,220 [Thread-945] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775550_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775550_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:51,220 [Thread-945] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775550_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775550_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:51,221 [Thread-945] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775550_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775550_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:51,221 [Thread-945] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775550_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775550_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:51,221 [Thread-945] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775550_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775550_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:51,221 [Thread-945] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775550_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775550_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:51,222 [Thread-945] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775550_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775550_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:51,222 [Thread-945] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(258)) - Deleting block file BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775544_1016
2020-04-02 05:13:51,222 [Thread-945] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775544_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775544_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:51,222 [Thread-945] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775544_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775544_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:51,222 [Thread-945] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775544_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775544_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:51,223 [Thread-945] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775544_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775544_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:51,223 [Thread-945] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775544_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775544_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:51,223 [Thread-945] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:deleteData(153)) - Deleting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir1/blk_-9223372036854775544
2020-04-02 05:13:51,223 [Thread-945] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775544_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775544_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:51,224 [Thread-945] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775544_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775544_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:51,224 [Thread-945] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775544_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775544_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:51,224 [Thread-945] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /deleted_2_1
2020-04-02 05:13:51,232 [Thread-945] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /deleted_2_1
2020-04-02 05:13:51,232 [IPC Server handler 3 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/deleted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:13:51,233 [Thread-945] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /deleted_2_1
2020-04-02 05:13:51,234 [IPC Server handler 7 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:13:51,234 [IPC Server handler 5 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775568_1015, blk_-9223372036854775552_1016]
2020-04-02 05:13:51,235 [IPC Server handler 5 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:13:51,253 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49612 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016]] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775552_1016 replica FinalizedReplica, blk_-9223372036854775552_1016, FINALIZED
  getNumBytes()     = 123
  getBytesOnDisk()  = 123
  getVisibleLength()= 123
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir1/blk_-9223372036854775552 for deletion
2020-04-02 05:13:51,253 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49612 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016]] INFO  datanode.DataNode (DataXceiver.java:readBlock(598)) - opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016 received exception java.io.FileNotFoundException: BlockId -9223372036854775552 is not valid.
2020-04-02 05:13:51,254 [Async disk worker #2 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775552_1016 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir1/blk_-9223372036854775552
2020-04-02 05:13:51,255 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49612 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016]] WARN  datanode.DataNode (DataXceiver.java:readBlock(643)) - DatanodeRegistration(127.0.0.1:45304, datanodeUuid=31f7c920-c39d-4ae7-b315-1227a3caafd0, infoPort=37250, infoSecurePort=0, ipcPort=45067, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366):Got exception while serving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016 to /127.0.0.1:49612
java.io.FileNotFoundException: BlockId -9223372036854775552 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:13:51,255 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49612 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016]] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:45304:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:49612 dst: /127.0.0.1:45304
java.io.FileNotFoundException: BlockId -9223372036854775552 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:13:51,256 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49726 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016]] INFO  datanode.DataNode (DataXceiver.java:readBlock(598)) - opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016
2020-04-02 05:13:51,257 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49726 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016]] WARN  datanode.DataNode (DataXceiver.java:readBlock(643)) - DatanodeRegistration(127.0.0.1:45304, datanodeUuid=31f7c920-c39d-4ae7-b315-1227a3caafd0, infoPort=37250, infoSecurePort=0, ipcPort=45067, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366):Got exception while serving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016 to /127.0.0.1:49726
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.getReplica(BlockSender.java:492)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:256)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:13:51,257 [Thread-945] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016, for OP_READ_BLOCK, self=/127.0.0.1:49726, remote=/127.0.0.1:45304, for file /deleted_2_1, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775552_1016
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:51,257 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49726 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016]] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:45304:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:49726 dst: /127.0.0.1:45304
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.getReplica(BlockSender.java:492)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:256)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:13:51,259 [Thread-945] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:45304 for blockBP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775552_1016, for OP_READ_BLOCK, self=/127.0.0.1:49726, remote=/127.0.0.1:45304, for file /deleted_2_1, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775552_1016
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:51,259 [IPC Server handler 1 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775568_1015, blk_-9223372036854775552_1016]
2020-04-02 05:13:51,260 [IPC Server handler 1 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:13:51,261 [Thread-945] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:45304,DS-52fa7b3d-3f2c-4afb-8e3c-b713e4545d8d,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:13:51,279 [IPC Server handler 9 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45304, datanodeUuid=31f7c920-c39d-4ae7-b315-1227a3caafd0, infoPort=37250, infoSecurePort=0, ipcPort=45067, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:13:51,279 [Block report processor] DEBUG BlockStateChange (BlockManager.java:removeStoredBlock(3781)) - BLOCK* removeStoredBlock: blk_-9223372036854775552_1016 from 127.0.0.1:45304
2020-04-02 05:13:51,280 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775552_1016 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:13:51,280 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775552_1016 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:13:51,280 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block DELETED_BLOCK: blk_-9223372036854775552_1016 is received from 127.0.0.1:45304
2020-04-02 05:13:51,280 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45304 receiving: 0, received: 0, deleted: 1
2020-04-02 05:13:53,199 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:53,199 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775552_1016 cannot be reconstructed from any node
2020-04-02 05:13:53,199 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:13:53,199 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:33931 to delete [blk_-9223372036854775721_1005]
2020-04-02 05:13:53,199 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:33488 to delete [blk_-9223372036854775726_1005]
2020-04-02 05:13:53,199 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:45304 to delete [blk_-9223372036854775724_1005]
2020-04-02 05:13:54,284 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775724_1005 replica FinalizedReplica, blk_-9223372036854775724_1005, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775724 for deletion
2020-04-02 05:13:54,284 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775726_1005 replica FinalizedReplica, blk_-9223372036854775726_1005, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775726 for deletion
2020-04-02 05:13:54,381 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775724_1005 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775724
2020-04-02 05:13:54,381 [Async disk worker #2 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775726_1005 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775726
2020-04-02 05:13:55,263 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775721_1005 replica FinalizedReplica, blk_-9223372036854775721_1005, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775721 for deletion
2020-04-02 05:13:55,266 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775721_1005 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775721
2020-04-02 05:13:56,200 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:56,203 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775552_1016 cannot be reconstructed from any node
2020-04-02 05:13:56,203 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:13:56,204 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:41818 to delete [blk_-9223372036854775720_1005]
2020-04-02 05:13:56,204 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:39776 to delete [blk_-9223372036854775723_1005]
2020-04-02 05:13:56,204 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34596 to delete [blk_-9223372036854775725_1005]
2020-04-02 05:13:57,097 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775720_1005 replica FinalizedReplica, blk_-9223372036854775720_1005, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775720 for deletion
2020-04-02 05:13:57,099 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775720_1005 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775720
2020-04-02 05:13:57,280 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775725_1005 replica FinalizedReplica, blk_-9223372036854775725_1005, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775725 for deletion
2020-04-02 05:13:57,285 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775723_1005 replica FinalizedReplica, blk_-9223372036854775723_1005, FINALIZED
  getNumBytes()     = 4194181
  getBytesOnDisk()  = 4194181
  getVisibleLength()= 4194181
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775723 for deletion
2020-04-02 05:13:57,287 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775725_1005 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775725
2020-04-02 05:13:57,293 [Async disk worker #1 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775723_1005 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775723
2020-04-02 05:13:59,205 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:59,205 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775552_1016 cannot be reconstructed from any node
2020-04-02 05:13:59,206 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:14:02,206 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:14:02,208 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775552_1016 cannot be reconstructed from any node
2020-04-02 05:14:02,208 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:14:05,209 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:14:05,209 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775552_1016 cannot be reconstructed from any node
2020-04-02 05:14:05,209 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:14:05,238 [Thread-945] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /deleted_2_1
2020-04-02 05:14:05,249 [IPC Server handler 7 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775568_1015, blk_-9223372036854775552_1016]
2020-04-02 05:14:05,252 [IPC Server handler 7 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:14:08,210 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:14:08,211 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775552_1016 cannot be reconstructed from any node
2020-04-02 05:14:08,211 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:14:09,169 [Thread-945] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /deleted_2_1
2020-04-02 05:14:09,185 [IPC Server handler 0 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775568_1015, blk_-9223372036854775552_1016]
2020-04-02 05:14:09,190 [IPC Server handler 0 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:14:11,212 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:14:11,212 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775552_1016 cannot be reconstructed from any node
2020-04-02 05:14:11,212 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:14:13,040 [Thread-945] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /deleted_2_1
2020-04-02 05:14:13,043 [IPC Server handler 9 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775568_1015, blk_-9223372036854775552_1016]
2020-04-02 05:14:13,044 [IPC Server handler 9 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:14:14,212 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:14:14,213 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775552_1016 cannot be reconstructed from any node
2020-04-02 05:14:14,213 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:14:17,213 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:14:17,214 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775552_1016 cannot be reconstructed from any node
2020-04-02 05:14:17,214 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[10]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[10]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[11]
[msx] perform reset as unitTestCounterInClass 11 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:14:18,247 [Thread-1012] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithBlockCorrupted(203)) - testReadWithBlockCorrupted: file = /deleted_3_0, dataBlkDelNum = 3, parityBlkDelNum = 0, deleteBlockFile? true
2020-04-02 05:14:18,306 [IPC Server handler 0 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/deleted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:14:18,308 [IPC Server handler 7 on 41191] DEBUG hdfs.StateChange (NameNodeRpcServer.java:delete(1084)) - *DIR* Namenode.delete: src=/deleted_3_0, recursive=true
2020-04-02 05:14:18,309 [IPC Server handler 7 on 41191] DEBUG hdfs.StateChange (FSDirDeleteOp.java:deleteInternal(180)) - DIR* NameSystem.delete: /deleted_3_0
2020-04-02 05:14:18,309 [IPC Server handler 7 on 41191] DEBUG hdfs.StateChange (FSDirDeleteOp.java:delete(55)) - DIR* FSDirectory.delete: /deleted_3_0
2020-04-02 05:14:18,309 [IPC Server handler 7 on 41191] DEBUG hdfs.StateChange (FSDirDeleteOp.java:unprotectedDelete(269)) - DIR* FSDirectory.unprotectedDelete: /deleted_3_0 is removed
2020-04-02 05:14:18,309 [IPC Server handler 7 on 41191] DEBUG hdfs.StateChange (FSDirDeleteOp.java:deleteInternal(201)) - DIR* Namesystem.delete: /deleted_3_0 is removed
2020-04-02 05:14:18,309 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 79 Total time for transactions(ms): 47 Number of transactions batched in Syncs: 14 Number of syncs: 65 SyncTimes(ms): 1 1 
2020-04-02 05:14:18,310 [IPC Server handler 7 on 41191] DEBUG BlockStateChange (BlockManager.java:addToInvalidates(1598)) - BLOCK* addToInvalidates: blk_-9223372036854775712_1006 127.0.0.1:41818 127.0.0.1:45304 127.0.0.1:38083 127.0.0.1:33931 127.0.0.1:33488 127.0.0.1:45517 
2020-04-02 05:14:18,310 [IPC Server handler 7 on 41191] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775712_1006 from priority queue 0
2020-04-02 05:14:18,310 [IPC Server handler 7 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/deleted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:14:18,311 [IPC Server handler 2 on 41191] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /deleted_3_0 for DFSClient_NONMAPREDUCE_-1389971812_1 at 127.0.0.1
2020-04-02 05:14:18,311 [IPC Server handler 2 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/deleted_3_0, holder=DFSClient_NONMAPREDUCE_-1389971812_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:14:18,312 [IPC Server handler 2 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: deleted_3_0 is added
2020-04-02 05:14:18,312 [IPC Server handler 2 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /deleted_3_0 inode 16397 DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:14:18,312 [IPC Server handler 2 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/deleted_3_0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:14:18,335 [IPC Server handler 5 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /deleted_3_0  inodeId 16397 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:14:18,335 [IPC Server handler 5 on 41191] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:14:18,337 [IPC Server handler 5 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /deleted_3_0 with blk_-9223372036854775536_1017 block is added to the in-memory file system
2020-04-02 05:14:18,337 [IPC Server handler 5 on 41191] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775536_1017, replicas=127.0.0.1:34596, 127.0.0.1:33931, 127.0.0.1:33488, 127.0.0.1:38003, 127.0.0.1:41818, 127.0.0.1:45304, 127.0.0.1:38083, 127.0.0.1:39776, 127.0.0.1:45517 for /deleted_3_0
2020-04-02 05:14:18,337 [IPC Server handler 5 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /deleted_3_0 with new block blk_-9223372036854775536_1017, current total block count is 1
2020-04-02 05:14:18,340 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50808 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775536_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775536_1017 src: /127.0.0.1:50808 dest: /127.0.0.1:34596
2020-04-02 05:14:18,349 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:54256 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775535_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775535_1017 src: /127.0.0.1:54256 dest: /127.0.0.1:33931
2020-04-02 05:14:18,367 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:59502 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775534_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775534_1017 src: /127.0.0.1:59502 dest: /127.0.0.1:33488
2020-04-02 05:14:18,376 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:43568 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775533_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775533_1017 src: /127.0.0.1:43568 dest: /127.0.0.1:38003
2020-04-02 05:14:18,383 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:53684 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775532_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775532_1017 src: /127.0.0.1:53684 dest: /127.0.0.1:41818
2020-04-02 05:14:18,396 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:49836 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775531_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775531_1017 src: /127.0.0.1:49836 dest: /127.0.0.1:45304
2020-04-02 05:14:18,442 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50698 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775530_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775530_1017 src: /127.0.0.1:50698 dest: /127.0.0.1:38083
2020-04-02 05:14:18,458 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50640 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775529_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775529_1017 src: /127.0.0.1:50640 dest: /127.0.0.1:39776
2020-04-02 05:14:18,467 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:40326 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775528_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775528_1017 src: /127.0.0.1:40326 dest: /127.0.0.1:45517
2020-04-02 05:14:18,661 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775530_1017, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50698, dest: /127.0.0.1:38083, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 3d038cc2-f80f-4a72-8c2c-febccfb87908, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775530_1017, duration(ns): 213760479
2020-04-02 05:14:18,665 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775529_1017, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50640, dest: /127.0.0.1:39776, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: ca9828e1-172e-4a2c-a1a8-917b3485899c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775529_1017, duration(ns): 198301439
2020-04-02 05:14:18,664 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775534_1017, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59502, dest: /127.0.0.1:33488, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: f1177179-f009-4517-a835-ba14c97e85ff, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775534_1017, duration(ns): 289515769
2020-04-02 05:14:18,664 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775535_1017, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54256, dest: /127.0.0.1:33931, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 04fa600d-9223-4e33-b0a1-d4242966c7f0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775535_1017, duration(ns): 303217887
2020-04-02 05:14:18,664 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775532_1017, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53684, dest: /127.0.0.1:41818, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 138c0d7d-7e58-4339-8b75-15c135daf76d, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775532_1017, duration(ns): 270933970
2020-04-02 05:14:18,664 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775531_1017, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49836, dest: /127.0.0.1:45304, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 31f7c920-c39d-4ae7-b315-1227a3caafd0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775531_1017, duration(ns): 259996810
2020-04-02 05:14:18,664 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775528_1017, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40326, dest: /127.0.0.1:45517, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775528_1017, duration(ns): 185834072
2020-04-02 05:14:18,665 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775531_1017, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775531_1017, type=LAST_IN_PIPELINE terminating
2020-04-02 05:14:18,665 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775528_1017, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775528_1017, type=LAST_IN_PIPELINE terminating
2020-04-02 05:14:18,664 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775533_1017, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43568, dest: /127.0.0.1:38003, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775533_1017, duration(ns): 280315626
2020-04-02 05:14:18,666 [IPC Server handler 7 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45304, datanodeUuid=31f7c920-c39d-4ae7-b315-1227a3caafd0, infoPort=37250, infoSecurePort=0, ipcPort=45067, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:14:18,666 [IPC Server handler 0 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33488, datanodeUuid=f1177179-f009-4517-a835-ba14c97e85ff, infoPort=42409, infoSecurePort=0, ipcPort=46631, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:14:18,666 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775531_1017 on 127.0.0.1:45304 size 4194304 replicaState = FINALIZED
2020-04-02 05:14:18,666 [IPC Server handler 1 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:41818, datanodeUuid=138c0d7d-7e58-4339-8b75-15c135daf76d, infoPort=42795, infoSecurePort=0, ipcPort=43620, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:14:18,666 [IPC Server handler 9 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38083, datanodeUuid=3d038cc2-f80f-4a72-8c2c-febccfb87908, infoPort=37146, infoSecurePort=0, ipcPort=37392, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:14:18,665 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775536_1017, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50808, dest: /127.0.0.1:34596, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 690f7552-c4c3-4286-845f-64b6525bf551, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775536_1017, duration(ns): 315333685
2020-04-02 05:14:18,665 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775532_1017, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775532_1017, type=LAST_IN_PIPELINE terminating
2020-04-02 05:14:18,665 [IPC Server handler 6 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:14:18,665 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775535_1017, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775535_1017, type=LAST_IN_PIPELINE terminating
2020-04-02 05:14:18,665 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775534_1017, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775534_1017, type=LAST_IN_PIPELINE terminating
2020-04-02 05:14:18,665 [IPC Server handler 8 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:14:18,665 [IPC Server handler 4 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33931, datanodeUuid=04fa600d-9223-4e33-b0a1-d4242966c7f0, infoPort=45217, infoSecurePort=0, ipcPort=38205, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:14:18,665 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775529_1017, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775529_1017, type=LAST_IN_PIPELINE terminating
2020-04-02 05:14:18,665 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775530_1017, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775530_1017, type=LAST_IN_PIPELINE terminating
2020-04-02 05:14:18,667 [IPC Server handler 5 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /deleted_3_0  inodeId 16397 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:14:18,667 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775536_1017, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775536_1017, type=LAST_IN_PIPELINE terminating
2020-04-02 05:14:18,666 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:18,666 [IPC Server handler 3 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45517, datanodeUuid=30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c, infoPort=41207, infoSecurePort=0, ipcPort=44568, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:14:18,668 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45304 is added to blk_-9223372036854775536_1017 (size=0)
2020-04-02 05:14:18,666 [IPC Server handler 2 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34596, datanodeUuid=690f7552-c4c3-4286-845f-64b6525bf551, infoPort=44049, infoSecurePort=0, ipcPort=36235, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:14:18,666 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775533_1017, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775533_1017, type=LAST_IN_PIPELINE terminating
2020-04-02 05:14:18,668 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775531_1017 is received from 127.0.0.1:45304
2020-04-02 05:14:18,669 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45304 receiving: 0, received: 1, deleted: 0
2020-04-02 05:14:18,669 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775534_1017 on 127.0.0.1:33488 size 4194304 replicaState = FINALIZED
2020-04-02 05:14:18,669 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:18,669 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33488 is added to blk_-9223372036854775536_1017 (size=0)
2020-04-02 05:14:18,669 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775534_1017 is received from 127.0.0.1:33488
2020-04-02 05:14:18,669 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33488 receiving: 0, received: 1, deleted: 0
2020-04-02 05:14:18,669 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775532_1017 on 127.0.0.1:41818 size 4194304 replicaState = FINALIZED
2020-04-02 05:14:18,669 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:18,669 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:41818 is added to blk_-9223372036854775536_1017 (size=0)
2020-04-02 05:14:18,669 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775532_1017 is received from 127.0.0.1:41818
2020-04-02 05:14:18,669 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:41818 receiving: 0, received: 1, deleted: 0
2020-04-02 05:14:18,670 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775530_1017 on 127.0.0.1:38083 size 4194304 replicaState = FINALIZED
2020-04-02 05:14:18,670 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:18,670 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38083 is added to blk_-9223372036854775536_1017 (size=0)
2020-04-02 05:14:18,670 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775530_1017 is received from 127.0.0.1:38083
2020-04-02 05:14:18,670 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38083 receiving: 0, received: 1, deleted: 0
2020-04-02 05:14:18,670 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775529_1017 on 127.0.0.1:39776 size 4194304 replicaState = FINALIZED
2020-04-02 05:14:18,670 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:18,670 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39776 is added to blk_-9223372036854775536_1017 (size=0)
2020-04-02 05:14:18,670 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775529_1017 is received from 127.0.0.1:39776
2020-04-02 05:14:18,670 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39776 receiving: 0, received: 1, deleted: 0
2020-04-02 05:14:18,670 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775533_1017 on 127.0.0.1:38003 size 4194304 replicaState = FINALIZED
2020-04-02 05:14:18,670 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:18,670 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38003 is added to blk_-9223372036854775536_1017 (size=0)
2020-04-02 05:14:18,671 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775533_1017 is received from 127.0.0.1:38003
2020-04-02 05:14:18,671 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38003 receiving: 0, received: 1, deleted: 0
2020-04-02 05:14:18,671 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775535_1017 on 127.0.0.1:33931 size 4194304 replicaState = FINALIZED
2020-04-02 05:14:18,671 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:18,671 [IPC Server handler 5 on 41191] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:14:18,671 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33931 is added to blk_-9223372036854775536_1017 (size=0)
2020-04-02 05:14:18,671 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775535_1017 is received from 127.0.0.1:33931
2020-04-02 05:14:18,671 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33931 receiving: 0, received: 1, deleted: 0
2020-04-02 05:14:18,672 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775528_1017 on 127.0.0.1:45517 size 4194304 replicaState = FINALIZED
2020-04-02 05:14:18,672 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:18,672 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45517 is added to blk_-9223372036854775536_1017 (size=0)
2020-04-02 05:14:18,672 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775528_1017 is received from 127.0.0.1:45517
2020-04-02 05:14:18,672 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45517 receiving: 0, received: 1, deleted: 0
2020-04-02 05:14:18,672 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775536_1017 on 127.0.0.1:34596 size 4194304 replicaState = FINALIZED
2020-04-02 05:14:18,672 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:18,672 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34596 is added to blk_-9223372036854775536_1017 (size=0)
2020-04-02 05:14:18,672 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775536_1017 is received from 127.0.0.1:34596
2020-04-02 05:14:18,672 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34596 receiving: 0, received: 1, deleted: 0
2020-04-02 05:14:18,673 [IPC Server handler 5 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /deleted_3_0 with blk_-9223372036854775520_1018 block is added to the in-memory file system
2020-04-02 05:14:18,673 [IPC Server handler 5 on 41191] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775520_1018, replicas=127.0.0.1:38003, 127.0.0.1:45517, 127.0.0.1:33931, 127.0.0.1:41818, 127.0.0.1:45304, 127.0.0.1:33488, 127.0.0.1:39776, 127.0.0.1:34596, 127.0.0.1:38083 for /deleted_3_0
2020-04-02 05:14:18,673 [IPC Server handler 5 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /deleted_3_0 with new block blk_-9223372036854775520_1018, current total block count is 2
2020-04-02 05:14:18,675 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:43580 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018 src: /127.0.0.1:43580 dest: /127.0.0.1:38003
2020-04-02 05:14:18,676 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50646 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775514_1018]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775514_1018 src: /127.0.0.1:50646 dest: /127.0.0.1:39776
2020-04-02 05:14:18,676 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50710 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775512_1018]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775512_1018 src: /127.0.0.1:50710 dest: /127.0.0.1:38083
2020-04-02 05:14:18,676 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:50830 [Receiving block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775513_1018]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775513_1018 src: /127.0.0.1:50830 dest: /127.0.0.1:34596
2020-04-02 05:14:18,684 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43580, dest: /127.0.0.1:38003, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018, duration(ns): 6601221
2020-04-02 05:14:18,684 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018, type=LAST_IN_PIPELINE terminating
2020-04-02 05:14:18,684 [IPC Server handler 7 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:14:18,684 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775520_1018 on 127.0.0.1:38003 size 123 replicaState = FINALIZED
2020-04-02 05:14:18,685 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:18,686 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38003 is added to blk_-9223372036854775520_1018 (size=0)
2020-04-02 05:14:18,686 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775514_1018, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50646, dest: /127.0.0.1:39776, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: ca9828e1-172e-4a2c-a1a8-917b3485899c, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775514_1018, duration(ns): 2988134
2020-04-02 05:14:18,686 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775520_1018 is received from 127.0.0.1:38003
2020-04-02 05:14:18,686 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38003 receiving: 0, received: 1, deleted: 0
2020-04-02 05:14:18,686 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775514_1018, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775514_1018, type=LAST_IN_PIPELINE terminating
2020-04-02 05:14:18,686 [IPC Server handler 0 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39776, datanodeUuid=ca9828e1-172e-4a2c-a1a8-917b3485899c, infoPort=36167, infoSecurePort=0, ipcPort=46492, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:14:18,686 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775514_1018 on 127.0.0.1:39776 size 123 replicaState = FINALIZED
2020-04-02 05:14:18,686 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:18,686 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39776 is added to blk_-9223372036854775520_1018 (size=0)
2020-04-02 05:14:18,687 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775513_1018, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50830, dest: /127.0.0.1:34596, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 690f7552-c4c3-4286-845f-64b6525bf551, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775513_1018, duration(ns): 6015992
2020-04-02 05:14:18,687 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775514_1018 is received from 127.0.0.1:39776
2020-04-02 05:14:18,688 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775513_1018, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775513_1018, type=LAST_IN_PIPELINE terminating
2020-04-02 05:14:18,688 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39776 receiving: 0, received: 1, deleted: 0
2020-04-02 05:14:18,688 [IPC Server handler 1 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34596, datanodeUuid=690f7552-c4c3-4286-845f-64b6525bf551, infoPort=44049, infoSecurePort=0, ipcPort=36235, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:14:18,688 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775513_1018 on 127.0.0.1:34596 size 123 replicaState = FINALIZED
2020-04-02 05:14:18,689 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:18,689 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775512_1018, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50710, dest: /127.0.0.1:38083, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1389971812_1, offset: 0, srvID: 3d038cc2-f80f-4a72-8c2c-febccfb87908, blockid: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775512_1018, duration(ns): 10192070
2020-04-02 05:14:18,689 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34596 is added to blk_-9223372036854775520_1018 (size=0)
2020-04-02 05:14:18,689 [PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775512_1018, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775512_1018, type=LAST_IN_PIPELINE terminating
2020-04-02 05:14:18,689 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775513_1018 is received from 127.0.0.1:34596
2020-04-02 05:14:18,690 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34596 receiving: 0, received: 1, deleted: 0
2020-04-02 05:14:18,691 [IPC Server handler 9 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38083, datanodeUuid=3d038cc2-f80f-4a72-8c2c-febccfb87908, infoPort=37146, infoSecurePort=0, ipcPort=37392, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:14:18,692 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775512_1018 on 127.0.0.1:38083 size 123 replicaState = FINALIZED
2020-04-02 05:14:18,692 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:18,692 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38083 is added to blk_-9223372036854775520_1018 (size=0)
2020-04-02 05:14:18,692 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775512_1018 is received from 127.0.0.1:38083
2020-04-02 05:14:18,692 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38083 receiving: 0, received: 1, deleted: 0
2020-04-02 05:14:18,698 [IPC Server handler 6 on 41191] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /deleted_3_0 for DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:14:18,698 [IPC Server handler 6 on 41191] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /deleted_3_0 with 2 blocks is persisted to the file system
2020-04-02 05:14:18,699 [IPC Server handler 6 on 41191] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /deleted_3_0 is closed by DFSClient_NONMAPREDUCE_-1389971812_1
2020-04-02 05:14:18,700 [Thread-1012] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(231)) - corruptBlocks on path /deleted_3_0
2020-04-02 05:14:18,705 [IPC Server handler 8 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775536_1017, blk_-9223372036854775520_1018]
2020-04-02 05:14:18,705 [IPC Server handler 8 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:14:18,706 [Thread-1012] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(258)) - Deleting block file BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775518_1018
2020-04-02 05:14:18,707 [Thread-1012] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775518_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775518_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:18,707 [Thread-1012] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775518_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775518_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:18,707 [Thread-1012] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775518_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775518_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:18,708 [Thread-1012] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775518_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775518_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:18,708 [Thread-1012] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775518_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775518_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:18,708 [Thread-1012] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775518_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775518_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:18,708 [Thread-1012] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775518_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775518_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:18,709 [Thread-1012] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775518_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775518_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:18,709 [Thread-1012] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775518_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775518_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:18,709 [Thread-1012] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(258)) - Deleting block file BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018
2020-04-02 05:14:18,709 [Thread-1012] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:18,709 [Thread-1012] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:18,710 [Thread-1012] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:18,710 [Thread-1012] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:18,710 [Thread-1012] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:18,710 [Thread-1012] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:deleteData(153)) - Deleting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir1/blk_-9223372036854775520
2020-04-02 05:14:18,711 [Thread-1012] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:18,711 [Thread-1012] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:18,711 [Thread-1012] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:18,711 [Thread-1012] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(258)) - Deleting block file BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775519_1018
2020-04-02 05:14:18,712 [Thread-1012] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775519_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775519_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:18,712 [Thread-1012] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775519_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775519_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:18,712 [Thread-1012] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775519_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775519_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:18,712 [Thread-1012] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775519_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775519_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:18,713 [Thread-1012] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775519_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775519_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:18,713 [Thread-1012] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775519_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775519_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:18,713 [Thread-1012] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775519_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775519_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:18,714 [Thread-1012] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775519_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775519_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:18,714 [Thread-1012] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775519_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775519_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2183)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:259)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:18,714 [Thread-1012] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /deleted_3_0
2020-04-02 05:14:18,722 [Thread-1012] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /deleted_3_0
2020-04-02 05:14:18,722 [IPC Server handler 4 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/deleted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:14:18,723 [Thread-1012] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /deleted_3_0
2020-04-02 05:14:18,724 [IPC Server handler 3 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:14:18,724 [IPC Server handler 2 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775536_1017, blk_-9223372036854775520_1018]
2020-04-02 05:14:18,725 [IPC Server handler 2 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:14:18,739 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:43588 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018]] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775520_1018 replica FinalizedReplica, blk_-9223372036854775520_1018, FINALIZED
  getNumBytes()     = 123
  getBytesOnDisk()  = 123
  getVisibleLength()= 123
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir1/blk_-9223372036854775520 for deletion
2020-04-02 05:14:18,741 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:43588 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018]] INFO  datanode.DataNode (DataXceiver.java:readBlock(598)) - opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018 received exception java.io.FileNotFoundException: BlockId -9223372036854775520 is not valid.
2020-04-02 05:14:18,741 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:43588 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018]] WARN  datanode.DataNode (DataXceiver.java:readBlock(643)) - DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366):Got exception while serving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018 to /127.0.0.1:43588
java.io.FileNotFoundException: BlockId -9223372036854775520 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:14:18,741 [Async disk worker #1 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775520_1018 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir1/blk_-9223372036854775520
2020-04-02 05:14:18,742 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:43588 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018]] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:38003:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:43588 dst: /127.0.0.1:38003
java.io.FileNotFoundException: BlockId -9223372036854775520 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:14:18,744 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:43590 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018]] INFO  datanode.DataNode (DataXceiver.java:readBlock(598)) - opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018
2020-04-02 05:14:18,744 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:43590 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018]] WARN  datanode.DataNode (DataXceiver.java:readBlock(643)) - DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366):Got exception while serving BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018 to /127.0.0.1:43590
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.getReplica(BlockSender.java:492)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:256)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:14:18,744 [Thread-1012] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(764)) - I/O error constructing remote block reader.
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018, for OP_READ_BLOCK, self=/127.0.0.1:43590, remote=/127.0.0.1:38003, for file /deleted_3_0, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775520_1018
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:18,744 [DataXceiver for client DFSClient_NONMAPREDUCE_-1389971812_1 at /127.0.0.1:43590 [Sending block BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018]] ERROR datanode.DataNode (DataXceiver.java:run(321)) - 127.0.0.1:38003:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:43590 dst: /127.0.0.1:38003
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.getReplica(BlockSender.java:492)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:256)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:593)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:14:18,745 [Thread-1012] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(279)) - Failed to connect to /127.0.0.1:38003 for blockBP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica not found for BP-1781155512-172.17.0.11-1585804127366:blk_-9223372036854775520_1018, for OP_READ_BLOCK, self=/127.0.0.1:43590, remote=/127.0.0.1:38003, for file /deleted_3_0, for pool BP-1781155512-172.17.0.11-1585804127366 block -9223372036854775520_1018
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:262)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:298)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:329)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:503)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:142)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:224)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:18,746 [IPC Server handler 5 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775536_1017, blk_-9223372036854775520_1018]
2020-04-02 05:14:18,747 [IPC Server handler 5 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:14:18,748 [Thread-1012] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(526)) - [DatanodeInfoWithStorage[127.0.0.1:38003,DS-cd20bec6-61af-4cee-a017-bfc56735fa58,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-04-02 05:14:20,214 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775552_1016 cannot be reconstructed from any node
2020-04-02 05:14:20,214 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-04-02 05:14:20,214 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:45304 to delete [blk_-9223372036854775709_1006]
2020-04-02 05:14:20,214 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:45517 to delete [blk_-9223372036854775704_1006]
2020-04-02 05:14:20,214 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:33931 to delete [blk_-9223372036854775706_1006]
2020-04-02 05:14:21,098 [IPC Server handler 9 on 41191] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38003, datanodeUuid=fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0, infoPort=37522, infoSecurePort=0, ipcPort=33566, storageInfo=lv=-57;cid=testClusterID;nsid=870746973;c=1585804127366) 1 blocks.
2020-04-02 05:14:21,098 [Block report processor] DEBUG BlockStateChange (BlockManager.java:removeStoredBlock(3781)) - BLOCK* removeStoredBlock: blk_-9223372036854775520_1018 from 127.0.0.1:38003
2020-04-02 05:14:21,099 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775520_1018 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:14:21,099 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775520_1018 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:14:21,099 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block DELETED_BLOCK: blk_-9223372036854775520_1018 is received from 127.0.0.1:38003
2020-04-02 05:14:21,099 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38003 receiving: 0, received: 0, deleted: 1
2020-04-02 05:14:21,280 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775709_1006 replica FinalizedReplica, blk_-9223372036854775709_1006, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775709 for deletion
2020-04-02 05:14:21,282 [Async disk worker #2 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775709_1006 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775709
2020-04-02 05:14:21,303 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775704_1006 replica FinalizedReplica, blk_-9223372036854775704_1006, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775704 for deletion
2020-04-02 05:14:21,316 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775704_1006 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775704
2020-04-02 05:14:22,290 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775706_1006 replica FinalizedReplica, blk_-9223372036854775706_1006, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775706 for deletion
2020-04-02 05:14:22,293 [Async disk worker #1 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775706_1006 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775706
2020-04-02 05:14:23,215 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775552_1016 cannot be reconstructed from any node
2020-04-02 05:14:23,220 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775520_1018 cannot be reconstructed from any node
2020-04-02 05:14:23,220 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:14:23,220 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:41818 to delete [blk_-9223372036854775711_1006]
2020-04-02 05:14:23,220 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:38083 to delete [blk_-9223372036854775708_1006]
2020-04-02 05:14:23,221 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:33488 to delete [blk_-9223372036854775705_1006]
2020-04-02 05:14:24,098 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775711_1006 replica FinalizedReplica, blk_-9223372036854775711_1006, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775711 for deletion
2020-04-02 05:14:24,101 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775711_1006 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775711
2020-04-02 05:14:24,281 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775705_1006 replica FinalizedReplica, blk_-9223372036854775705_1006, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775705 for deletion
2020-04-02 05:14:24,288 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775705_1006 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775705
2020-04-02 05:14:24,985 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775708_1006 replica FinalizedReplica, blk_-9223372036854775708_1006, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775708 for deletion
2020-04-02 05:14:24,991 [Async disk worker #1 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1781155512-172.17.0.11-1585804127366 blk_-9223372036854775708_1006 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1781155512-172.17.0.11-1585804127366/current/finalized/subdir0/subdir0/blk_-9223372036854775708
2020-04-02 05:14:26,221 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775552_1016 cannot be reconstructed from any node
2020-04-02 05:14:26,225 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775520_1018 cannot be reconstructed from any node
2020-04-02 05:14:26,225 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:14:29,226 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775552_1016 cannot be reconstructed from any node
2020-04-02 05:14:29,227 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775520_1018 cannot be reconstructed from any node
2020-04-02 05:14:29,227 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:14:32,228 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775552_1016 cannot be reconstructed from any node
2020-04-02 05:14:32,228 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775520_1018 cannot be reconstructed from any node
2020-04-02 05:14:32,228 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:14:32,360 [Thread-1012] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /deleted_3_0
2020-04-02 05:14:32,369 [IPC Server handler 0 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775536_1017, blk_-9223372036854775520_1018]
2020-04-02 05:14:32,370 [IPC Server handler 0 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:14:35,229 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775552_1016 cannot be reconstructed from any node
2020-04-02 05:14:35,229 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775520_1018 cannot be reconstructed from any node
2020-04-02 05:14:35,229 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:14:36,202 [Thread-1012] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /deleted_3_0
2020-04-02 05:14:36,219 [IPC Server handler 2 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775536_1017, blk_-9223372036854775520_1018]
2020-04-02 05:14:36,225 [IPC Server handler 2 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:14:38,230 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775552_1016 cannot be reconstructed from any node
2020-04-02 05:14:38,231 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775520_1018 cannot be reconstructed from any node
2020-04-02 05:14:38,231 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:14:39,829 [Thread-1012] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /deleted_3_0
2020-04-02 05:14:39,831 [IPC Server handler 6 on 41191] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775536_1017, blk_-9223372036854775520_1018]
2020-04-02 05:14:39,832 [IPC Server handler 6 on 41191] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:14:41,232 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775552_1016 cannot be reconstructed from any node
2020-04-02 05:14:41,232 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775520_1018 cannot be reconstructed from any node
2020-04-02 05:14:41,233 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:14:44,233 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775552_1016 cannot be reconstructed from any node
2020-04-02 05:14:44,234 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775520_1018 cannot be reconstructed from any node
2020-04-02 05:14:44,234 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[11]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[11]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:14:44,793 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:14:44,800 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 8
2020-04-02 05:14:44,800 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 38205 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:14:44,801 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:14:44,802 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7e0aadd0] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:14:44,803 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-653a74b1-1e06-48c8-9fc4-adfe2a024aaf) exiting.
2020-04-02 05:14:44,803 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-3f8ec3d4-2938-4c87-90b2-6481f726aa28) exiting.
2020-04-02 05:14:44,840 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@22c01ab0{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:14:44,847 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@411341bd{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:14:44,847 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@71a9b4c7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:14:44,848 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1494b84d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:14:44,851 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38205
2020-04-02 05:14:44,861 [IPC Server listener on 38205] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38205
2020-04-02 05:14:44,865 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:14:44,869 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:14:44,869 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid 04fa600d-9223-4e33-b0a1-d4242966c7f0) service to localhost/127.0.0.1:41191
2020-04-02 05:14:44,870 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid 04fa600d-9223-4e33-b0a1-d4242966c7f0)
2020-04-02 05:14:44,870 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:14:44,884 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1781155512-172.17.0.11-1585804127366] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:44,892 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1781155512-172.17.0.11-1585804127366] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:44,897 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:14:44,897 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:14:44,899 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:14:44,899 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:14:44,902 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:14:44,902 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 7
2020-04-02 05:14:44,903 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 37392 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:14:44,903 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:14:44,903 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5aabbb29] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:14:44,904 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-94f6e665-b2d5-46c4-969f-c9b2db0add83) exiting.
2020-04-02 05:14:44,904 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-f29fcc8c-4f45-47a4-addd-01231a8988bd) exiting.
2020-04-02 05:14:44,938 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@514eedd8{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:14:44,939 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@617fe9e1{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:14:44,939 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@16fb356{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:14:44,940 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5003041b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:14:44,940 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37392
2020-04-02 05:14:44,945 [IPC Server listener on 37392] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37392
2020-04-02 05:14:44,947 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:14:44,948 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:14:44,960 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid 3d038cc2-f80f-4a72-8c2c-febccfb87908) service to localhost/127.0.0.1:41191
2020-04-02 05:14:44,966 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid 3d038cc2-f80f-4a72-8c2c-febccfb87908)
2020-04-02 05:14:44,972 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:14:44,984 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1781155512-172.17.0.11-1585804127366] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:44,995 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1781155512-172.17.0.11-1585804127366] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:44,998 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:14:44,998 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:14:44,999 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:14:45,000 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:14:45,003 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:14:45,003 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 6
2020-04-02 05:14:45,003 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 45067 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:14:45,004 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:14:45,004 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@459f7aa3] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:14:45,006 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-52fa7b3d-3f2c-4afb-8e3c-b713e4545d8d) exiting.
2020-04-02 05:14:45,006 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-57d3a558-2677-4860-b211-26930cea2ac4) exiting.
2020-04-02 05:14:45,034 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6e57e95e{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:14:45,035 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2755d705{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:14:45,035 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7e70bd39{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:14:45,035 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2f4854d6{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:14:45,037 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 45067
2020-04-02 05:14:45,040 [IPC Server listener on 45067] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 45067
2020-04-02 05:14:45,044 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:14:45,048 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid 31f7c920-c39d-4ae7-b315-1227a3caafd0) service to localhost/127.0.0.1:41191
2020-04-02 05:14:45,048 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:14:45,049 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid 31f7c920-c39d-4ae7-b315-1227a3caafd0)
2020-04-02 05:14:45,049 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:14:45,060 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1781155512-172.17.0.11-1585804127366] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:45,071 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1781155512-172.17.0.11-1585804127366] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:45,076 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:14:45,076 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:14:45,078 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:14:45,078 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:14:45,081 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:14:45,081 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 5
2020-04-02 05:14:45,081 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 33566 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:14:45,082 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:14:45,082 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@21694e53] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:14:45,084 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-8ed92d4e-a113-43e3-89fc-e65f907cbe5e) exiting.
2020-04-02 05:14:45,084 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-cd20bec6-61af-4cee-a017-bfc56735fa58) exiting.
2020-04-02 05:14:45,101 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0) service to localhost/127.0.0.1:41191
2020-04-02 05:14:45,101 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid fbeeb0c1-9c8e-419c-bfbe-a866c4ce83e0)
2020-04-02 05:14:45,101 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:14:45,107 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6cea706c{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:14:45,108 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3bd7f8dc{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:14:45,108 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@759fad4{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:14:45,109 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@26be6ca7{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:14:45,110 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33566
2020-04-02 05:14:45,118 [IPC Server listener on 33566] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33566
2020-04-02 05:14:45,131 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:14:45,131 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:14:45,131 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:14:45,133 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:14:45,134 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:14:45,136 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1781155512-172.17.0.11-1585804127366] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:45,149 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1781155512-172.17.0.11-1585804127366] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:45,158 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:14:45,158 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 4
2020-04-02 05:14:45,158 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 43620 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:14:45,158 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:14:45,158 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@62923ee6] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:14:45,161 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-d9137667-94c0-4dee-b215-ab45ce9137b2) exiting.
2020-04-02 05:14:45,161 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-c5dfe81d-cd58-425d-bfae-86f08d014c3b) exiting.
2020-04-02 05:14:45,182 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@66ea1466{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:14:45,182 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1601e47{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:14:45,183 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@a1217f9{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:14:45,183 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4fd4cae3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:14:45,184 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43620
2020-04-02 05:14:45,194 [IPC Server listener on 43620] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43620
2020-04-02 05:14:45,198 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:14:45,198 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid 138c0d7d-7e58-4339-8b75-15c135daf76d) service to localhost/127.0.0.1:41191
2020-04-02 05:14:45,198 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:14:45,198 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid 138c0d7d-7e58-4339-8b75-15c135daf76d)
2020-04-02 05:14:45,198 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:14:45,209 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1781155512-172.17.0.11-1585804127366] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:45,219 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1781155512-172.17.0.11-1585804127366] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:45,227 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:14:45,227 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:14:45,229 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:14:45,231 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:14:45,238 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:14:45,238 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 3
2020-04-02 05:14:45,238 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 44568 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:14:45,238 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:14:45,238 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4a3e3e8b] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:14:45,241 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-a691264e-7ef4-4189-b9ec-6f397eff2bb2) exiting.
2020-04-02 05:14:45,241 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-bd9fc205-c45f-48b9-85ed-311ae68dcf33) exiting.
2020-04-02 05:14:45,269 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@192f2f27{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:14:45,269 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@8a589a2{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:14:45,270 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@32232e55{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:14:45,270 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@549621f3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:14:45,271 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 44568
2020-04-02 05:14:45,277 [IPC Server listener on 44568] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 44568
2020-04-02 05:14:45,278 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:14:45,282 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:14:45,282 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid 30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c) service to localhost/127.0.0.1:41191
2020-04-02 05:14:45,282 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid 30e90dfe-1a60-498d-8cb5-4dfd8fcf4c0c)
2020-04-02 05:14:45,282 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:14:45,295 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1781155512-172.17.0.11-1585804127366] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:45,309 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1781155512-172.17.0.11-1585804127366] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:45,334 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:14:45,334 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:14:45,336 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:14:45,336 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:14:45,340 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:14:45,341 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:14:45,341 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 46631 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:14:45,341 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:14:45,341 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3af17be2] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:14:45,343 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-473eb806-1eb7-4944-8753-5f4b73aff970) exiting.
2020-04-02 05:14:45,344 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-74648b74-08f4-4ca5-a128-e9784b6b21d8) exiting.
2020-04-02 05:14:45,370 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2f94c4db{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:14:45,370 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@593e824f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:14:45,371 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1d9bec4d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:14:45,371 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4ef27d66{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:14:45,373 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 46631
2020-04-02 05:14:45,385 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:14:45,385 [IPC Server listener on 46631] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 46631
2020-04-02 05:14:45,385 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:14:45,385 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid f1177179-f009-4517-a835-ba14c97e85ff) service to localhost/127.0.0.1:41191
2020-04-02 05:14:45,389 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid f1177179-f009-4517-a835-ba14c97e85ff)
2020-04-02 05:14:45,390 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:14:45,401 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1781155512-172.17.0.11-1585804127366] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:45,408 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1781155512-172.17.0.11-1585804127366] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:45,415 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:14:45,415 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:14:45,419 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:14:45,419 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:14:45,426 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:14:45,427 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:14:45,427 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 46492 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:14:45,427 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:14:45,427 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@71e5f61d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:14:45,432 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-0a0c2452-7424-4ea5-a7af-8c6055bbad34) exiting.
2020-04-02 05:14:45,432 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-c37ee172-cb9b-4f05-84aa-bcebbe58c663) exiting.
2020-04-02 05:14:45,455 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2cf23c81{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:14:45,456 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3624da92{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:14:45,456 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@60fa3495{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:14:45,456 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6a62689d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:14:45,457 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 46492
2020-04-02 05:14:45,471 [IPC Server listener on 46492] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 46492
2020-04-02 05:14:45,475 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:14:45,475 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:14:45,475 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid ca9828e1-172e-4a2c-a1a8-917b3485899c) service to localhost/127.0.0.1:41191
2020-04-02 05:14:45,475 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid ca9828e1-172e-4a2c-a1a8-917b3485899c)
2020-04-02 05:14:45,475 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:14:45,487 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1781155512-172.17.0.11-1585804127366] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:45,495 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1781155512-172.17.0.11-1585804127366] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:45,503 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:14:45,503 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:14:45,508 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:14:45,508 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:14:45,516 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:14:45,517 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:14:45,517 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 36235 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:14:45,517 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:14:45,517 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@655f7ea] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:14:45,521 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-2078a8cc-9828-4e10-96be-f8b4239ff4fe) exiting.
2020-04-02 05:14:45,521 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-244b1c01-4b44-4923-8631-0dc549a7ddde) exiting.
2020-04-02 05:14:45,544 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5dd91bca{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:14:45,545 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@409b1aa0{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:14:45,545 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@68b6f0d6{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:14:45,546 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@686449f9{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:14:45,547 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36235
2020-04-02 05:14:45,558 [IPC Server listener on 36235] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36235
2020-04-02 05:14:45,559 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:14:45,559 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:14:45,564 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid 690f7552-c4c3-4286-845f-64b6525bf551) service to localhost/127.0.0.1:41191
2020-04-02 05:14:45,665 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1781155512-172.17.0.11-1585804127366 (Datanode Uuid 690f7552-c4c3-4286-845f-64b6525bf551)
2020-04-02 05:14:45,669 [BP-1781155512-172.17.0.11-1585804127366 heartbeating to localhost/127.0.0.1:41191] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1781155512-172.17.0.11-1585804127366
2020-04-02 05:14:45,681 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1781155512-172.17.0.11-1585804127366] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:45,712 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1781155512-172.17.0.11-1585804127366] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:45,718 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:14:45,719 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:14:45,724 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:14:45,724 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:14:45,733 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:14:45,733 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:14:45,733 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 41191 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:14:45,733 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:14:45,734 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 87
2020-04-02 05:14:45,734 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@555cf22] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:14:45,735 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@58ffcbd7] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:14:45,735 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 88 Total time for transactions(ms): 49 Number of transactions batched in Syncs: 16 Number of syncs: 73 SyncTimes(ms): 1 1 
2020-04-02 05:14:45,737 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000088
2020-04-02 05:14:45,738 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000088
2020-04-02 05:14:45,739 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:14:45,739 [CacheReplicationMonitor(115943867)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:14:45,740 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41191
2020-04-02 05:14:45,744 [IPC Server listener on 41191] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41191
2020-04-02 05:14:45,751 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:14:45,751 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:14:45,751 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:14:45,752 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@7e7b159b] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:run(248)) - PendingReconstructionMonitor thread is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:14:45,803 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:14:45,804 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:14:45,805 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@797b0699{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:14:45,806 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4f704591{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:14:45,806 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4f49f6af{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:14:45,807 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7d322cad{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:14:45,809 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:14:45,832 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:14:45,833 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] all testRunFinished

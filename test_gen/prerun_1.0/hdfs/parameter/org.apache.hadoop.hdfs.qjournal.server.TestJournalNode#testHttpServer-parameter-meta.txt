adl.feature.ownerandgroup.enableupn unit_test false get
adl.http.timeout unit_test -1 get
bind.address hdfs:JournalNode.1 null get
datanode.https.port unit_test 50475 get
dfs.balancer.address unit_test 0.0.0.0:0 get
dfs.balancer.block-move.timeout unit_test 0 get
dfs.balancer.dispatcherThreads unit_test 200 get
dfs.balancer.getBlocks.min-block-size unit_test 10485760 get
dfs.balancer.getBlocks.size unit_test 2147483648 get
dfs.balancer.keytab.enabled unit_test false get
dfs.balancer.max-iteration-time unit_test 1200000 get
dfs.balancer.max-no-move-interval unit_test 60000 get
dfs.balancer.max-size-to-move unit_test 10737418240 get
dfs.balancer.movedWinWidth unit_test 5400000 get
dfs.balancer.moverThreads unit_test 1000 get
dfs.block.access.key.update.interval unit_test 600 get
dfs.block.access.token.enable unit_test false get
dfs.block.access.token.lifetime unit_test 600 get
dfs.block.access.token.protobuf.enable unit_test false get
dfs.block.invalidate.limit unit_test 1000 get
dfs.block.misreplication.processing.limit unit_test 10000 get
dfs.block.placement.ec.classname unit_test org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant get
dfs.block.replicator.classname unit_test org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault get
dfs.block.scanner.volume.bytes.per.second unit_test 1048576 get
dfs.blockreport.incremental.intervalMsec unit_test 0 get
dfs.blockreport.initialDelay unit_test 0s get
dfs.blockreport.intervalMsec unit_test 21600000 get
dfs.blockreport.split.threshold unit_test 1000000 get
dfs.blocksize unit_test 134217728 get
dfs.bytes-per-checksum unit_test 512 get
dfs.cachereport.intervalMsec unit_test 10000 get
dfs.checksum.combine.mode unit_test MD5MD5CRC get
dfs.checksum.type unit_test CRC32C get
dfs.client-write-packet-size unit_test 65536 get
dfs.client.block.write.locateFollowingBlock.initial.delay.ms unit_test 400 get
dfs.client.block.write.locateFollowingBlock.retries unit_test 5 get
dfs.client.block.write.replace-datanode-on-failure.best-effort unit_test false get
dfs.client.block.write.replace-datanode-on-failure.enable unit_test true get
dfs.client.block.write.replace-datanode-on-failure.min-replication unit_test 0 get
dfs.client.block.write.replace-datanode-on-failure.policy unit_test DEFAULT get
dfs.client.block.write.retries unit_test 3 get
dfs.client.cached.conn.retry unit_test 3 get
dfs.client.context unit_test default get
dfs.client.datanode-restart.timeout unit_test 30s get
dfs.client.domain.socket.data.traffic unit_test false get
dfs.client.failover.connection.retries unit_test 0 get
dfs.client.failover.connection.retries.on.timeouts unit_test 0 get
dfs.client.failover.max.attempts unit_test 15 get
dfs.client.failover.random.order unit_test false get
dfs.client.failover.sleep.base.millis unit_test 500 get
dfs.client.failover.sleep.max.millis unit_test 15000 get
dfs.client.hedged.read.threadpool.size unit_test 0 get
dfs.client.hedged.read.threshold.millis unit_test 500 get
dfs.client.https.keystore.resource unit_test ssl-client.xml get
dfs.client.https.need-auth unit_test false get
dfs.client.key.provider.cache.expiry unit_test 864000000 get
dfs.client.max.block.acquire.failures unit_test 3 get
dfs.client.mmap.cache.size unit_test 256 get
dfs.client.mmap.cache.timeout.ms unit_test 3600000 get
dfs.client.mmap.enabled unit_test true get
dfs.client.mmap.retry.timeout.ms unit_test 300000 get
dfs.client.read.short.circuit.replica.stale.threshold.ms unit_test 1800000 get
dfs.client.read.shortcircuit unit_test false get
dfs.client.read.shortcircuit.buffer.size unit_test 1048576 get
dfs.client.read.shortcircuit.skip.checksum unit_test false get
dfs.client.read.shortcircuit.streams.cache.expiry.ms unit_test 300000 get
dfs.client.read.shortcircuit.streams.cache.size unit_test 256 get
dfs.client.read.striped.threadpool.size unit_test 18 get
dfs.client.retry.interval-ms.get-last-block-length unit_test 4000 get
dfs.client.retry.max.attempts unit_test 10 get
dfs.client.retry.policy.enabled unit_test false get
dfs.client.retry.policy.spec unit_test 10000,6,60000,10 get
dfs.client.retry.times.get-last-block-length unit_test 3 get
dfs.client.retry.window.base unit_test 3000 get
dfs.client.server-defaults.validity.period.ms unit_test 3600000 get
dfs.client.short.circuit.replica.stale.threshold.ms unit_test 1800000 get
dfs.client.slow.io.warning.threshold.ms unit_test 30000 get
dfs.client.socket-timeout unit_test 60000 get
dfs.client.socket.send.buffer.size unit_test 0 get
dfs.client.socketcache.capacity unit_test 16 get
dfs.client.socketcache.expiryMsec unit_test 3000 get
dfs.client.test.drop.namenode.response.number unit_test 0 get
dfs.client.use.datanode.hostname unit_test false get
dfs.client.use.legacy.blockreader.local unit_test false get
dfs.client.write.byte-array-manager.count-limit unit_test 2048 get
dfs.client.write.byte-array-manager.count-reset-time-period-ms unit_test 10000 get
dfs.client.write.byte-array-manager.count-threshold unit_test 128 get
dfs.client.write.byte-array-manager.enabled unit_test false get
dfs.client.write.exclude.nodes.cache.expiry.interval.millis unit_test 600000 get
dfs.client.write.max-packets-in-flight unit_test 80 get
dfs.cluster.administrators hdfs:JournalNode.1   get
dfs.content-summary.limit unit_test 5000 get
dfs.content-summary.sleep-microsec unit_test 500 get
dfs.data.transfer.client.tcpnodelay unit_test true get
dfs.data.transfer.server.tcpnodelay unit_test true get
dfs.datanode.address unit_test 0.0.0.0:9866 get
dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction unit_test 0.75f get
dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold unit_test 10737418240 get
dfs.datanode.balance.bandwidthPerSec unit_test 10m get
dfs.datanode.balance.max.concurrent.moves unit_test 50 get
dfs.datanode.block-pinning.enabled unit_test false get
dfs.datanode.block.id.layout.upgrade.threads unit_test 12 get
dfs.datanode.bp-ready.timeout unit_test 20s get
dfs.datanode.cache.revocation.polling.ms unit_test 500 get
dfs.datanode.cache.revocation.timeout.ms unit_test 900000 get
dfs.datanode.cached-dfsused.check.interval.ms unit_test 600000 get
dfs.datanode.data.dir unit_test file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/tmp/dfs/data get
dfs.datanode.data.dir.perm unit_test 700 get
dfs.datanode.directoryscan.interval unit_test 21600s get
dfs.datanode.directoryscan.threads unit_test 1 get
dfs.datanode.directoryscan.throttle.limit.ms.per.sec unit_test 1000 get
dfs.datanode.disk.check.min.gap unit_test 15m get
dfs.datanode.disk.check.timeout unit_test 10m get
dfs.datanode.dns.interface unit_test default get
dfs.datanode.dns.nameserver unit_test default get
dfs.datanode.drop.cache.behind.reads unit_test false get
dfs.datanode.drop.cache.behind.writes unit_test false get
dfs.datanode.du.reserved unit_test 0 get
dfs.datanode.du.reserved.calculator unit_test org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.ReservedSpaceCalculator$ReservedSpaceCalculatorAbsolute get
dfs.datanode.du.reserved.pct unit_test 0 get
dfs.datanode.ec.reconstruction.stripedread.buffer.size unit_test 65536 get
dfs.datanode.ec.reconstruction.stripedread.timeout.millis unit_test 5000 get
dfs.datanode.ec.reconstruction.threads unit_test 8 get
dfs.datanode.ec.reconstruction.xmits.weight unit_test 0.5 get
dfs.datanode.failed.volumes.tolerated unit_test 0 get
dfs.datanode.fileio.profiling.sampling.percentage unit_test 0 get
dfs.datanode.fsdatasetcache.max.threads.per.volume unit_test 4 get
dfs.datanode.handler.count unit_test 10 get
dfs.datanode.http.address unit_test 0.0.0.0:9864 get
dfs.datanode.http.internal-proxy.port unit_test 0 get
dfs.datanode.https.address unit_test 0.0.0.0:9865 get
dfs.datanode.ipc.address unit_test 0.0.0.0:9867 get
dfs.datanode.lazywriter.interval.sec unit_test 60 get
dfs.datanode.max.locked.memory unit_test 0 get
dfs.datanode.max.transfer.threads unit_test 4096 get
dfs.datanode.metrics.logger.period.seconds unit_test 600 get
dfs.datanode.network.counts.cache.max.size unit_test 2147483647 get
dfs.datanode.oob.timeout-ms unit_test 1500,0,0,0 get
dfs.datanode.outliers.report.interval unit_test 30m get
dfs.datanode.peer.metrics.min.outlier.detection.samples unit_test 1000 get
dfs.datanode.peer.stats.enabled unit_test false get
dfs.datanode.readahead.bytes unit_test 4194304 get
dfs.datanode.restart.replica.expiration unit_test 50 get
dfs.datanode.scan.period.hours unit_test 504 get
dfs.datanode.shared.file.descriptor.paths unit_test /dev/shm,/tmp get
dfs.datanode.slow.io.warning.threshold.ms unit_test 300 get
dfs.datanode.socket.reuse.keepalive unit_test 4000 get
dfs.datanode.socket.write.timeout unit_test 480000 get
dfs.datanode.sync.behind.writes unit_test false get
dfs.datanode.sync.behind.writes.in.background unit_test false get
dfs.datanode.transfer.socket.recv.buffer.size unit_test 0 get
dfs.datanode.transfer.socket.send.buffer.size unit_test 0 get
dfs.datanode.transferTo.allowed unit_test true get
dfs.datanode.use.datanode.hostname unit_test false get
dfs.default.chunk.view.size unit_test 32768 get
dfs.disk.balancer.block.tolerance.percent unit_test 10 get
dfs.disk.balancer.enabled unit_test true get
dfs.disk.balancer.max.disk.errors unit_test 5 get
dfs.disk.balancer.max.disk.throughputInMBperSec unit_test 10 get
dfs.disk.balancer.plan.threshold.percent unit_test 10 get
dfs.disk.balancer.plan.valid.interval unit_test 1d get
dfs.domain.socket.disable.interval.seconds unit_test 600 get
dfs.edit.log.transfer.bandwidthPerSec hdfs:JournalNode.1 0 getLong
dfs.edit.log.transfer.bandwidthPerSec unit_test 0 get
dfs.edit.log.transfer.timeout hdfs:JournalNode.1 30000 getInt
dfs.edit.log.transfer.timeout unit_test 30000 get
dfs.encrypt.data.overwrite.downstream.derived.qop unit_test false get
dfs.encrypt.data.transfer unit_test false get
dfs.encrypt.data.transfer.cipher.key.bitlength unit_test 128 get
dfs.ha.automatic-failover.enabled unit_test false get
dfs.ha.fencing.ssh.connect-timeout unit_test 30000 get
dfs.ha.log-roll.period unit_test 120s get
dfs.ha.standby.checkpoints unit_test true get
dfs.ha.tail-edits.in-progress hdfs:JournalNode.1 false getBoolean
dfs.ha.tail-edits.in-progress unit_test false get
dfs.ha.tail-edits.namenode-retries unit_test 3 get
dfs.ha.tail-edits.period unit_test 60s get
dfs.ha.tail-edits.period.backoff-max unit_test 0 get
dfs.ha.tail-edits.rolledits.timeout unit_test 60 get
dfs.ha.zkfc.nn.http.timeout.ms unit_test 20000 get
dfs.ha.zkfc.port unit_test 8019 get
dfs.heartbeat.interval unit_test 3s get
dfs.http.client.failover.max.attempts unit_test 15 get
dfs.http.client.failover.sleep.base.millis unit_test 500 get
dfs.http.client.failover.sleep.max.millis unit_test 15000 get
dfs.http.client.retry.max.attempts unit_test 10 get
dfs.http.client.retry.policy.enabled unit_test false get
dfs.http.client.retry.policy.spec unit_test 10000,6,60000,10 get
dfs.http.policy hdfs:JournalNode.1 HTTP_ONLY get
dfs.http.policy unit_test HTTP_ONLY get
dfs.https.server.keystore.resource unit_test ssl-server.xml get
dfs.image.compress unit_test false get
dfs.image.compression.codec unit_test org.apache.hadoop.io.compress.DefaultCodec get
dfs.image.transfer-bootstrap-standby.bandwidthPerSec unit_test 0 get
dfs.image.transfer.bandwidthPerSec hdfs:JournalNode.1 0 getLong
dfs.image.transfer.bandwidthPerSec unit_test 0 get
dfs.image.transfer.chunksize unit_test 65536 get
dfs.image.transfer.timeout unit_test 60000 get
dfs.internal.nameservices hdfs:JournalNode.1 [] getTrimmedStringCollection
dfs.journalnode.edit-cache-size.bytes unit_test 1048576 get
dfs.journalnode.edits.dir hdfs:JournalNode.1 /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/TestJournalNode get
dfs.journalnode.edits.dir unit_test /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/TestJournalNode get
dfs.journalnode.edits.dir.perm hdfs:JournalNode.1 700 get
dfs.journalnode.edits.dir.perm unit_test 700 get
dfs.journalnode.enable.sync hdfs:JournalNode.1 true getBoolean
dfs.journalnode.enable.sync unit_test true get
dfs.journalnode.http-address hdfs:JournalNode.1 0.0.0.0:8480 get
dfs.journalnode.http-address unit_test 0.0.0.0:8480 get
dfs.journalnode.http-bind-host hdfs:JournalNode.1 null getTrimmed
dfs.journalnode.https-address hdfs:JournalNode.1 0.0.0.0:8481 get
dfs.journalnode.https-address unit_test 0.0.0.0:8481 get
dfs.journalnode.https-bind-host hdfs:JournalNode.1 null getTrimmed
dfs.journalnode.rpc-address hdfs:JournalNode.1 0.0.0.0:0 get
dfs.journalnode.rpc-address unit_test 0.0.0.0:0 get
dfs.journalnode.rpc-bind-host hdfs:JournalNode.1 null getTrimmed
dfs.journalnode.sync.interval hdfs:JournalNode.1 120000 getLong
dfs.journalnode.sync.interval unit_test 120000 get
dfs.lock.suppress.warning.interval unit_test 10s get
dfs.ls.limit unit_test 1000 get
dfs.metrics.percentiles.intervals unit_test [I@6af9fcb2 getInts
dfs.metrics.session-id hdfs:JournalNode.1 null get
dfs.mover.address unit_test 0.0.0.0:0 get
dfs.mover.keytab.enabled unit_test false get
dfs.mover.max-no-move-interval unit_test 60000 get
dfs.mover.movedWinWidth unit_test 5400000 get
dfs.mover.moverThreads unit_test 1000 get
dfs.mover.retry.max.attempts unit_test 10 get
dfs.namenode.accesstime.precision unit_test 3600000 get
dfs.namenode.acls.enabled unit_test false get
dfs.namenode.audit.log.async unit_test false get
dfs.namenode.audit.log.token.tracking.id unit_test false get
dfs.namenode.audit.loggers unit_test default get
dfs.namenode.available-space-block-placement-policy.balanced-space-preference-fraction unit_test 0.6 get
dfs.namenode.avoid.read.stale.datanode unit_test false get
dfs.namenode.avoid.write.stale.datanode unit_test false get
dfs.namenode.backup.address unit_test 0.0.0.0:50100 get
dfs.namenode.backup.http-address unit_test 0.0.0.0:50105 get
dfs.namenode.block-placement-policy.default.prefer-local-node unit_test true get
dfs.namenode.block.deletion.increment unit_test 1000 get
dfs.namenode.blockreport.queue.size unit_test 1024 get
dfs.namenode.blocks.per.postponedblocks.rescan unit_test 10000 get
dfs.namenode.caching.enabled unit_test true get
dfs.namenode.checkpoint.check.period unit_test 60s get
dfs.namenode.checkpoint.check.quiet-multiplier unit_test 1.5 get
dfs.namenode.checkpoint.dir unit_test file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/tmp/dfs/namesecondary get
dfs.namenode.checkpoint.edits.dir unit_test file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/tmp/dfs/namesecondary get
dfs.namenode.checkpoint.max-retries unit_test 3 get
dfs.namenode.checkpoint.period unit_test 3600s get
dfs.namenode.checkpoint.txns unit_test 1000000 get
dfs.namenode.datanode.registration.ip-hostname-check unit_test true get
dfs.namenode.decommission.blocks.per.interval unit_test 500000 get
dfs.namenode.decommission.interval unit_test 30s get
dfs.namenode.decommission.max.concurrent.tracked.nodes unit_test 100 get
dfs.namenode.delegation.key.update-interval unit_test 86400000 get
dfs.namenode.delegation.token.always-use unit_test false get
dfs.namenode.delegation.token.max-lifetime unit_test 604800000 get
dfs.namenode.delegation.token.renew-interval unit_test 86400000 get
dfs.namenode.ec.policies.max.cellsize unit_test 4194304 get
dfs.namenode.ec.system.default.policy unit_test RS-6-3-1024k get
dfs.namenode.edekcacheloader.initial.delay.ms unit_test 3000 get
dfs.namenode.edekcacheloader.interval.ms unit_test 1000 get
dfs.namenode.edit.log.autoroll.check.interval.ms unit_test 300000 get
dfs.namenode.edit.log.autoroll.multiplier.threshold unit_test 0.5 get
dfs.namenode.edits.asynclogging unit_test true get
dfs.namenode.edits.dir unit_test file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/tmp/dfs/name get
dfs.namenode.edits.dir.minimum unit_test 1 get
dfs.namenode.edits.journal-plugin.qjournal unit_test org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager get
dfs.namenode.edits.noeditlogchannelflush hdfs:JournalNode.1 false getBoolean
dfs.namenode.edits.noeditlogchannelflush unit_test false get
dfs.namenode.enable.retrycache unit_test true get
dfs.namenode.file.close.num-committed-allowed unit_test 0 get
dfs.namenode.fs-limits.max-blocks-per-file unit_test 10000 get
dfs.namenode.fs-limits.max-component-length unit_test 255 get
dfs.namenode.fs-limits.max-directory-items unit_test 1048576 get
dfs.namenode.fs-limits.max-xattr-size unit_test 16384 get
dfs.namenode.fs-limits.max-xattrs-per-inode unit_test 32 get
dfs.namenode.fs-limits.min-block-size unit_test 0 get
dfs.namenode.fslock.fair unit_test true get
dfs.namenode.full.block.report.lease.length.ms unit_test 300000 get
dfs.namenode.handler.count unit_test 10 get
dfs.namenode.heartbeat.recheck-interval unit_test 300000 get
dfs.namenode.hosts.provider.classname unit_test org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager get
dfs.namenode.http-address unit_test 0.0.0.0:9870 get
dfs.namenode.https-address unit_test 0.0.0.0:9871 get
dfs.namenode.inotify.max.events.per.rpc unit_test 1000 get
dfs.namenode.invalidate.work.pct.per.iteration unit_test 0.32f get
dfs.namenode.kerberos.internal.spnego.principal unit_test ${dfs.web.authentication.kerberos.principal} get
dfs.namenode.kerberos.principal.pattern unit_test * get
dfs.namenode.lazypersist.file.scrub.interval.sec unit_test 300 get
dfs.namenode.lease-recheck-interval-ms unit_test 2000 get
dfs.namenode.lifeline.handler.ratio unit_test 0.10 get
dfs.namenode.list.cache.directives.num.responses unit_test 100 get
dfs.namenode.list.cache.pools.num.responses unit_test 100 get
dfs.namenode.list.encryption.zones.num.responses unit_test 100 get
dfs.namenode.list.openfiles.num.responses unit_test 1000 get
dfs.namenode.list.reencryption.status.num.responses unit_test 100 get
dfs.namenode.lock.detailed-metrics.enabled unit_test false get
dfs.namenode.maintenance.replication.min unit_test 1 get
dfs.namenode.max-corrupt-file-blocks-returned unit_test 100 get
dfs.namenode.max-lock-hold-to-release-lease-ms unit_test 25 get
dfs.namenode.max-num-blocks-to-log unit_test 1000 get
dfs.namenode.max.extra.edits.segments.retained unit_test 10000 get
dfs.namenode.max.full.block.report.leases unit_test 6 get
dfs.namenode.max.objects unit_test 0 get
dfs.namenode.max.op.size unit_test 52428800 get
dfs.namenode.metrics.logger.period.seconds unit_test 600 get
dfs.namenode.missing.checkpoint.periods.before.shutdown unit_test 3 get
dfs.namenode.name.cache.threshold unit_test 10 get
dfs.namenode.name.dir unit_test file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/tmp/dfs/name get
dfs.namenode.name.dir.restore unit_test false get
dfs.namenode.num.checkpoints.retained unit_test 2 get
dfs.namenode.num.extra.edits.retained unit_test 1000000 get
dfs.namenode.path.based.cache.block.map.allocation.percent unit_test 0.25 get
dfs.namenode.path.based.cache.refresh.interval.ms unit_test 30000 get
dfs.namenode.path.based.cache.retry.interval.ms unit_test 30000 get
dfs.namenode.posix.acl.inheritance.enabled unit_test true get
dfs.namenode.provided.enabled unit_test false get
dfs.namenode.quota.init-threads unit_test 4 get
dfs.namenode.read-lock-reporting-threshold-ms unit_test 5000 get
dfs.namenode.reconstruction.pending.timeout-sec unit_test 300 get
dfs.namenode.redundancy.considerLoad unit_test true get
dfs.namenode.redundancy.considerLoad.factor unit_test 2.0 get
dfs.namenode.redundancy.interval.seconds unit_test 3s get
dfs.namenode.reencrypt.batch.size unit_test 1000 get
dfs.namenode.reencrypt.edek.threads unit_test 10 get
dfs.namenode.reencrypt.sleep.interval unit_test 1m get
dfs.namenode.reencrypt.throttle.limit.handler.ratio unit_test 1.0 get
dfs.namenode.reencrypt.throttle.limit.updater.ratio unit_test 1.0 get
dfs.namenode.reject-unresolved-dn-topology-mapping unit_test false get
dfs.namenode.replication.max-streams unit_test 2 get
dfs.namenode.replication.max-streams-hard-limit unit_test 4 get
dfs.namenode.replication.min unit_test 1 get
dfs.namenode.replication.work.multiplier.per.iteration unit_test 2 get
dfs.namenode.resource.check.interval unit_test 5000 get
dfs.namenode.resource.checked.volumes.minimum unit_test 1 get
dfs.namenode.resource.du.reserved unit_test 104857600 get
dfs.namenode.retrycache.expirytime.millis unit_test 600000 get
dfs.namenode.retrycache.heap.percent unit_test 0.03f get
dfs.namenode.safemode.extension unit_test 30000 get
dfs.namenode.safemode.min.datanodes unit_test 0 get
dfs.namenode.safemode.threshold-pct unit_test 0.999f get
dfs.namenode.secondary.http-address unit_test 0.0.0.0:9868 get
dfs.namenode.secondary.https-address unit_test 0.0.0.0:9869 get
dfs.namenode.send.qop.enabled unit_test false get
dfs.namenode.service.handler.count unit_test 10 get
dfs.namenode.shared.edits.dir hdfs:JournalNode.1 null getTrimmed
dfs.namenode.snapshot.capture.openfiles unit_test false get
dfs.namenode.snapshot.max.limit unit_test 65536 get
dfs.namenode.snapshot.skip.capture.accesstime-only-change unit_test false get
dfs.namenode.snapshot.skiplist.interval unit_test 10 get
dfs.namenode.snapshot.skiplist.max.levels unit_test 0 get
dfs.namenode.snapshotdiff.allow.snap-root-descendant unit_test true get
dfs.namenode.snapshotdiff.listing.limit unit_test 1000 get
dfs.namenode.stale.datanode.interval unit_test 30000 get
dfs.namenode.stale.datanode.minimum.interval unit_test 3 get
dfs.namenode.startup.delay.block.deletion.sec unit_test 0 get
dfs.namenode.storage.dir.perm unit_test 700 get
dfs.namenode.storageinfo.defragment.interval.ms unit_test 600000 get
dfs.namenode.storageinfo.defragment.ratio unit_test 0.75 get
dfs.namenode.storageinfo.defragment.timeout.ms unit_test 4 get
dfs.namenode.support.allow.format unit_test true get
dfs.namenode.top.enabled unit_test true get
dfs.namenode.top.num.users unit_test 10 get
dfs.namenode.top.window.num.buckets unit_test 10 get
dfs.namenode.top.windows.minutes unit_test 1,5,25 get
dfs.namenode.upgrade.domain.factor unit_test 3 get
dfs.namenode.write-lock-reporting-threshold-ms unit_test 5000 get
dfs.namenode.write.stale.datanode.ratio unit_test 0.5f get
dfs.namenode.xattrs.enabled unit_test true get
dfs.nameservices hdfs:JournalNode.1 [] getTrimmedStringCollection
dfs.net.topology.impl unit_test org.apache.hadoop.hdfs.net.DFSNetworkTopology get
dfs.permissions.ContentSummary.subAccess unit_test false get
dfs.permissions.enabled unit_test true get
dfs.permissions.superusergroup unit_test supergroup get
dfs.pipeline.ecn unit_test false get
dfs.provided.aliasmap.class unit_test org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TextFileRegionAliasMap get
dfs.provided.aliasmap.inmemory.batch-size unit_test 500 get
dfs.provided.aliasmap.inmemory.enabled unit_test false get
dfs.provided.aliasmap.inmemory.leveldb.dir unit_test /tmp get
dfs.provided.aliasmap.inmemory.server.log unit_test false get
dfs.provided.aliasmap.load.retries unit_test 0 get
dfs.provided.aliasmap.text.delimiter unit_test , get
dfs.provided.storage.id unit_test DS-PROVIDED get
dfs.qjm.operations.timeout unit_test 60s get
dfs.qjournal.accept-recovery.timeout.ms unit_test 120000 get
dfs.qjournal.finalize-segment.timeout.ms unit_test 120000 get
dfs.qjournal.get-journal-state.timeout.ms unit_test 120000 get
dfs.qjournal.http.open.timeout.ms unit_test 60000 get
dfs.qjournal.http.read.timeout.ms unit_test 60000 get
dfs.qjournal.new-epoch.timeout.ms unit_test 120000 get
dfs.qjournal.prepare-recovery.timeout.ms unit_test 120000 get
dfs.qjournal.queued-edits.limit.mb unit_test 10 get
dfs.qjournal.queued-edits.limit.mb unit_test 10 getInt
dfs.qjournal.select-input-streams.timeout.ms unit_test 20000 get
dfs.qjournal.start-segment.timeout.ms unit_test 20000 get
dfs.qjournal.write-txns.timeout.ms unit_test 20000 get
dfs.quota.by.storage.type.enabled unit_test true get
dfs.reformat.disabled unit_test false get
dfs.replication unit_test 3 get
dfs.replication.max unit_test 512 get
dfs.secondary.namenode.kerberos.internal.spnego.principal unit_test ${dfs.web.authentication.kerberos.principal} get
dfs.short.circuit.shared.memory.watcher.interrupt.check.ms unit_test 60000 get
dfs.storage.policy.enabled unit_test true get
dfs.storage.policy.satisfier.address unit_test 0.0.0.0:0 get
dfs.storage.policy.satisfier.datanode.cache.refresh.interval.ms unit_test 300000 get
dfs.storage.policy.satisfier.max.outstanding.paths unit_test 10000 get
dfs.storage.policy.satisfier.mode unit_test none get
dfs.storage.policy.satisfier.queue.limit unit_test 1000 get
dfs.storage.policy.satisfier.recheck.timeout.millis unit_test 60000 get
dfs.storage.policy.satisfier.retry.max.attempts unit_test 3 get
dfs.storage.policy.satisfier.self.retry.timeout.millis unit_test 300000 get
dfs.storage.policy.satisfier.work.multiplier.per.iteration unit_test 1 get
dfs.stream-buffer-size unit_test 4096 get
dfs.use.dfs.network.topology unit_test true get
dfs.user.home.dir.prefix unit_test /user get
dfs.web.authentication.filter unit_test org.apache.hadoop.hdfs.web.AuthFilter get
dfs.web.authentication.kerberos.keytab hdfs:JournalNode.1 null get
dfs.web.ugi hdfs:JournalNode.1 null get
dfs.webhdfs.acl.provider.permission.pattern unit_test ^(default:)?(user|group|mask|other):[[A-Za-z_][A-Za-z0-9._-]]*:([rwx-]{3})?(,(default:)?(user|group|mask|other):[[A-Za-z_][A-Za-z0-9._-]]*:([rwx-]{3})?)*$ get
dfs.webhdfs.netty.high.watermark unit_test 65535 get
dfs.webhdfs.netty.low.watermark unit_test 32768 get
dfs.webhdfs.oauth2.enabled unit_test false get
dfs.webhdfs.rest-csrf.browser-useragents-regex unit_test ^Mozilla.*,^Opera.* get
dfs.webhdfs.rest-csrf.custom-header unit_test X-XSRF-HEADER get
dfs.webhdfs.rest-csrf.enabled unit_test false get
dfs.webhdfs.rest-csrf.methods-to-ignore unit_test GET,OPTIONS,HEAD,TRACE get
dfs.webhdfs.socket.connect-timeout unit_test 60s get
dfs.webhdfs.socket.read-timeout unit_test 60s get
dfs.webhdfs.ugi.expire.after.access unit_test 600000 get
dfs.webhdfs.use.ipc.callq unit_test true get
dfs.webhdfs.user.provider.user.pattern unit_test ^[A-Za-z_][A-Za-z0-9._-]*[$]?$ get
dfs.xframe.enabled unit_test true get
dfs.xframe.value unit_test SAMEORIGIN get
file.blocksize unit_test 67108864 get
file.bytes-per-checksum unit_test 512 get
file.client-write-packet-size unit_test 65536 get
file.replication unit_test 1 get
file.stream-buffer-size unit_test 4096 get
fs.AbstractFileSystem.abfs.impl unit_test org.apache.hadoop.fs.azurebfs.Abfs get
fs.AbstractFileSystem.abfss.impl unit_test org.apache.hadoop.fs.azurebfs.Abfss get
fs.AbstractFileSystem.adl.impl unit_test org.apache.hadoop.fs.adl.Adl get
fs.AbstractFileSystem.file.impl unit_test org.apache.hadoop.fs.local.LocalFs get
fs.AbstractFileSystem.ftp.impl unit_test org.apache.hadoop.fs.ftp.FtpFs get
fs.AbstractFileSystem.har.impl unit_test org.apache.hadoop.fs.HarFs get
fs.AbstractFileSystem.hdfs.impl unit_test org.apache.hadoop.fs.Hdfs get
fs.AbstractFileSystem.s3a.impl unit_test org.apache.hadoop.fs.s3a.S3A get
fs.AbstractFileSystem.swebhdfs.impl unit_test org.apache.hadoop.fs.SWebHdfs get
fs.AbstractFileSystem.viewfs.impl unit_test org.apache.hadoop.fs.viewfs.ViewFs get
fs.AbstractFileSystem.wasb.impl unit_test org.apache.hadoop.fs.azure.Wasb get
fs.AbstractFileSystem.wasbs.impl unit_test org.apache.hadoop.fs.azure.Wasbs get
fs.AbstractFileSystem.webhdfs.impl unit_test org.apache.hadoop.fs.WebHdfs get
fs.abfs.impl unit_test org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem get
fs.abfss.impl unit_test org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem get
fs.adl.impl unit_test org.apache.hadoop.fs.adl.AdlFileSystem get
fs.adl.oauth2.access.token.provider.type unit_test ClientCredential get
fs.automatic.close unit_test true get
fs.azure.authorization unit_test false get
fs.azure.authorization.caching.enable unit_test true get
fs.azure.local.sas.key.mode unit_test false get
fs.azure.sas.expiry.period unit_test 90d get
fs.azure.saskey.usecontainersaskeyforallaccess unit_test true get
fs.azure.secure.mode unit_test false get
fs.azure.user.agent.prefix unit_test unknown get
fs.client.resolve.remote.symlinks unit_test true get
fs.client.resolve.topology.enabled unit_test false get
fs.defaultFS unit_test file:/// get
fs.df.interval unit_test 60000 get
fs.du.interval unit_test 600000 get
fs.ftp.data.connection.mode unit_test ACTIVE_LOCAL_DATA_CONNECTION_MODE get
fs.ftp.host unit_test 0.0.0.0 get
fs.ftp.host.port unit_test 21 get
fs.ftp.impl unit_test org.apache.hadoop.fs.ftp.FTPFileSystem get
fs.ftp.transfer.mode unit_test BLOCK_TRANSFER_MODE get
fs.har.impl.disable.cache unit_test true get
fs.permissions.umask-mode unit_test 022 get
fs.s3a.assumed.role.credentials.provider unit_test org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider get
fs.s3a.assumed.role.session.duration unit_test 30m get
fs.s3a.assumed.role.sts.endpoint.region unit_test us-west-1 get
fs.s3a.attempts.maximum unit_test 20 get
fs.s3a.block.size unit_test 32M get
fs.s3a.buffer.dir unit_test /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/tmp/s3a get
fs.s3a.change.detection.mode unit_test server get
fs.s3a.change.detection.source unit_test etag get
fs.s3a.change.detection.version.required unit_test true get
fs.s3a.committer.magic.enabled unit_test false get
fs.s3a.committer.name unit_test file get
fs.s3a.committer.staging.abort.pending.uploads unit_test true get
fs.s3a.committer.staging.conflict-mode unit_test fail get
fs.s3a.committer.staging.tmp.path unit_test tmp/staging get
fs.s3a.committer.staging.unique-filenames unit_test true get
fs.s3a.committer.threads unit_test 8 get
fs.s3a.connection.establish.timeout unit_test 5000 get
fs.s3a.connection.maximum unit_test 15 get
fs.s3a.connection.ssl.enabled unit_test true get
fs.s3a.connection.timeout unit_test 200000 get
fs.s3a.etag.checksum.enabled unit_test false get
fs.s3a.fast.upload.active.blocks unit_test 4 get
fs.s3a.fast.upload.buffer unit_test disk get
fs.s3a.impl unit_test org.apache.hadoop.fs.s3a.S3AFileSystem get
fs.s3a.list.version unit_test 2 get
fs.s3a.max.total.tasks unit_test 5 get
fs.s3a.metadatastore.authoritative unit_test false get
fs.s3a.metadatastore.impl unit_test org.apache.hadoop.fs.s3a.s3guard.NullMetadataStore get
fs.s3a.multiobjectdelete.enable unit_test true get
fs.s3a.multipart.purge unit_test false get
fs.s3a.multipart.purge.age unit_test 86400 get
fs.s3a.multipart.size unit_test 100M get
fs.s3a.multipart.threshold unit_test 2147483647 get
fs.s3a.paging.maximum unit_test 5000 get
fs.s3a.path.style.access unit_test false get
fs.s3a.readahead.range unit_test 64K get
fs.s3a.retry.interval unit_test 500ms get
fs.s3a.retry.limit unit_test 20 get
fs.s3a.retry.throttle.interval unit_test 1000ms get
fs.s3a.retry.throttle.limit unit_test 20 get
fs.s3a.s3guard.cli.prune.age unit_test 86400000 get
fs.s3a.s3guard.ddb.background.sleep unit_test 25ms get
fs.s3a.s3guard.ddb.max.retries unit_test 9 get
fs.s3a.s3guard.ddb.table.capacity.read unit_test 500 get
fs.s3a.s3guard.ddb.table.capacity.write unit_test 100 get
fs.s3a.s3guard.ddb.table.create unit_test false get
fs.s3a.s3guard.ddb.throttle.retry.interval unit_test 100ms get
fs.s3a.socket.recv.buffer unit_test 8192 get
fs.s3a.socket.send.buffer unit_test 8192 get
fs.s3a.threads.keepalivetime unit_test 60 get
fs.s3a.threads.max unit_test 10 get
fs.swift.impl unit_test org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem get
fs.trash.checkpoint.interval unit_test 0 get
fs.trash.interval unit_test 0 get
fs.viewfs.rename.strategy unit_test SAME_MOUNTPOINT get
fs.wasb.impl unit_test org.apache.hadoop.fs.azure.NativeAzureFileSystem get
fs.wasbs.impl unit_test org.apache.hadoop.fs.azure.NativeAzureFileSystem$Secure get
ftp.blocksize unit_test 67108864 get
ftp.bytes-per-checksum unit_test 512 get
ftp.client-write-packet-size unit_test 65536 get
ftp.replication unit_test 3 get
ftp.stream-buffer-size unit_test 4096 get
ha.failover-controller.cli-check.rpc-timeout.ms unit_test 20000 get
ha.failover-controller.graceful-fence.connection.retries unit_test 1 get
ha.failover-controller.graceful-fence.rpc-timeout.ms unit_test 5000 get
ha.failover-controller.new-active.rpc-timeout.ms unit_test 60000 get
ha.health-monitor.check-interval.ms unit_test 1000 get
ha.health-monitor.connect-retry-interval.ms unit_test 1000 get
ha.health-monitor.rpc-timeout.ms unit_test 45000 get
ha.health-monitor.sleep-after-disconnect.ms unit_test 1000 get
ha.zookeeper.acl unit_test world:anyone:rwcda get
ha.zookeeper.parent-znode unit_test /hadoop-ha get
ha.zookeeper.session-timeout.ms unit_test 10000 get
hadoop.caller.context.enabled unit_test false get
hadoop.caller.context.max.size unit_test 128 get
hadoop.caller.context.signature.max.size unit_test 40 get
hadoop.common.configuration.version unit_test 3.0.0 get
hadoop.fuse.connection.timeout unit_test 300 get
hadoop.fuse.timer.period unit_test 5 get
hadoop.hdfs.configuration.version unit_test 1 get
hadoop.htrace.sampler.classes hdfs:JournalNode.1 null get
hadoop.htrace.span.receiver.classes hdfs:JournalNode.1 null get
hadoop.htrace.tracer.id hdfs:JournalNode.1 null get
hadoop.http.acceptor.count hdfs:JournalNode.1 -1 getInt
hadoop.http.authentication.kerberos.keytab unit_test /root/hadoop.keytab get
hadoop.http.authentication.kerberos.principal unit_test HTTP/_HOST@LOCALHOST get
hadoop.http.authentication.signature.secret.file unit_test /root/hadoop-http-auth-signature-secret get
hadoop.http.authentication.simple.anonymous.allowed unit_test true get
hadoop.http.authentication.token.validity unit_test 36000 get
hadoop.http.authentication.type unit_test simple get
hadoop.http.cross-origin.allowed-headers unit_test X-Requested-With,Content-Type,Accept,Origin get
hadoop.http.cross-origin.allowed-methods unit_test GET,POST,HEAD get
hadoop.http.cross-origin.allowed-origins unit_test * get
hadoop.http.cross-origin.enabled unit_test false get
hadoop.http.cross-origin.max-age unit_test 1800 get
hadoop.http.filter.initializers unit_test org.apache.hadoop.http.lib.StaticUserWebFilter get
hadoop.http.idle_timeout.ms hdfs:JournalNode.1 10000 getInt
hadoop.http.logs.enabled hdfs:JournalNode.1 true getBoolean
hadoop.http.logs.enabled unit_test true get
hadoop.http.max.request.header.size hdfs:JournalNode.1 65536 getInt
hadoop.http.max.response.header.size hdfs:JournalNode.1 65536 getInt
hadoop.http.max.threads hdfs:JournalNode.1 -1 getInt
hadoop.http.selector.count hdfs:JournalNode.1 -1 getInt
hadoop.http.socket.backlog.size hdfs:JournalNode.1 128 getInt
hadoop.http.staticuser.user hdfs:JournalNode.1 dr.who get
hadoop.http.staticuser.user unit_test dr.who get
hadoop.http.temp.dir hdfs:JournalNode.1 null get
hadoop.jetty.logs.serve.aliases hdfs:JournalNode.1 true getBoolean
hadoop.jetty.logs.serve.aliases unit_test true get
hadoop.kerberos.kinit.command unit_test kinit get
hadoop.kerberos.min.seconds.before.relogin unit_test 60 get
hadoop.kerberos.min.seconds.before.relogin unit_test 60 getLong
hadoop.registry.jaas.context unit_test Client get
hadoop.registry.secure unit_test false get
hadoop.registry.system.acls unit_test sasl:yarn@, sasl:mapred@, sasl:hdfs@ get
hadoop.registry.zk.connection.timeout.ms unit_test 15000 get
hadoop.registry.zk.quorum unit_test localhost:2181 get
hadoop.registry.zk.retry.ceiling.ms unit_test 60000 get
hadoop.registry.zk.retry.interval.ms unit_test 1000 get
hadoop.registry.zk.retry.times unit_test 5 get
hadoop.registry.zk.root unit_test /registry get
hadoop.registry.zk.session.timeout.ms unit_test 60000 get
hadoop.rpc.protection unit_test authentication get
hadoop.rpc.socket.factory.class.default unit_test org.apache.hadoop.net.StandardSocketFactory get
hadoop.security.auth_to_local unit_test RULE:[1:$1] RULE:[2:$1] get
hadoop.security.auth_to_local.mechanism unit_test hadoop get
hadoop.security.authentication hdfs:JournalNode.1 simple get
hadoop.security.authentication unit_test simple get
hadoop.security.authorization hdfs:JournalNode.1 false getBoolean
hadoop.security.authorization unit_test false get
hadoop.security.credential.clear-text-fallback unit_test true get
hadoop.security.crypto.buffer.size unit_test 8192 get
hadoop.security.crypto.cipher.suite unit_test AES/CTR/NoPadding get
hadoop.security.crypto.codec.classes.aes.ctr.nopadding unit_test org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec, org.apache.hadoop.crypto.JceAesCtrCryptoCodec get
hadoop.security.dns.log-slow-lookups.enabled unit_test false get
hadoop.security.dns.log-slow-lookups.enabled unit_test false getBoolean
hadoop.security.dns.log-slow-lookups.threshold.ms unit_test 1000 get
hadoop.security.dns.log-slow-lookups.threshold.ms unit_test 1000 getInt
hadoop.security.group.mapping unit_test org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback get
hadoop.security.group.mapping.ldap.connection.timeout.ms unit_test 60000 get
hadoop.security.group.mapping.ldap.conversion.rule unit_test none get
hadoop.security.group.mapping.ldap.directory.search.timeout unit_test 10000 get
hadoop.security.group.mapping.ldap.num.attempts unit_test 3 get
hadoop.security.group.mapping.ldap.num.attempts.before.failover unit_test 3 get
hadoop.security.group.mapping.ldap.posix.attr.gid.name unit_test gidNumber get
hadoop.security.group.mapping.ldap.posix.attr.uid.name unit_test uidNumber get
hadoop.security.group.mapping.ldap.read.timeout.ms unit_test 60000 get
hadoop.security.group.mapping.ldap.search.attr.group.name unit_test cn get
hadoop.security.group.mapping.ldap.search.attr.member unit_test member get
hadoop.security.group.mapping.ldap.search.filter.group unit_test (objectClass=group) get
hadoop.security.group.mapping.ldap.search.filter.user unit_test (&(objectClass=user)(sAMAccountName={0})) get
hadoop.security.group.mapping.ldap.search.group.hierarchy.levels unit_test 0 get
hadoop.security.group.mapping.ldap.ssl unit_test false get
hadoop.security.group.mapping.providers.combined unit_test true get
hadoop.security.groups.cache.background.reload unit_test false get
hadoop.security.groups.cache.background.reload unit_test false getBoolean
hadoop.security.groups.cache.background.reload.threads unit_test 3 get
hadoop.security.groups.cache.background.reload.threads unit_test 3 getInt
hadoop.security.groups.cache.secs unit_test 300 get
hadoop.security.groups.cache.secs unit_test 300 getLong
hadoop.security.groups.cache.warn.after.ms unit_test 5000 get
hadoop.security.groups.cache.warn.after.ms unit_test 5000 getLong
hadoop.security.groups.negative-cache.secs unit_test 30 get
hadoop.security.groups.negative-cache.secs unit_test 30 getLong
hadoop.security.groups.shell.command.timeout unit_test 0s get
hadoop.security.instrumentation.requires.admin hdfs:JournalNode.1 false getBoolean
hadoop.security.instrumentation.requires.admin unit_test false get
hadoop.security.java.secure.random.algorithm unit_test SHA1PRNG get
hadoop.security.key.default.bitlength unit_test 128 get
hadoop.security.key.default.cipher unit_test AES/CTR/NoPadding get
hadoop.security.kms.client.authentication.retry-count unit_test 1 get
hadoop.security.kms.client.encrypted.key.cache.expiry unit_test 43200000 get
hadoop.security.kms.client.encrypted.key.cache.low-watermark unit_test 0.3f get
hadoop.security.kms.client.encrypted.key.cache.num.refill.threads unit_test 2 get
hadoop.security.kms.client.encrypted.key.cache.size unit_test 500 get
hadoop.security.kms.client.failover.sleep.base.millis unit_test 100 get
hadoop.security.kms.client.failover.sleep.max.millis unit_test 2000 get
hadoop.security.kms.client.timeout unit_test 60 get
hadoop.security.random.device.file.path unit_test /dev/urandom get
hadoop.security.sensitive-config-keys unit_test 
hadoop.security.token.service.use_ip unit_test true getBoolean
hadoop.security.uid.cache.secs unit_test 14400 get
hadoop.security.uid.cache.secs unit_test 14400 getLong
hadoop.service.shutdown.timeout unit_test 30s get
hadoop.shell.missing.defaultFs.warning unit_test false get
hadoop.shell.safely.delete.limit.num.files unit_test 100 get
hadoop.ssl.client.conf unit_test ssl-client.xml get
hadoop.ssl.enabled unit_test false get
hadoop.ssl.enabled.protocols unit_test TLSv1,SSLv2Hello,TLSv1.1,TLSv1.2 get
hadoop.ssl.enabled.protocols unit_test [Ljava.lang.String;@7b9436de getStrings
hadoop.ssl.hostname.verifier unit_test DEFAULT get
hadoop.ssl.keystores.factory.class unit_test org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory get
hadoop.ssl.require.client.cert unit_test false get
hadoop.ssl.require.client.cert unit_test false getBoolean
hadoop.ssl.server.conf unit_test ssl-server.xml get
hadoop.system.tags unit_test YARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT
hadoop.tags.system unit_test YARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT
hadoop.tmp.dir unit_test /tmp/hadoop-root get
hadoop.token.files unit_test null get
hadoop.user.group.metrics.percentiles.intervals unit_test [I@31304f14 getInts
hadoop.user.group.static.mapping.overrides unit_test dr.who=; get
hadoop.util.hash.type unit_test murmur get
hadoop.workaround.non.threadsafe.getpwuid unit_test true get
hadoop.workaround.non.threadsafe.getpwuid unit_test true getBoolean
hadoop.zk.acl unit_test world:anyone:rwcda get
hadoop.zk.num-retries unit_test 1000 get
hadoop.zk.retry-interval-ms unit_test 1000 get
hadoop.zk.timeout-ms unit_test 10000 get
httpfs.buffer.size unit_test 4096 get
io.compression.codec.bzip2.library unit_test system-native get
io.erasurecode.codec.rs-legacy.rawcoders unit_test rs-legacy_java get
io.erasurecode.codec.rs.rawcoders unit_test rs_native,rs_java get
io.erasurecode.codec.xor.rawcoders unit_test xor_native,xor_java get
io.file.buffer.size unit_test 4096 get
io.file.buffer.size unit_test 4096 getInt
io.map.index.interval unit_test 128 get
io.map.index.skip unit_test 0 get
io.mapfile.bloom.error.rate unit_test 0.005 get
io.mapfile.bloom.size unit_test 1048576 get
io.seqfile.compress.blocksize unit_test 1000000 get
io.seqfile.local.dir unit_test /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/tmp/io/local get
io.serializations unit_test org.apache.hadoop.io.serializer.WritableSerialization, org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization, org.apache.hadoop.io.serializer.avro.AvroReflectSerialization get
io.skip.checksum.errors unit_test false get
ipc.0.backoff.enable hdfs:JournalNode.1 false getBoolean
ipc.0.faircallqueue.priority-levels hdfs:JournalNode.1 0 getInt
ipc.0.scheduler.priority.levels hdfs:JournalNode.1 4 getInt
ipc.client.async.calls.max unit_test 100 getInt
ipc.client.bind.wildcard.addr unit_test false get
ipc.client.bind.wildcard.addr unit_test false getBoolean
ipc.client.connect.max.retries unit_test 10 get
ipc.client.connect.max.retries unit_test 10 getInt
ipc.client.connect.max.retries.on.sasl unit_test 5 getInt
ipc.client.connect.max.retries.on.timeouts unit_test 45 get
ipc.client.connect.max.retries.on.timeouts unit_test 45 getInt
ipc.client.connect.retry.interval unit_test 1000 get
ipc.client.connect.retry.interval unit_test 1000 getInt
ipc.client.connect.timeout unit_test 20000 get
ipc.client.connect.timeout unit_test 20000 getInt
ipc.client.connection.idle-scan-interval.ms hdfs:JournalNode.1 10000 getInt
ipc.client.connection.maxidletime hdfs:JournalNode.1 10000 getInt
ipc.client.connection.maxidletime unit_test 10000 get
ipc.client.connection.maxidletime unit_test 10000 getInt
ipc.client.fallback-to-simple-auth-allowed unit_test false get
ipc.client.fallback-to-simple-auth-allowed unit_test false getBoolean
ipc.client.idlethreshold hdfs:JournalNode.1 4000 getInt
ipc.client.idlethreshold unit_test 4000 get
ipc.client.kill.max hdfs:JournalNode.1 10 getInt
ipc.client.kill.max unit_test 10 get
ipc.client.low-latency unit_test false get
ipc.client.low-latency unit_test false getBoolean
ipc.client.ping unit_test true get
ipc.client.ping unit_test true getBoolean
ipc.client.rpc-timeout.ms unit_test 0 get
ipc.client.rpc-timeout.ms unit_test 0 getInt
ipc.client.tcpnodelay unit_test true get
ipc.client.tcpnodelay unit_test true getBoolean
ipc.maximum.data.length hdfs:JournalNode.1 67108864 getInt
ipc.maximum.data.length unit_test 67108864 get
ipc.maximum.response.length unit_test 134217728 get
ipc.maximum.response.length unit_test 134217728 getInt
ipc.ping.interval unit_test 60000 get
ipc.ping.interval unit_test 60000 getInt
ipc.server.handler.queue.size hdfs:JournalNode.1 100 getInt
ipc.server.listen.queue.size hdfs:JournalNode.1 128 getInt
ipc.server.listen.queue.size unit_test 128 get
ipc.server.log.slow.rpc hdfs:JournalNode.1 false getBoolean
ipc.server.log.slow.rpc unit_test false get
ipc.server.max.connections hdfs:JournalNode.1 0 getInt
ipc.server.max.connections unit_test 0 get
ipc.server.max.response.size hdfs:JournalNode.1 1048576 getInt
ipc.server.read.connection-queue.size hdfs:JournalNode.1 100 getInt
ipc.server.read.threadpool.size hdfs:JournalNode.1 1 getInt
ipc.server.tcpnodelay hdfs:JournalNode.1 true getBoolean
journalnode.htracesampler.classes hdfs:JournalNode.1 null get
journalnode.htracespan.receiver.classes hdfs:JournalNode.1 null get
journalnode.htracetracer.id hdfs:JournalNode.1 null get
net.topology.impl unit_test org.apache.hadoop.net.NetworkTopology get
net.topology.node.switch.mapping.impl unit_test org.apache.hadoop.net.ScriptBasedMapping get
net.topology.script.number.args unit_test 100 get
nfs.allow.insecure.ports unit_test true get
nfs.dump.dir unit_test /tmp/.hdfs-nfs get
nfs.exports.allowed.hosts unit_test * rw get
nfs.mountd.port unit_test 4242 get
nfs.rtmax unit_test 1048576 get
nfs.server.port unit_test 2049 get
nfs.wtmax unit_test 1048576 get
org.apache.hadoop.mapred.JobConf hdfs:JournalNode.1 null getClassByNameOrNull
org.apache.hadoop.mapred.JobConf unit_test null getClassByNameOrNull
org.apache.hadoop.net.StandardSocketFactory unit_test class org.apache.hadoop.net.StandardSocketFactory getClassByName
rpc.metrics.percentiles.intervals hdfs:JournalNode.1 [I@6e535154 getInts
rpc.metrics.quantile.enable unit_test false get
seq.io.sort.factor unit_test 100 get
seq.io.sort.mb unit_test 100 get
ssl.client.keystore.type unit_test jks get
ssl.client.truststore.location unit_test  get
ssl.client.truststore.type unit_test jks get
ssl.server.exclude.cipher.list unit_test [Ljava.lang.String;@6302bbb1 getTrimmedStrings
tfile.fs.input.buffer.size unit_test 262144 get
tfile.fs.output.buffer.size unit_test 262144 get
tfile.io.chunk.size unit_test 1048576 get

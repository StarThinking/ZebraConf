datanode.https.port unit_test 50475 get
dfs.balancer.address unit_test 0.0.0.0:0 get
dfs.balancer.block-move.timeout unit_test 0 get
dfs.balancer.dispatcherThreads unit_test 200 get
dfs.balancer.getBlocks.min-block-size unit_test 10485760 get
dfs.balancer.getBlocks.size unit_test 2147483648 get
dfs.balancer.keytab.enabled unit_test false get
dfs.balancer.max-iteration-time unit_test 1200000 get
dfs.balancer.max-no-move-interval unit_test 60000 get
dfs.balancer.max-size-to-move unit_test 10737418240 get
dfs.balancer.movedWinWidth unit_test 5400000 get
dfs.balancer.moverThreads unit_test 1000 get
dfs.block.access.key.update.interval unit_test 600 get
dfs.block.access.token.enable unit_test false get
dfs.block.access.token.lifetime unit_test 600 get
dfs.block.access.token.protobuf.enable unit_test false get
dfs.block.invalidate.limit unit_test 1000 get
dfs.block.misreplication.processing.limit unit_test 10000 get
dfs.block.placement.ec.classname unit_test org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant get
dfs.block.replicator.classname unit_test org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault get
dfs.block.scanner.volume.bytes.per.second unit_test 1048576 get
dfs.blockreport.incremental.intervalMsec unit_test 0 get
dfs.blockreport.initialDelay unit_test 0s get
dfs.blockreport.intervalMsec unit_test 21600000 get
dfs.blockreport.split.threshold unit_test 1000000 get
dfs.blocksize unit_test 134217728 get
dfs.bytes-per-checksum unit_test 512 get
dfs.cachereport.intervalMsec unit_test 10000 get
dfs.checksum.combine.mode unit_test MD5MD5CRC get
dfs.checksum.type unit_test CRC32C get
dfs.client-write-packet-size unit_test 65536 get
dfs.client.block.write.locateFollowingBlock.initial.delay.ms unit_test 400 get
dfs.client.block.write.locateFollowingBlock.retries unit_test 5 get
dfs.client.block.write.replace-datanode-on-failure.best-effort unit_test false get
dfs.client.block.write.replace-datanode-on-failure.enable unit_test true get
dfs.client.block.write.replace-datanode-on-failure.min-replication unit_test 0 get
dfs.client.block.write.replace-datanode-on-failure.policy unit_test DEFAULT get
dfs.client.block.write.retries unit_test 3 get
dfs.client.cached.conn.retry unit_test 3 get
dfs.client.context unit_test default get
dfs.client.datanode-restart.timeout unit_test 30s get
dfs.client.domain.socket.data.traffic unit_test false get
dfs.client.failover.connection.retries unit_test 0 get
dfs.client.failover.connection.retries.on.timeouts unit_test 0 get
dfs.client.failover.max.attempts unit_test 15 get
dfs.client.failover.random.order unit_test false get
dfs.client.failover.sleep.base.millis unit_test 500 get
dfs.client.failover.sleep.max.millis unit_test 15000 get
dfs.client.hedged.read.threadpool.size unit_test 0 get
dfs.client.hedged.read.threshold.millis unit_test 500 get
dfs.client.https.keystore.resource unit_test ssl-client.xml get
dfs.client.https.need-auth unit_test false get
dfs.client.key.provider.cache.expiry unit_test 864000000 get
dfs.client.max.block.acquire.failures unit_test 3 get
dfs.client.mmap.cache.size unit_test 256 get
dfs.client.mmap.cache.timeout.ms unit_test 3600000 get
dfs.client.mmap.enabled unit_test true get
dfs.client.mmap.retry.timeout.ms unit_test 300000 get
dfs.client.read.short.circuit.replica.stale.threshold.ms unit_test 1800000 get
dfs.client.read.shortcircuit unit_test false get
dfs.client.read.shortcircuit.buffer.size unit_test 1048576 get
dfs.client.read.shortcircuit.skip.checksum unit_test false get
dfs.client.read.shortcircuit.streams.cache.expiry.ms unit_test 300000 get
dfs.client.read.shortcircuit.streams.cache.size unit_test 256 get
dfs.client.read.striped.threadpool.size unit_test 18 get
dfs.client.retry.interval-ms.get-last-block-length unit_test 4000 get
dfs.client.retry.max.attempts unit_test 10 get
dfs.client.retry.policy.enabled unit_test false get
dfs.client.retry.policy.spec unit_test 10000,6,60000,10 get
dfs.client.retry.times.get-last-block-length unit_test 3 get
dfs.client.retry.window.base unit_test 3000 get
dfs.client.server-defaults.validity.period.ms unit_test 3600000 get
dfs.client.slow.io.warning.threshold.ms unit_test 30000 get
dfs.client.socket-timeout unit_test 60000 get
dfs.client.socket.send.buffer.size unit_test 0 get
dfs.client.socketcache.capacity unit_test 16 get
dfs.client.socketcache.expiryMsec unit_test 3000 get
dfs.client.test.drop.namenode.response.number unit_test 0 get
dfs.client.use.datanode.hostname unit_test false get
dfs.client.use.legacy.blockreader.local unit_test false get
dfs.client.write.byte-array-manager.count-limit unit_test 2048 get
dfs.client.write.byte-array-manager.count-reset-time-period-ms unit_test 10000 get
dfs.client.write.byte-array-manager.count-threshold unit_test 128 get
dfs.client.write.byte-array-manager.enabled unit_test false get
dfs.client.write.exclude.nodes.cache.expiry.interval.millis unit_test 600000 get
dfs.client.write.max-packets-in-flight unit_test 80 get
dfs.content-summary.limit unit_test 5000 get
dfs.content-summary.sleep-microsec unit_test 500 get
dfs.data.transfer.client.tcpnodelay unit_test true get
dfs.data.transfer.server.tcpnodelay unit_test true get
dfs.datanode.address unit_test 0.0.0.0:9866 get
dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction unit_test 0.75f get
dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold unit_test 10737418240 get
dfs.datanode.balance.bandwidthPerSec unit_test 10m get
dfs.datanode.balance.max.concurrent.moves unit_test 50 get
dfs.datanode.block-pinning.enabled unit_test false get
dfs.datanode.block.id.layout.upgrade.threads unit_test 12 get
dfs.datanode.bp-ready.timeout unit_test 20s get
dfs.datanode.cache.revocation.polling.ms unit_test 500 get
dfs.datanode.cache.revocation.timeout.ms unit_test 900000 get
dfs.datanode.cached-dfsused.check.interval.ms unit_test 600000 get
dfs.datanode.data.dir unit_test file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/tmp/dfs/data get
dfs.datanode.data.dir.perm unit_test 700 get
dfs.datanode.directoryscan.interval unit_test 21600s get
dfs.datanode.directoryscan.threads unit_test 1 get
dfs.datanode.directoryscan.throttle.limit.ms.per.sec unit_test 1000 get
dfs.datanode.disk.check.min.gap unit_test 15m get
dfs.datanode.disk.check.timeout unit_test 10m get
dfs.datanode.dns.interface unit_test default get
dfs.datanode.dns.nameserver unit_test default get
dfs.datanode.drop.cache.behind.reads unit_test false get
dfs.datanode.drop.cache.behind.writes unit_test false get
dfs.datanode.du.reserved unit_test 0 get
dfs.datanode.du.reserved.calculator unit_test org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.ReservedSpaceCalculator$ReservedSpaceCalculatorAbsolute get
dfs.datanode.du.reserved.pct unit_test 0 get
dfs.datanode.ec.reconstruction.stripedread.buffer.size unit_test 65536 get
dfs.datanode.ec.reconstruction.stripedread.timeout.millis unit_test 5000 get
dfs.datanode.ec.reconstruction.threads unit_test 8 get
dfs.datanode.ec.reconstruction.xmits.weight unit_test 0.5 get
dfs.datanode.failed.volumes.tolerated unit_test 0 get
dfs.datanode.fileio.profiling.sampling.percentage unit_test 0 get
dfs.datanode.fsdatasetcache.max.threads.per.volume unit_test 4 get
dfs.datanode.handler.count unit_test 10 get
dfs.datanode.http.address unit_test 0.0.0.0:9864 get
dfs.datanode.http.internal-proxy.port unit_test 0 get
dfs.datanode.https.address unit_test 0.0.0.0:9865 get
dfs.datanode.ipc.address unit_test 0.0.0.0:9867 get
dfs.datanode.lazywriter.interval.sec unit_test 60 get
dfs.datanode.max.locked.memory unit_test 0 get
dfs.datanode.max.transfer.threads unit_test 4096 get
dfs.datanode.metrics.logger.period.seconds unit_test 600 get
dfs.datanode.network.counts.cache.max.size unit_test 2147483647 get
dfs.datanode.oob.timeout-ms unit_test 1500,0,0,0 get
dfs.datanode.outliers.report.interval unit_test 30m get
dfs.datanode.peer.metrics.min.outlier.detection.samples unit_test 1000 get
dfs.datanode.peer.stats.enabled unit_test false get
dfs.datanode.readahead.bytes unit_test 4194304 get
dfs.datanode.restart.replica.expiration unit_test 50 get
dfs.datanode.scan.period.hours unit_test 504 get
dfs.datanode.shared.file.descriptor.paths unit_test /dev/shm,/tmp get
dfs.datanode.slow.io.warning.threshold.ms unit_test 300 get
dfs.datanode.socket.reuse.keepalive unit_test 4000 get
dfs.datanode.socket.write.timeout unit_test 480000 get
dfs.datanode.sync.behind.writes unit_test false get
dfs.datanode.sync.behind.writes.in.background unit_test false get
dfs.datanode.transfer.socket.recv.buffer.size unit_test 0 get
dfs.datanode.transfer.socket.send.buffer.size unit_test 0 get
dfs.datanode.transferTo.allowed unit_test true get
dfs.datanode.use.datanode.hostname unit_test false get
dfs.default.chunk.view.size unit_test 32768 get
dfs.disk.balancer.block.tolerance.percent unit_test 10 get
dfs.disk.balancer.enabled unit_test true get
dfs.disk.balancer.max.disk.errors unit_test 5 get
dfs.disk.balancer.max.disk.throughputInMBperSec unit_test 10 get
dfs.disk.balancer.plan.threshold.percent unit_test 10 get
dfs.disk.balancer.plan.valid.interval unit_test 1d get
dfs.domain.socket.disable.interval.seconds unit_test 600 get
dfs.edit.log.transfer.bandwidthPerSec unit_test 0 get
dfs.edit.log.transfer.timeout unit_test 30000 get
dfs.encrypt.data.overwrite.downstream.derived.qop unit_test false get
dfs.encrypt.data.transfer unit_test false get
dfs.encrypt.data.transfer.cipher.key.bitlength unit_test 128 get
dfs.ha.automatic-failover.enabled unit_test false get
dfs.ha.log-roll.period unit_test 120s get
dfs.ha.standby.checkpoints unit_test true get
dfs.ha.tail-edits.in-progress unit_test false get
dfs.ha.tail-edits.namenode-retries unit_test 3 get
dfs.ha.tail-edits.period unit_test 60s get
dfs.ha.tail-edits.period.backoff-max unit_test 0 get
dfs.ha.tail-edits.rolledits.timeout unit_test 60 get
dfs.ha.zkfc.nn.http.timeout.ms unit_test 20000 get
dfs.ha.zkfc.port unit_test 8019 get
dfs.heartbeat.interval unit_test 3s get
dfs.http.client.failover.max.attempts unit_test 15 get
dfs.http.client.failover.sleep.base.millis unit_test 500 get
dfs.http.client.failover.sleep.max.millis unit_test 15000 get
dfs.http.client.retry.max.attempts unit_test 10 get
dfs.http.client.retry.policy.enabled unit_test false get
dfs.http.client.retry.policy.spec unit_test 10000,6,60000,10 get
dfs.http.policy unit_test HTTP_ONLY get
dfs.https.server.keystore.resource unit_test ssl-server.xml get
dfs.image.compress unit_test false get
dfs.image.compression.codec unit_test org.apache.hadoop.io.compress.DefaultCodec get
dfs.image.transfer-bootstrap-standby.bandwidthPerSec unit_test 0 get
dfs.image.transfer.bandwidthPerSec unit_test 0 get
dfs.image.transfer.chunksize unit_test 65536 get
dfs.image.transfer.timeout unit_test 60000 get
dfs.journalnode.edit-cache-size.bytes unit_test 1048576 get
dfs.journalnode.edits.dir unit_test /tmp/hadoop/dfs/journalnode/ get
dfs.journalnode.edits.dir.perm unit_test 700 get
dfs.journalnode.enable.sync unit_test true get
dfs.journalnode.http-address unit_test 0.0.0.0:8480 get
dfs.journalnode.https-address unit_test 0.0.0.0:8481 get
dfs.journalnode.rpc-address unit_test 0.0.0.0:8485 get
dfs.journalnode.sync.interval unit_test 120000 get
dfs.lock.suppress.warning.interval unit_test 10s get
dfs.ls.limit unit_test 1000 get
dfs.mover.address unit_test 0.0.0.0:0 get
dfs.mover.keytab.enabled unit_test false get
dfs.mover.max-no-move-interval unit_test 60000 get
dfs.mover.movedWinWidth unit_test 5400000 get
dfs.mover.moverThreads unit_test 1000 get
dfs.mover.retry.max.attempts unit_test 10 get
dfs.namenode.accesstime.precision unit_test 3600000 get
dfs.namenode.acls.enabled unit_test false get
dfs.namenode.audit.log.async unit_test false get
dfs.namenode.audit.log.token.tracking.id unit_test false get
dfs.namenode.audit.loggers unit_test default get
dfs.namenode.available-space-block-placement-policy.balanced-space-preference-fraction unit_test 0.6 get
dfs.namenode.avoid.read.stale.datanode unit_test false get
dfs.namenode.avoid.write.stale.datanode unit_test false get
dfs.namenode.backup.address unit_test 0.0.0.0:50100 get
dfs.namenode.backup.http-address unit_test 0.0.0.0:50105 get
dfs.namenode.block-placement-policy.default.prefer-local-node unit_test true get
dfs.namenode.block.deletion.increment unit_test 1000 get
dfs.namenode.blockreport.queue.size unit_test 1024 get
dfs.namenode.blocks.per.postponedblocks.rescan unit_test 10000 get
dfs.namenode.caching.enabled unit_test true get
dfs.namenode.checkpoint.check.period unit_test 60s get
dfs.namenode.checkpoint.check.quiet-multiplier unit_test 1.5 get
dfs.namenode.checkpoint.dir unit_test file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/tmp/dfs/namesecondary get
dfs.namenode.checkpoint.edits.dir unit_test file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/tmp/dfs/namesecondary get
dfs.namenode.checkpoint.max-retries unit_test 3 get
dfs.namenode.checkpoint.period unit_test 3600s get
dfs.namenode.checkpoint.txns unit_test 1000000 get
dfs.namenode.datanode.registration.ip-hostname-check unit_test true get
dfs.namenode.decommission.blocks.per.interval unit_test 500000 get
dfs.namenode.decommission.interval unit_test 30s get
dfs.namenode.decommission.max.concurrent.tracked.nodes unit_test 100 get
dfs.namenode.delegation.key.update-interval unit_test 86400000 get
dfs.namenode.delegation.token.always-use unit_test false get
dfs.namenode.delegation.token.max-lifetime unit_test 604800000 get
dfs.namenode.delegation.token.renew-interval unit_test 86400000 get
dfs.namenode.ec.policies.max.cellsize unit_test 4194304 get
dfs.namenode.ec.system.default.policy unit_test RS-6-3-1024k get
dfs.namenode.edekcacheloader.initial.delay.ms unit_test 3000 get
dfs.namenode.edekcacheloader.interval.ms unit_test 1000 get
dfs.namenode.edit.log.autoroll.check.interval.ms unit_test 300000 get
dfs.namenode.edit.log.autoroll.multiplier.threshold unit_test 0.5 get
dfs.namenode.edits.asynclogging unit_test true get
dfs.namenode.edits.dir unit_test file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/tmp/dfs/name get
dfs.namenode.edits.dir.minimum unit_test 1 get
dfs.namenode.edits.noeditlogchannelflush unit_test false get
dfs.namenode.enable.retrycache unit_test true get
dfs.namenode.file.close.num-committed-allowed unit_test 0 get
dfs.namenode.fs-limits.max-blocks-per-file unit_test 10000 get
dfs.namenode.fs-limits.max-component-length unit_test 255 get
dfs.namenode.fs-limits.max-directory-items unit_test 1048576 get
dfs.namenode.fs-limits.max-xattr-size unit_test 16384 get
dfs.namenode.fs-limits.max-xattrs-per-inode unit_test 32 get
dfs.namenode.fs-limits.min-block-size unit_test 1048576 get
dfs.namenode.fslock.fair unit_test true get
dfs.namenode.full.block.report.lease.length.ms unit_test 300000 get
dfs.namenode.handler.count unit_test 10 get
dfs.namenode.heartbeat.recheck-interval unit_test 300000 get
dfs.namenode.hosts.provider.classname unit_test org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager get
dfs.namenode.http-address unit_test 0.0.0.0:9870 get
dfs.namenode.https-address unit_test 0.0.0.0:9871 get
dfs.namenode.inotify.max.events.per.rpc unit_test 1000 get
dfs.namenode.invalidate.work.pct.per.iteration unit_test 0.32f get
dfs.namenode.kerberos.internal.spnego.principal unit_test testingforemptydefaultvalue get
dfs.namenode.lazypersist.file.scrub.interval.sec unit_test 300 get
dfs.namenode.lease-recheck-interval-ms unit_test 2000 get
dfs.namenode.lifeline.handler.ratio unit_test 0.10 get
dfs.namenode.list.cache.directives.num.responses unit_test 100 get
dfs.namenode.list.cache.pools.num.responses unit_test 100 get
dfs.namenode.list.encryption.zones.num.responses unit_test 100 get
dfs.namenode.list.openfiles.num.responses unit_test 1000 get
dfs.namenode.list.reencryption.status.num.responses unit_test 100 get
dfs.namenode.lock.detailed-metrics.enabled unit_test false get
dfs.namenode.maintenance.replication.min unit_test 1 get
dfs.namenode.max-corrupt-file-blocks-returned unit_test 100 get
dfs.namenode.max-lock-hold-to-release-lease-ms unit_test 25 get
dfs.namenode.max-num-blocks-to-log unit_test 1000 get
dfs.namenode.max.extra.edits.segments.retained unit_test 10000 get
dfs.namenode.max.full.block.report.leases unit_test 6 get
dfs.namenode.max.objects unit_test 0 get
dfs.namenode.max.op.size unit_test 52428800 get
dfs.namenode.metrics.logger.period.seconds unit_test 600 get
dfs.namenode.missing.checkpoint.periods.before.shutdown unit_test 3 get
dfs.namenode.name.cache.threshold unit_test 10 get
dfs.namenode.name.dir unit_test file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/tmp/dfs/name get
dfs.namenode.name.dir.restore unit_test false get
dfs.namenode.num.checkpoints.retained unit_test 2 get
dfs.namenode.num.extra.edits.retained unit_test 1000000 get
dfs.namenode.path.based.cache.block.map.allocation.percent unit_test 0.25 get
dfs.namenode.path.based.cache.refresh.interval.ms unit_test 30000 get
dfs.namenode.path.based.cache.retry.interval.ms unit_test 30000 get
dfs.namenode.posix.acl.inheritance.enabled unit_test true get
dfs.namenode.provided.enabled unit_test false get
dfs.namenode.quota.init-threads unit_test 4 get
dfs.namenode.read-lock-reporting-threshold-ms unit_test 5000 get
dfs.namenode.reconstruction.pending.timeout-sec unit_test 300 get
dfs.namenode.redundancy.considerLoad unit_test true get
dfs.namenode.redundancy.considerLoad.factor unit_test 2.0 get
dfs.namenode.redundancy.interval.seconds unit_test 3s get
dfs.namenode.reencrypt.batch.size unit_test 1000 get
dfs.namenode.reencrypt.edek.threads unit_test 10 get
dfs.namenode.reencrypt.sleep.interval unit_test 1m get
dfs.namenode.reencrypt.throttle.limit.handler.ratio unit_test 1.0 get
dfs.namenode.reencrypt.throttle.limit.updater.ratio unit_test 1.0 get
dfs.namenode.reject-unresolved-dn-topology-mapping unit_test false get
dfs.namenode.replication.max-streams unit_test 2 get
dfs.namenode.replication.max-streams-hard-limit unit_test 4 get
dfs.namenode.replication.min unit_test 1 get
dfs.namenode.replication.work.multiplier.per.iteration unit_test 2 get
dfs.namenode.resource.check.interval unit_test 5000 get
dfs.namenode.resource.checked.volumes.minimum unit_test 1 get
dfs.namenode.resource.du.reserved unit_test 104857600 get
dfs.namenode.retrycache.expirytime.millis unit_test 600000 get
dfs.namenode.retrycache.heap.percent unit_test 0.03f get
dfs.namenode.safemode.extension unit_test 30000 get
dfs.namenode.safemode.min.datanodes unit_test 0 get
dfs.namenode.safemode.threshold-pct unit_test 0.999f get
dfs.namenode.secondary.http-address unit_test 0.0.0.0:9868 get
dfs.namenode.secondary.https-address unit_test 0.0.0.0:9869 get
dfs.namenode.send.qop.enabled unit_test false get
dfs.namenode.service.handler.count unit_test 10 get
dfs.namenode.snapshot.capture.openfiles unit_test false get
dfs.namenode.snapshot.max.limit unit_test 65536 get
dfs.namenode.snapshot.skip.capture.accesstime-only-change unit_test false get
dfs.namenode.snapshot.skiplist.interval unit_test 10 get
dfs.namenode.snapshot.skiplist.max.levels unit_test 0 get
dfs.namenode.snapshotdiff.allow.snap-root-descendant unit_test true get
dfs.namenode.snapshotdiff.listing.limit unit_test 1000 get
dfs.namenode.stale.datanode.interval unit_test 30000 get
dfs.namenode.stale.datanode.minimum.interval unit_test 3 get
dfs.namenode.startup.delay.block.deletion.sec unit_test 0 get
dfs.namenode.storage.dir.perm unit_test 700 get
dfs.namenode.storageinfo.defragment.interval.ms unit_test 600000 get
dfs.namenode.storageinfo.defragment.ratio unit_test 0.75 get
dfs.namenode.storageinfo.defragment.timeout.ms unit_test 4 get
dfs.namenode.support.allow.format unit_test true get
dfs.namenode.top.enabled unit_test true get
dfs.namenode.top.num.users unit_test 10 get
dfs.namenode.top.window.num.buckets unit_test 10 get
dfs.namenode.top.windows.minutes unit_test 1,5,25 get
dfs.namenode.upgrade.domain.factor unit_test 3 get
dfs.namenode.write-lock-reporting-threshold-ms unit_test 5000 get
dfs.namenode.write.stale.datanode.ratio unit_test 0.5f get
dfs.namenode.xattrs.enabled unit_test true get
dfs.net.topology.impl unit_test org.apache.hadoop.hdfs.net.DFSNetworkTopology get
dfs.permissions.ContentSummary.subAccess unit_test false get
dfs.permissions.enabled unit_test true get
dfs.permissions.superusergroup unit_test supergroup get
dfs.pipeline.ecn unit_test false get
dfs.provided.aliasmap.class unit_test org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TextFileRegionAliasMap get
dfs.provided.aliasmap.inmemory.batch-size unit_test 500 get
dfs.provided.aliasmap.inmemory.enabled unit_test false get
dfs.provided.aliasmap.inmemory.leveldb.dir unit_test /tmp get
dfs.provided.aliasmap.inmemory.server.log unit_test false get
dfs.provided.aliasmap.load.retries unit_test 0 get
dfs.provided.aliasmap.text.delimiter unit_test , get
dfs.provided.storage.id unit_test DS-PROVIDED get
dfs.qjm.operations.timeout unit_test 60s get
dfs.qjournal.accept-recovery.timeout.ms unit_test 120000 get
dfs.qjournal.finalize-segment.timeout.ms unit_test 120000 get
dfs.qjournal.get-journal-state.timeout.ms unit_test 120000 get
dfs.qjournal.http.open.timeout.ms unit_test 60000 get
dfs.qjournal.http.read.timeout.ms unit_test 60000 get
dfs.qjournal.new-epoch.timeout.ms unit_test 120000 get
dfs.qjournal.prepare-recovery.timeout.ms unit_test 120000 get
dfs.qjournal.queued-edits.limit.mb unit_test 10 get
dfs.qjournal.select-input-streams.timeout.ms unit_test 20000 get
dfs.qjournal.start-segment.timeout.ms unit_test 20000 get
dfs.qjournal.write-txns.timeout.ms unit_test 20000 get
dfs.quota.by.storage.type.enabled unit_test true get
dfs.reformat.disabled unit_test false get
dfs.replication unit_test 3 get
dfs.replication.max unit_test 512 get
dfs.secondary.namenode.kerberos.internal.spnego.principal unit_test testingforemptydefaultvalue get
dfs.short.circuit.shared.memory.watcher.interrupt.check.ms unit_test 60000 get
dfs.storage.policy.enabled unit_test true get
dfs.storage.policy.satisfier.address unit_test 0.0.0.0:0 get
dfs.storage.policy.satisfier.datanode.cache.refresh.interval.ms unit_test 300000 get
dfs.storage.policy.satisfier.max.outstanding.paths unit_test 10000 get
dfs.storage.policy.satisfier.mode unit_test none get
dfs.storage.policy.satisfier.queue.limit unit_test 1000 get
dfs.storage.policy.satisfier.recheck.timeout.millis unit_test 60000 get
dfs.storage.policy.satisfier.retry.max.attempts unit_test 3 get
dfs.storage.policy.satisfier.self.retry.timeout.millis unit_test 300000 get
dfs.storage.policy.satisfier.work.multiplier.per.iteration unit_test 1 get
dfs.stream-buffer-size unit_test 4096 get
dfs.use.dfs.network.topology unit_test true get
dfs.user.home.dir.prefix unit_test /user get
dfs.web.authentication.filter unit_test org.apache.hadoop.hdfs.web.AuthFilter get
dfs.webhdfs.acl.provider.permission.pattern unit_test ^(default:)?(user|group|mask|other):[[A-Za-z_][A-Za-z0-9._-]]*:([rwx-]{3})?(,(default:)?(user|group|mask|other):[[A-Za-z_][A-Za-z0-9._-]]*:([rwx-]{3})?)*$ get
dfs.webhdfs.netty.high.watermark unit_test 65535 get
dfs.webhdfs.netty.low.watermark unit_test 32768 get
dfs.webhdfs.oauth2.enabled unit_test false get
dfs.webhdfs.rest-csrf.browser-useragents-regex unit_test ^Mozilla.*,^Opera.* get
dfs.webhdfs.rest-csrf.custom-header unit_test X-XSRF-HEADER get
dfs.webhdfs.rest-csrf.enabled unit_test false get
dfs.webhdfs.rest-csrf.methods-to-ignore unit_test GET,OPTIONS,HEAD,TRACE get
dfs.webhdfs.socket.connect-timeout unit_test 60s get
dfs.webhdfs.socket.read-timeout unit_test 60s get
dfs.webhdfs.ugi.expire.after.access unit_test 600000 get
dfs.webhdfs.use.ipc.callq unit_test true get
dfs.webhdfs.user.provider.user.pattern unit_test ^[A-Za-z_][A-Za-z0-9._-]*[$]?$ get
dfs.xframe.enabled unit_test true get
dfs.xframe.value unit_test SAMEORIGIN get
httpfs.buffer.size unit_test 4096 get
